[{"id":0,"href":"/docs/hbase/mds/base/","title":"基础","section":"Hbase","content":"数据模型 #    Table\n Hbase的table由多个行组成。\n   Row\n 一个行在Hbase中由一个或多个有值的列组成。Row按照字母进行排序，因此行健的设计非常重要。这种设计方式可以让有关系的行非常的近，通常行健的设计是网站的域名反转，比如(org.apache.www, org.apache.mail, org.apache.jira)，这样的话所有的Apache的域名就很接近。\n   Cloumn\n 列由列簇加上列的标识组成，一般是“列簇:列标识”，创建表的时候不用指定列标识。\n   Column Family\n 列簇在物理上包含了许多的列与列的值，每个列簇都有一些存储的属性可配置。例如是否使用缓存，压缩类型，存储版本数等。在表中，每一行都有相同的列簇，尽管有些列簇什么东西也没有存。\n   Column Qualifier\n 列簇的限定词，理解为列的唯一标识。但是列标识是可以改变的，因此每一行可能有不同的列标识。\n   Cell\n Cell是由row，column family,column qualifier包含时间戳与值组成的，一般表达某个值的版本。\n   Timestamp\n 时间戳一般写在value的旁边，代表某个值的版本号，默认的时间戳是你写入数据的那一刻，但是你也可以在写入数据的时候指定不同的时间戳。\n      属性 Hbase Rdbms     数据类型 只有字符串 丰富的数据类型   数据操作 增删改查，不支持join 各种函数和表连接   存储模式 基于列式存储 基于表结构和行式存储   数据保护 更新后仍然保留旧版本 替换   可伸缩性 轻易增加节点 需要中间层，牺牲性能    RowKey #  RowKey是会按字典序排序的，HBase表会用RowKey来横向切分表。无论是读和写都是用RowKey去定位到HRegion，然后找到HRegionServer。\nHRegion上有两个很重要的属性：start-key和end-key。在定位HRegionServer的时候，实际上就是定位这个RowKey在不在这个HRegion的start-key和end-key范围之内，如果在，说明找到了。\n设计 #    避免单调的递增行健，因为Hbase的行健是有序排列的，这样可能导致一段时间内大部分写入集中在某一个Region上进行操作，负载都在一台节点上；\n 可以设计成：[metric_type][event_timestamp]，不同的metric_type可以将压力分散到不同的region上。\n   行健短到可读即可，因为查询短键不必长键性能好多少，所以设计时要权衡长度；\n  行健不能改变，唯一可以改变的方式是先删除后插入。\n  直接关系到后续服务的访问性能。\n行键设计\n列簇设计\n命令 #     命令 作用     create 创建表   desc 查看表信息   put 插入数据   get 查询数据   scan 查询数据   alter 修改表   truncate 清空表数据   drop 删除表    创建表 #  create \u0026#39;table_name\u0026#39;, \u0026#39;column_family_1\u0026#39;, \u0026#39;column_family_2\u0026#39; # 例：创建一个名为student，列族名为info的表 create \u0026#39;student\u0026#39; \u0026#39;info\u0026#39; # 查看Hbase中的表 list PUT #  put \u0026#39;table_name\u0026#39;, \u0026#39;row_key\u0026#39;, \u0026#39;column_family:cloumn\u0026#39;, \u0026#39;value\u0026#39; # 例：将信息（name：July）插入到表student中 put \u0026#39;student\u0026#39; , \u0026#39;001\u0026#39; , \u0026#39;info:name\u0026#39; , \u0026#39;July\u0026#39; 查询 #  # 查询整行数据 get \u0026#39;table_name\u0026#39;, \u0026#39;row_key\u0026#39; # 例：获取表 student 行键为 001 的数据 get \u0026#39;student\u0026#39; , \u0026#39;001\u0026#39; # 查询某列数据 get \u0026#39;table_name\u0026#39;, \u0026#39;row_key\u0026#39;, \u0026#39;column_family:cloumn\u0026#39; # 例：查询表 student，001行，info列族，name列的数据 get \u0026#39;student\u0026#39; , \u0026#39;001\u0026#39; , \u0026#39;info:name\u0026#39; # 使用scan # 例：指定startrow scan \u0026#39;student\u0026#39;, {COLUMNS =\u0026gt; [\u0026#39;info:age\u0026#39;, \u0026#39;address\u0026#39;], LIMIT =\u0026gt; 10, STARTROW =\u0026gt; \u0026#39;2\u0026#39;} # 例：指定过滤 scan \u0026#39;student\u0026#39;,{FILTER=\u0026gt;\u0026#34;(TimestampsFilter (1491533426297))\u0026#34;} 删除 #  delete \u0026#39;table_name\u0026#39;, \u0026#39;row_key\u0026#39;, \u0026#39;column_family:cloumn\u0026#39; # 删除整行 deleteall \u0026#39;table_name\u0026#39;, \u0026#39;row_key\u0026#39; 清空数据 #  # 清空数据 truncate \u0026#39;table_name\u0026#39; # 例：清空表student中的数据 truncate \u0026#39;student\u0026#39; # 在清空表中数据时，系统自动先禁用表再清空数据，当数据清空完成后，系统自动恢复表的使用 # 查看表是否可用 is_enabled \u0026#39;table_name\u0026#39; 删除表 #  # Hbase表不能直接删除 # 先禁用表 disable \u0026#39;table_name\u0026#39; # 删除表 drop \u0026#39;table_name\u0026#39; 特性 #   强读写一致，但是不是“最终一致性”的数据存储，这使得它非常适合高速的计算聚合 自动分片，通过Region分散在集群中，当行数增长的时候，Region也会自动的切分和再分配 自动的故障转移  HBase可以以低成本来存储海量的数据并且支持高并发随机写和实时查询。\n列式存储 #      行存储 列存储     写性能 写入是一次完成，性能更高 把一行记录拆分成单列保存，写入次数明显比行存储多，实际花费时间比行存储多   读性能 读取少数几列时，需遍历其他无关列，IO开销较大，读整行数据时，依次顺序读即可，性能高 读取少数几列时，无需读取无关列，性能高；读取整行时，需分别读取所有列，并拼装成行，性能低   数据压缩 每行数据存储在一起，压缩比较低 以列为单位存储数据，这使得类型相同的数据存放在一起，对压缩算法友好，压缩比较高    "},{"id":1,"href":"/docs/mysql/mds/architecture/","title":"基础架构","section":"MySQL","content":"Server层 #   包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n 连接器 #   负责跟客户端建立连接、获取权限、维持和管理连接。\n mysql -h$ip -P$port -u$user -p  一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。 连接完成后，如果没有后续的动作，这个连接就处于空闲状态，可以在 show processlist 命令中看到它。 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。 如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。    长连接：连接成功后，如果客户端持续有请求，则一直使用同一个连接。\n  短连接：每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n  比较：建立连接的过程通常是比较复杂的，所以在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。\n  使用长连接可能产生的问题：有些时候 MySQL 占用内存涨得特别快。解决方案：\n MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。\n  定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。    查询缓存 #   MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。\n 执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。但是不建议使用查询缓存：\n  失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。\n 导致：对于更新压力大的数据库来说，查询缓存的命中率会非常低。 适用场景：业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。    按需使用：将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定：\nmysql\u0026gt; select SQL_CACHE * from T where ID=10；   分析器 #    词法分析：输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\n MySQL 从你输入的\u0026quot;select\u0026quot;这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n   语法分析：根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n 如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒。\n   优化器 #  优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执行器 #   对表有没有执行查询的权限。(在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。  mysql\u0026gt; select * from T where ID=10;  这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：\n 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。    对于有索引的表，执行的逻辑也差不多。\n第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。\n 存储引擎层 #   负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。\n "},{"id":2,"href":"/docs/distribute/","title":"分布式数据系统","section":"Docs","content":"出于以下目的需要在多台机器上分布数据：\n  扩展性\n 当数据量或者读写负载巨大，严重超出了单台机器的处理上限，需要将负载分散到多台机器。\n   容错与高可用性\n 当单台机器（或者多台，以及网络甚至整个数据中心）出现故障，还希望应用系统可以继续工作，这时需要采用多台机器提供冗余。这样某些组件失效之后，冗余组件可以迅速接管。\n   延迟考虑\n 如果客户遍布世界各地，通常需要考虑在全球范围内部署服务，以方便用户就近访问最近数据中心所提供的服务，从而避免数据请求跨越了半个地球才能到达目标。\n   系统扩展能力 #    共享内存架构\n 当负载增加需要更强的处理能力时，最简单的办法就是购买更强大的机器（有时称为垂直扩展）。由一个操作系统管理更多的CPU、内存和磁盘，通过高速内部总线使每个CPU都可以访问所有的存储器或磁盘。在这样一个共享内存架构中，所有这些组件的集合可看做一台大机器。\n  此架构问题在于：成本增长过快甚至超过了线性，即如果把一台机器内的CPU数量增加一倍，内存扩容一倍，磁盘容量加大一倍，则最终总成本增加不止一倍。并且由于性能瓶颈因素，这样的一台机器尽管拥有了两倍的硬件指标但却不一定能处理两倍的负载。\n  共享内存架构能够提供有限的容错能力，例如高端的服务器可以热插拔很多组件（在不关闭机器的情况下更换磁盘，内存模块，甚至是CPU）。但是很显然，它仍局限于某个特定的地理位置，无法提供异地容错能力。\n   共享磁盘架构\n 共享磁盘架构拥有多台服务器，每个服务器各自拥有独立的CPU和内存，然后将数据存储在可共享访问的磁盘列阵上，服务器与磁盘列阵之间往往通过高速网络连接。\n  这种架构多适用于数据仓库等负载，然而通常由于资源竞争以及锁的开销等限制了其进一步的扩展能力。\n   无共享结构 #   运行数据库软件的机器或者虚拟机称为节点。每个节点独立使用本地的CPU，内存和磁盘。节点之间所有协调通信等任务全部运行在传统网络（以太网）之上且核心逻辑主要依靠软件来实现。\n  无共享系统不需要专门的硬件，具有较高的性价比。它可以跨过多个物理区域分发数据，从而减少用户的访问延迟，甚至当整个数据中心发生灾难时仍能继续工作。通过云计算虚拟机的部署方式，可以轻松拥有跨区域的分布式架构和服务能力。\n  虽然分布式无共享体系架构具有很多优点，但也会给应用程序带来更多的复杂性，有时甚至会限制实际可用的数据模型。\n 复制与分区 #  将数据分布在多节点时有两种常见的方式：\n  复制\n 在多个节点上保存相同数据的副本，每个副本具体的存储位置可能不尽相同。复制方法可以提供冗余：如果某些节点发生不可用，则可以通过其他节点继续提供数据访问服务。复制也可以帮助提高系统性能。\n   分区\n 将一个大块头数据库拆分成多个较小的子集即分区，不同的分区分配给不同的节点（也成为分片）。\n   这些是不同的数据分布机制，然而它们经常被放到一起组合使用。\n"},{"id":3,"href":"/docs/algorithm/mds/base_data_structure/","title":"一维","section":"数据结构和算法","content":"数组（array） #   数组是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。\n 特点 #    线性表\n 线性表就是数据排列像一条线一样的数据结构，每个线性表上的数据最多只有前和后两个方向。\n  链表、队列、栈等也是线性表结构。\n  二叉树、堆、图等，是非线性表，因为数据之间并不是简单的前后关系。\n   连续的内存空间和相同的数据类型\n 这两个限制，使数组有了随机访问的特性，计算机可以使用以下寻址公式，随机访问数组中的某个元素：\n a[i]_address = base_address + i * data_type_size  base_address 为数组的起始地址，data_type_size是每个元素占用的内存的大小，i是元素的索引。\n   低效的插入和删除\n 为了保证数组的连续性，在进行插入、删除操作的时候，需要做大量的数据迁移工作，因此效率会低一些。\n   插入\n 假设数组的长度为 n，如果需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，需要将第 k～n 这部分的元素都顺序地往后挪一位。\n如果数据插在末尾，这时的时间复杂度为 O(1)。\n但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。平均情况时间复杂度为 (1+2+…n)/n=O(n)。\n   删除\n 跟插入数据类似，如果要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。\n   优化\n 插入：如果数组中的元素，是没有任何规律的，数组只是被当作一个存储数据的集合，这种情况下，可以直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。\n  删除：可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作(这也是标记清除算法思想)。\n     时间复杂度 #   随机查找：O(1) 插入：最好：O(1)，最坏：O(N)，平均O(N) 删除：最好：O(1)，最坏：O(N)，平均O(N)  容器ArrayList #   Java语言中的容器，java.util.ArrayList，底层的数据结构就是数组。封装了操作的细节，并且支持动态扩容，使用起来更加方便。\n需要注意一点的是，如果能够预知数据的数量，最好提前定义容器的大小，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。\n  尽管ArrayList用起来很方便，但是数组也并非没有用武之地： 1.数组无法存储基本类型数据，而装箱拆箱也会有一定的性能消耗，特别关注性能，选择数组； 2.某些使用多维数据结构的情况下，使用数组看起来更直观，Object[][] array与ArrayList\u0026lt;ArrayList\u0026lt;object\u0026gt; \u0026gt; array。\n Leetcode练习题 #     题目 编号 思路     两数之和 1 哈希表   盛水最多的容器 11 双指针（左右夹逼）   移动零 283 双指针   爬楼梯 70    三数之和 15 排序、双指针（左右夹逼）   删除排序数组中的重复项 26 双指针   旋转数组 189 反转数组   合并两个有序数组 88 归并思路   加一 66     链表（linked list） #     题目 编号 思路     合并两个有序链表 21 归并或递归   反转链表 206 迭代或递归   两两交换链表中的节点 24 递归   环形链表 141 快慢指针   环形链表2 142 visted list   K个一组翻转链表 25 分段反转    栈（stack） #     题目 编号 思路     有效的括号 20 栈   最小栈 155 辅助单调栈   柱状图中最大的矩形 84 单调栈   滑动窗口的最大值 239 双端队列   设计循环双端队列 641 容量加一   接雨水 42 单调栈    队列（queue） #  双端队列（deque） #  集合（set） #  映射（map） #     题目 编号 思路     有效的字母异位词 242 数组计数   字母异位词分组 49 数组计数 + 哈希表   两数之和 1     "},{"id":4,"href":"/docs/elasticsearch/mds/0_pre/","title":"前置知识","section":"Elasticsearch","content":"倒排索引 #  核心组成 #    单词词典（Term Dictionary）\n 记录所有文档的单词，记录单词到倒排列表的关联关系；一般比较大，可以通过B+树或者哈希拉链法实现，以满足高性能的插入与查询。\n   倒排索引表（Posting List）\n 记录了单词对应的文档集合，由倒排索引项组成。倒排索引项（Posting）：\n 文档ID； 词频TF：该单词在文档中出现的次数，用于相关性评分； 位置（Position）：单词在文档中分词的位置。用于语句搜索（phrase query）； 偏移（Offset）：记录单词的开始结束位置，实现高亮显示。       默认使用 #   Elasticsearch的JSON文档中的每个字段，都有自己的倒排索引；\n可以指定对某些字段不做索引：优点：节省空间；缺点：字段无法被搜索。\n 搜索的相关性 #  搜索是用户和搜索引擎的对话，用户关心的是搜索引擎结果的相关性：\n 是否可以找到所有相关的内容 有多少不相关的内容被返回了 文档的打分是否合理 结合业务需求，平衡结果排  衡量相关性：\n Precision（查准率）：尽可能返回较少无关文档 Recall（查全率）：尽量返回较多相关文档 Ranking：能否按照相关度排序   绿色代表应该被搜索到的结果，黄色代表不应该被搜索到的结果。\n Precision = True Postive / (True and False Positives)\nRecall = True Postive / (True Positives + False Negtives)\n相关性算分 #   搜索的相关性算分，描述了一个文档和查询语句的匹配程度。Elasticsearch会对每个匹配查询条件的结果进行算分_score； 打分的本质是排序，需要把最符合用户需求的文档排在前面。ES5之前，默认的相关性算分采用TF-IDF，现在采用BM 25。  词频 #    Term Frequency：检索词在一篇文档中出现的频率，计算公式： TF = 检索词出现的次数 / 文档的总字数。\n 度量一条查询和结果文档相关性的简单方法：简单将搜索中的每一个词的TF进行相加。比如说搜索\u0026quot;区块链的应用\u0026quot;，相关性 = TF（区块链） + TF（的） + TF（应用）。\n   Stop word：有些词出现再多次也无需计算到相关性中。比如，的”在文档中出现了很多次，但是对贡献相关度几乎没有用处，不应该考虑他们的TF。\n  逆文档频率 #  DF：检索词在所有文档中出现的频率。 Inverse Document Frequency：简单说 = log（全部文档数/检索词出现过得文档总数）；\n 假设搜索\u0026quot;区块链的应用\u0026quot;，“区块链”在相对较少的文档中出现；“应用”在相对比较多的文档中出现；“Stop Word”在大量文档中出现。所以“区块链”这个词比“应用”这个词共享度更高。\n TF-IDF本质就是将TF求和变成了加权求和： TF（区块链）* IDF（区块链） + IDF（的）* TF（的） + TF（应用）* IDF（应用）\nTF-IDF的概念 #  TF-IDF被公认为是信息检索领域最重要的发明； 除了在信息检索，在文献分类和其他相关领域有这非常广泛的应用； IDF的概念，最早是剑桥大学的“斯巴克 琼斯”提出：\n 1972年-“关键词特殊性的统计解释和它在文献检索中的应用”；但是没有理论上解释IDF应该使用log（全部文档数/检索词出现过得文档总数），而不是其他函数。也没有做进一步的研究。\n  Lucene的TF-IDF评分公式：  BM25 #  控制算分 #   Boosting 是控制相关度的一种手段，可以对索引、字段、或查询条件使用。\n 参数boost的含义：\n 当boost \u0026gt; 1 时，打分的相关度相对性提升； 当0\u0026lt; boost \u0026lt; 1时，打分的权重相对性降低； 当boost \u0026lt; 0时，贡献负分。  分词 #  Analysis与Analyzer #   Analysis   文本分析是把全文本转换一系列单词（term/token）的过程，也叫分词。\n  Analyzer   Analysis通过Analyzer来实现。\n ES在数据写入时转换词条，匹配Query语句时也需要用相同的分析器对查询语句进行分析。\nAnalyzer的组成 #   Character Filters   针对原始文本处理，例如去除html。\n  Tokenizer   按照规则切分为单词，比如按照空格。\n  Token Filter   将切分的单词进行加工，小写，删除stopwords（停用词），增加同义词。\n ES 内置的分词器 #    Standard Analyzer：默认分词器，按词切分，小写处理；\n  Simple Analyzer：按照非字母切分（符号被过滤），小写处理；\n  Stop Analyzer：小写处理，停用词过滤（the，a，is）；\n  Whitespace Analyzer：按照空格切分，不转小写；\n  Keyword Analyzer：不分词，直接将输入当做输出；\n  Patter Analyzer：正则表达式，默认\\W+（分字符分隔）；\n  Language：提供了30多种常见语言的分词器；\n  Customer Analyzer：自定义分词器。\n  _analyzer API #    指定Analyzer进行测试\nGET /_analyze { \u0026#34;analyzer\u0026#34; : \u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34; : \u0026#34;Master Elasticsearch, elasticsearch in Action\u0026#34; }   指定索引的字段进行测试\nPOST 索引名/_analyze { \u0026#34;field\u0026#34; : \u0026#34;title\u0026#34;, \u0026#34;text\u0026#34; : \u0026#34;Master Elasticsearch, elasticsearch in Action\u0026#34; }   自定义分词器进行测试\nPOST /_analyze { \u0026#34;tokenizer\u0026#34; : \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34; : [\u0026#34;lowercase\u0026#34;], \u0026#34;text\u0026#34; : \u0026#34;Master Elasticsearch, elasticsearch in Action\u0026#34; }   自然语言与查询Recall #  当处理人类自然语言时，有些情况，尽管搜索和原文不完全匹配，但是希望搜到一些内容；Quick brown fox 和 fast brown fox / Jumping fox 和 Jumped foxes。\n一些可采取的优化：归一化词元：清除变音符号；抽取词根：清除单复数和时态差异；包含同义词；拼写错误：拼写错误，或者同音异形词。\n多语言混合的挑战 #    一些具体的多语言场景\n 不同索引使用不同的语言；同一索引中，不同的字段使用不同的语言；一个文档的一个字段内混合不同的语言。\n   混合语言存在的一些挑战\n 词干提取：以色列文档，包含了希伯来语、阿拉伯语、俄语和英文；不正确的文档频率：英文为主的文章中，德文算分高（稀有）；需要判断用户搜索时使用的语言，语言识别。例如，根据语言，查询不同的索引。\n   分词的挑战 #    英文分词\n You\u0026rsquo;re分成一个还是多个？Half-backed\n   中文分词\n 分词标准：哈工大标准中，姓和名分开。HanLP是在一起的。具体情况需制定不同的标准；\n歧义（组合型歧义，交集型歧义，真歧义）：中华人民共和国/美国会通过对台收武法案/上海仁和服装厂。\n   中文分词方法的演变 #    查字典\n 最容易想到的分词方法（北京航空大学的梁南元教授提出）；一个句子从左到右扫描一遍。遇到有的词就标示出来。找到复合词，就找最长的；不认识的字符就分割成单个字词。\n   最小词数的分词理论\n 哈工大王晓龙博士把查字典的方法理论化，一句话应该分成数量最少的词串；遇到二义性的分隔，无能为力（例如：发展中国家、上海大学城书店）；用各种文化规则来解决二义性，都并不成功。\n   统计语言模型\n 1990年前后，清华大学电子工程系郭进博士。解决了二义性问题，将中文分词的错误率降低了一个数量级。概率问题，动态规划 + 利用维特比算法快速找到最佳分词。\n   基于统计的机器学习算法\n 这类目前常用的算法是HMM、CRF、SVM、深度学习等算法；\n   中文分词器现状 #   中文分词器以统计语言模型为基础，经过几十年的发展，今天基本已经可以看做是一个已经解决的问题。不同分词器的好坏，主要的差别在于数据的使用和工程使用的精度。常见的分词器都是使用机器学习算法和词典相结合，一方面能够提高分词准确率，另一方面能够改善领域适应性。\n 一些中文分词器 #    HanLP\n  IK\n  Pinyin\n  "},{"id":5,"href":"/docs/elasticsearch/mds/1_basic/","title":"基本使用","section":"Elasticsearch","content":"基本概念 #  文档（Document） #    Elasticsearch是面向文档的，文档是所有课搜索数据的最小单位；\n 可以理解为关系型数据库中的一条记录。\n   文档会被序列化成JSON格式，保存在Elasticsearch 中；\n JSON对象由字段组成；每个字段都有对应的字段类型（字符串/数值/布尔/日期/二进制/范围类型）。\n   每个文档都有一个Unique ID。\n 可以自己指定ID；或者通过Elasticsearch自动生成。\n   JSON文档 #   字段的类型可以通过指定或者通过Elasticsearch自动推算； 支持数组/嵌套。  文档元数据 #   _index：文档所属的索引名； _type：文档所属的类型名； _id：文档的唯一ID； _source：文档的原始JSON数据； _all：整合所有字段内容到该字段，已被废除； _version：文档的版本信息； _score：相关性打分。  Response元数据 #   took：花费的时间； total：符合条件的总文档数； hits：结果集，默认前十个文档； _index：索引名； _id：文档的id； _score：相关度评分； _source：文档原始信息。  索引（Index） #   索引是文档的容器，是一类文档的集合。Index体现了逻辑空间的概念：每个索引都有自己的Mapping定义，用于定义包含的文档字段名和字段类型；Shard体现了物理空间的概念：索引中的数据分散在Shard上。\n   Mapping定义文档字段的类型\n  Setting定义不同的数据分布\n  Type\n 7.0之前，一个Index可以设置多个Types；6.0开始，Type已经被Deprecated。7.0开始，一个索引只能创建一个Type-\u0026quot;_doc\u0026quot;。\n   索引的不同语义 #   名词：一个Elasticsearch集群中，可以创建很多个不同的索引； 动词：保存一个文档到Elasticsearch的过程也叫索引（indexing）； ES中，创建一个倒排索引的过程。名词：一个B树索引，一个倒排索引。  与关系型数据库对比 #     RDBMS Elasticsearch     Table Index（Type）   Row Document   Column Field   Schema Mapping   SQL DSL   高性能全文检索 事务性/Join    基本操作 #  Rest api #    创建索引\nPUT movies   查看所有索引\n_cat/indices   查看索引相关信息\nGET 索引名   查看索引文档总数\nGET 索引名/_count   查看状态为绿的索引\nGET /_cat/indices?v\u0026amp;health=green   按照文档个数排序\nGET /_cat/indices?v\u0026amp;s=docs.count:desc   查看具体的字段\nGET /_cat/indices/关键字*?pri\u0026amp;v\u0026amp;h=health,index,pri,rep,docs.count,mt   占用多少内存\nGET /_cat/indices?v\u0026amp;h=i,tm\u0026amp;s=tm:desc   CRUD #   create document. 自动生成 _id  POST users/_doc { \u0026#34;user\u0026#34; : \u0026#34;Mike\u0026#34;, \u0026#34;post_date\u0026#34; : \u0026#34;2019-04-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Kibana\u0026#34; }  create document. 指定Id。如果id已经存在，报错  PUT users/_doc/1?op_type=create { \u0026#34;user\u0026#34; : \u0026#34;Jack\u0026#34;, \u0026#34;post_date\u0026#34; : \u0026#34;2019-05-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Elasticsearch\u0026#34; }  create document. 指定 ID 如果已经存在，就报错  PUT users/_create/1 { \u0026#34;user\u0026#34; : \u0026#34;Jack\u0026#34;, \u0026#34;post_date\u0026#34; : \u0026#34;2019-05-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Elasticsearch\u0026#34; }  Update 指定 ID (先删除，在写入)  PUT users/_doc/1 { \u0026#34;user\u0026#34; : \u0026#34;Mike\u0026#34; }  在原文档上增加字段  POST users/_update/1/ { \u0026#34;doc\u0026#34;:{ \u0026#34;post_date\u0026#34; : \u0026#34;2019-05-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Elasticsearch\u0026#34; } } PUT 必须指定id；POST 则非必须指定id。\n HTTP协议规定，POST方法修改资源状态时，URL指示的是该资源的父级资源，待修改资源的ID信息在请求体中携带。而PUT方法修改资源状态时，URL直接指示待修改资源。因此，同样是创建资源，重复提交POST请求可能产生两个不同的资源，而重复提交PUT请求只会对其URL中指定的资源起作用，也就是只会创建一个资源。\n  删除文档  DELETE users/_doc/1 Bulk API #   Bulk 操作  { \u0026#34;index\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; } } { \u0026#34;field1\u0026#34; : \u0026#34;value1\u0026#34; } { \u0026#34;delete\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34; } } { \u0026#34;create\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test2\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;3\u0026#34; } } { \u0026#34;field1\u0026#34; : \u0026#34;value3\u0026#34; } { \u0026#34;update\u0026#34; : {\u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;} } { \u0026#34;doc\u0026#34; : {\u0026#34;field2\u0026#34; : \u0026#34;value2\u0026#34;} }  mget 操作  GET /_mget { \u0026#34;docs\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; }, { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34; } ] } GET /_mget { \u0026#34;docs\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_source\u0026#34; : false }, { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34;, \u0026#34;_source\u0026#34; : [\u0026#34;field3\u0026#34;, \u0026#34;field4\u0026#34;] }, { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;3\u0026#34;, \u0026#34;_source\u0026#34; : { \u0026#34;include\u0026#34;: [\u0026#34;user\u0026#34;], \u0026#34;exclude\u0026#34;: [\u0026#34;user.location\u0026#34;] } } ] }  URI中指定index  GET /test2/_mget { \u0026#34;docs\u0026#34; : [ { \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; }, { \u0026#34;_id\u0026#34; : \u0026#34;3\u0026#34; } ] }  msearch 操作  POST kibana_sample_data_ecommerce/_msearch {} {\u0026#34;query\u0026#34; : {\u0026#34;match_all\u0026#34; : {}},\u0026#34;size\u0026#34;:1} {\u0026#34;index\u0026#34; : \u0026#34;kibana_sample_data_flights\u0026#34;} {\u0026#34;query\u0026#34; : {\u0026#34;match_all\u0026#34; : {}},\u0026#34;size\u0026#34;:2} 常见错误返回 #     问题 原因     无法连接 网络故障或集群挂了   连接无法关闭 网络故障或节点出错   429 集群过于繁忙   4xx 请求体格式有错   500 集群内部错误    Search API #  URI Search #   在URL中使用查询参数。\n   参数\n q：指定查询语句，使用Query String Syntax； df：默认字段，不指定时，会对所有字段进行查询； Sort排序 / from 和 Size 用于分页； Profile 可以查看查询时如何执行。    Query String Syntax\n  指定字段\n# 查询title字段包含2021的数据，使用的是 TermQuery（title字段是text类型） GET /movies/_search?q=2012\u0026amp;df=title # 另一种写法 GET /movies/_search?q=title:2021 # 带上sort等参数 GET /movies/_search?q=2012\u0026amp;df=title\u0026amp;sort=year:desc\u0026amp;from=0\u0026amp;size=10\u0026amp;timeout=1s   泛查询\n# 查询所有字段包含或等于2021的数据，使用的是 DisjunctionMaxQuery  GET /movies/_search?q=2012   Term vs Phrase\n# 查询title字段中包含Beautiful 和 Mind的数据，使用的是 PhraseQuery，Phrase查询，还要求前后顺序保持一致 GET /movies/_search?q=title:\u0026#34;Beautiful Mind\u0026#34; # 查询title字段包含Beautiful 或其他字段包含 Mind的数据，使用TermQuery（对title字段）和DisjunctionMaxQuery （对所有字段） GET /movies/_search?q=title:Beautiful Mind   分组与引号\n TermQuery 使用括号括起来；PhraseQuery 使用引号括起来。\n # 查询title字段包含Beautiful 或Mind 的数据，使用的是 TermQuery  GET /movies/_search?q=title:(Beautiful Mind)   布尔操作\n 两个TermQuery在一起，默认是or的关系，其他关系操作符： AND / OR / NOT\n   分组\n +表示 msut -表示 must_not\n # 查询title中包含了Beautiful 和Mind 的数据，使用的是BooleanQuery GET /movies/_search?q=title:(Beautiful AND Mind) # 查询title中包含了Beautiful 但不包含Mind 的数据，使用的是BooleanQuery GET /movies/_search?q=title:(Beautiful NOT Mind) # 等价于上一句 GET /movies/_search?q=title:(+Beautiful -Mind) # 查询title包含了Mind和可能包含Beautiful 的数据，使用的是BooleanQuery GET /movies/_search?q=title:(Beautiful %2BMind)   范围查询\n 区间表示：[]闭区间，{}开区间\n # 查询year字段大于1980的数据，使用的是IndexOrDocValuesQuery GET /movies/_search?q=year:\u0026gt;=1980 # 查询 year字段大于2010小于2018的数据，使用的是IndexOrDocValuesQuery GET /movies/_search?q=year:[2010 TO 2018]   通配符查询（通配符查询效率低，占用内存大，不建议使用）\n ? 代表1个字符，* 代表0个或多个字符\n # 查询title字段中有b开头的term的数据，使用的是MultiTermQueryConstantScoreWrapper GET /movies/_search?q=title:b*   模糊匹配 \u0026amp; 近似匹配\n# 查询title字段中类似beautifl（有一个字符的误差）的数据，使用的是BoostQuery GET /movies/_search?q=title:beautifl~1 # 查询title字段中有类似Lord Rings的短语，中间可以有小于2个间隔，使用的是PhraseQuery GET /movies/_search?q=title:\u0026#34;Lord Rings\u0026#34;~2     Request Body Search #   使用Elasticsearch提供的，基于JSON格式的更加完备的Query Domain Specific Language（DSL）。\n   分页：from，size\n  排序：sort：[{\u0026ldquo;字段名\u0026rdquo; : \u0026ldquo;desc\u0026rdquo;}]\n  _source filtering\n 如果_source没有存储，那就只返回匹配的文档的元数据；_source支持使用通配符：_source[\u0026ldquo;name*\u0026quot;]。\n   脚本字段：\n 使用painless脚本，计算出一个结果作为字段。\n # order_date字段和hello拼接作为一个新字段 GET kibana_sample_data_ecommerce/_search { \u0026#34;script_fields\u0026#34;: { \u0026#34;new_field\u0026#34;: { \u0026#34;script\u0026#34;: { \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;doc[\u0026#39;order_date\u0026#39;].value+\u0026#39;hello\u0026#39;\u0026#34; } } }, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } }   使用Match\n# operator为and表示两个term是and的关系，默认为or的关系 POST movies/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;last christmas\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;and\u0026#34; } } } }   短语搜索 - Match Phrase\n# slop表示短语之间可以有多少个位置 POST movies/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_phrase\u0026#34;: { \u0026#34;title\u0026#34;:{ \u0026#34;query\u0026#34;: \u0026#34;one love\u0026#34;, \u0026#34;slop\u0026#34;: 1 } } } }   Query String\n 类似于URI查询\n # 检索内容中可以有操作符，例如AND 、OR POST 索引名/_search { \u0026#34;query\u0026#34; : { \u0026#34;query_string\u0026#34; : { \u0026#34;default field\u0026#34; : \u0026#34;字段名\u0026#34;, \u0026#34;query\u0026#34; : \u0026#34;检索内容\u0026#34; } } }   Simple Query String\n  类似于Query String，但会忽略错误的语法，同时只支持部分查询语法； 不支持 AND OR NOT，会当做字符串处理； Term 之间默认关系是OR，可以指定Operator。   POST 索引名/_search { \u0026#34;query\u0026#34; : { \u0026#34;simple_query_string\u0026#34; : { \u0026#34;fields\u0026#34; : [\u0026#34;字段名\u0026#34;], \u0026#34;query\u0026#34; : \u0026#34;检索内容\u0026#34;, \u0026#34;default_operator\u0026#34; : \u0026#34;AND\u0026#34; } } }   Mapping #   Mapping类似数据库中的schema的定义，作用如下：\n定义索引中的字段的名称；\n定义字段的数据类型，例如字符串、数字、布尔；\n字段，倒排索引的相关配置（Analyzed or Not Analyzed）。\nMapping会把JSON文档映射成Lucene所需要的的扁平格式；\n一个Mapping属于一个索引的Type：每个文档都属于一个Type；一个Type有一个Mapping定义；7.0开始，不需要再Mapping定义中指定type信息。\n 字段的数据类型 #    简单类型\n  Text/Keyword Date Integer/Floating Boolean IPv4 \u0026amp; IPv6     复杂类型\n 对象类型/嵌套类型    特殊类型\n geo_point \u0026amp; geo_shape / percolator     假设要实现多字段类型，厂商名字实现精确匹配：\n 增加一个keyword字段 使用不同的analyzer：  不同语言 拼音字段的搜索 还支持为搜索和索引指定不同的analyzer     Dynamic Mapping #   写入文档时，如果索引不存在，会自动创建索引；Dynamic Mapping 的机制，使得我们无需手动定义Mappings。Elasticsearch会自动根据文档信息，推算出字段的类型；有时候会推算的不对，例如地理位置信息；类型设置不对时，会导致一些功能无法正常运行，例如Range查询。\n   类型字段识别\n   JSON类型 Elasticsearch类型     字符串 匹配日期格式，设置成Date   字符串 配置数字设置为float或者long，该选项默认关闭   字符串 设置为Text，并增加keyword子字段   布尔值 boolean   浮点数 float   整数 long   对象 Object   数组 由第一个非空数值的类型决定   空值 忽略      修改Mapping的字段类型\n  新增加字段\n   Dynamic 新增字段时候的表现     true 一旦有新增字段的文档写入，Mapping也同时被更新   false Mapping不会被更新，新增字段的数据无法被索引，但信息会出现在_source中   strict 文档写入失败      对已有字段\n 一旦已有数据写入，就不再支持修改字段定义。Lucene实现的倒排索引，一旦生产后，就不允许修改。\n   如果希望改变字段类型，必须Reindex API，重建索引。\n 如果修改了字段的数据类型，会导致已被索引的属于无法被搜索；如果是增加新的字段，就不会有这样的影响。\n     显示Mapping #  PUT 索引名 { \u0026#34;mappings\u0026#34; : {} }  手写，减少工作量，减少出错概率：\n创建一个临时的index，写入一些样本数据；\n通过访问Mapping API 获得该临时文件的动态Mapping定义；\n修改后用，使用该配置创建索引；\n删除临时索引。\n 常见参数 #    index-控制当前字段是否被索引。默认为true\n  Index Options\n  docs-记录doc id； freqs-记录doc id 和 term frequencies； positions-记录doc id / term frequencies / term position； offsets-记录doc id / term frequencies / term position / character offects。    Text 类型默认记录positions，其他默认 docs。\n   null_value；\n 需要对Null值实现搜索； 只有Keyword类型支持设定null_value。    copy_to；\n _all 在 7中被copy_to所替代；满足一些特定的搜索需求；copy_to将字段的数值拷贝到目标字段，实现类似_all的作用；copy_to的目标字段不出现在_source中。\n   数组类型；\n 任何字段，都可以包含多个相同类型的数值。\n   Index Template #   设定Mappings和Settings，并按照一定的规则，自动匹配到新创建的索引之上。也就是新创建索引时，不需要显示设置Mappings和Setting。\n 模板仅在一个索引被创建时，才会产生作用。修改模板不会影响已创建的索引； 可以设定多个索引模板，这些设置会被“merge”在一起； 可以指定“order”的数值，控制“merging”的过程。     工作方式\n 当一个索引被创建时：\n 应用Elasticsearch默认的settings 和 mappings； 应用order数值低的Index Template中的设定； 应用order高的Index Template中的设定，之前的设定会被覆盖； 应用创建索引时，用户所指定的Settings和Mappings，并覆盖之前模板中的设定。 优先级：用户指定 \u0026gt; order高 \u0026gt; order低 \u0026gt; ES默认     demo\n  创建Index Template\n# 匹配所有索引，设置主分片为1，副本分片为1 PUT _template/template_default { \u0026#34;index_patterns\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;order\u0026#34; : 0, \u0026#34;version\u0026#34;: 1, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 1, \u0026#34;number_of_replicas\u0026#34;:1 } } # 匹配名字为test开头的索引， PUT /_template/template_test，设置主分片为1，副本分片为1，关闭日期推测，打开数字推测 { \u0026#34;index_patterns\u0026#34; : [\u0026#34;test*\u0026#34;], \u0026#34;order\u0026#34; : 1, \u0026#34;settings\u0026#34; : { \u0026#34;number_of_shards\u0026#34;: 1, \u0026#34;number_of_replicas\u0026#34; : 2 }, \u0026#34;mappings\u0026#34; : { \u0026#34;date_detection\u0026#34;: false, \u0026#34;numeric_detection\u0026#34;: true } }   查看template\n# 查看名为template_default的模板 GET /_template/template_default # 查看名字以temp开头的模板 GET /_template/temp*   创建索引\nPUT testmy { \u0026#34;settings\u0026#34;:{ \u0026#34;number_of_replicas\u0026#34;:5 } } # 查看索引 GET testmy/_mapping GET testmy/_settings     Dynamic Template #   应用在某个索引上面，根据Elasticsearch识别的数据类型，结合字段名称，来动态设定字段类型。\n例如：\n 所有字符串类型都设定成keyword，或者关闭keyword字段； is开头的字段都设置成boolean； long开头的字段都设置成long类型。     demo\n# 类型为string设置字段为keyword类型，类型为string且名字以字段名is开头，设置字段为boolean类型 PUT my_index { \u0026#34;mappings\u0026#34;: { \u0026#34;dynamic_templates\u0026#34;: [ { \u0026#34;strings_as_boolean\u0026#34;: { \u0026#34;match_mapping_type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;match\u0026#34;:\u0026#34;is*\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; } } }, { \u0026#34;strings_as_keywords\u0026#34;: { \u0026#34;match_mapping_type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } ] } } # 匹配字段名为name.*的字段，不匹配字段名为*.middle的字段 PUT my_index { \u0026#34;mappings\u0026#34;: { \u0026#34;dynamic_templates\u0026#34;: [ { \u0026#34;full_name\u0026#34;: { \u0026#34;path_match\u0026#34;: \u0026#34;name.*\u0026#34;, \u0026#34;path_unmatch\u0026#34;: \u0026#34;*.middle\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;copy_to\u0026#34;: \u0026#34;full_name\u0026#34; } } } ] } }   "},{"id":6,"href":"/docs/distribute/mds/data_copy/","title":"数据复制","section":"分布式数据系统","content":" 复制主要指通过互联网络在多台机器上保存相同数据的副本。通过数据复制方案，通常希望达到以下目的：\n  使数据在地理位置上更接近用户，从而降低访问延迟； 当部分组件出现故障，系统依然可以继续工作，从而提高可用性； 扩展至多台机器以同时提供数据访问服务，从而提高读吞吐量。   复制的数据并非一成不变，一般采用主从复制、多主节点复制和无主节点复制三种方案，处理那些持续更改的数据。\n 主节点与从节点 #  主从复制原理：\n 指定一个副本为主副本（或称为主节点）。当客户写数据库时，必须将写请求发送给主副本，主副本首先将新数据写入本地存储； 其他副本则全部称为从副本（或称为从节点）。主副本把新数据写入本地存储后，然后将数据更改作为复制的日志或更改流发送给所有从副本。每个从副本获得更改日志之后将其应用到本地，且严格保持与祝副本相同的写入顺序； 客户端从数据库中读数据时，可以在主副本或者从副本上执行查询。  同步/异步复制 #    同步\n 同步复制主节点需要等待直到从节点确认完成了写入 。\n  优点：主从数据一致（万一主节点发生故障，可以在从节点访问最新数据）； 缺点：从节点无法完成确认的话（例如从节点崩溃或网络原因），写入不能视为成功。主节点会阻塞其后所有写操作，直到同步副本确认完成。    异步\n 异步复制主节点发送消息后立即返回不用等待从节点确认 。\n  优点：从节点落后不会影响主节点响应写请求，系统吞吐性能更好； 缺点：数据不同步；如果主节点失败且不可恢复，所有尚未复制到从节点的写请求将丢失。   异步复制被广泛使用。场景：节点数据巨大；分布于广域地理环境。\n   半同步\n 半同步，一个从节点同步，其他异步。\n  优点：至少两个节点拥有最新的数据副本。    链式同步\n  配置新的从节点 #   某个时间点对主节点的数据副本产生一个一致性快照 ； 将此快照拷贝到新的从节点 ； 从节点连接主节点请求快照点之后的的数据变更日志 ； 从节点处理快照点之后的数据变更，称为 追赶。  处理节点失效 #    从节点失效：追赶式恢复\n  根据复制日志，从节点知道发生故障前最后一笔事务 ； 之后连接到主节点，从那之后追赶。     主节点失效：节点切换\n  某个从节点提升为主节点； 客户端更新 ； 其他从节点接受新的主节点。     节点自动切换步骤\n  确认主节点失效（超时机制） ; 选举新的主节点（共识问题）; 重新配置系统使主节点生效（请求路由）。     节点自动切换变数\n  异步复制，主从数据不同步；选举之后，原主上线且未意识到角色变化，同步其他从节点，但其中一个现在是新主，造成写冲突。解决：原主未完成的写请求丢弃； 丢弃更新可能比较危险； 脑裂； 设置合适超时时间。    考虑节点失效、网络不可靠、副本一致性、持久性、可用性与延迟之间的权衡。\n     复制日志的实现 #    基于语句的复制\n 优点：简单。但有许多不适用的场景：\n 非确定性函数语句：NOW()或RAND()； 使用自增列或依赖现有数据，副本必须按照相同顺序，对于多个同时并发执行的事务有限制； 有副作用的语句（.触发器、存储过程、自定义函数）可能在每个副本产生不同副作用。     基于预写日志(WAL)传输\n  基于行的逻辑日志复制\n  行插入，日志包含所有相关列的新值 ; 行删除，日志里有足够的信息来唯一标识已经删除的行 ; 行更新，日志包含足够信息来唯一标识更新的行，以及所有列的新值。     基于触发器复制\n 开销高，容易出错，但是很灵活。\n   复制滞后问题 #  读自己的写 #   用户访问可能被修改的内容，从主读；否则在从读 ； 更新后一分钟内从主读，监控从，不读滞后一分钟的从 ； 客户端记住更新的时间戳，附带在请求中，系统根据该时间戳保证相应的副本处理 ； 副本分布在多中心，先把请求路由到主节点所在的数据中心。    跨设备写后读一致性：\n  元数据必须做到全局共享 ； 如果副本分布在多数据中心，确保将来自不同设备的请求路由到同一个数据中心。     单调读 #   现象：用户看到了最新内容之后又读到了过期的内容，好像时间被回拨。\n  单调读一致性可以确保不会发生这种异常，这是一个比强一致性弱，但比最终一致性强的包中。\n  实现：确保每个用户总是从固定的同一副本执行读取。\n 前缀一致读 #   该保证是说，对于一系列按照某个顺序发生的写请求，那么读取这些内容时也会按照当时的写入顺序。\n  解决方案： 确保任何具有因果顺序关系的写入都交给一个分区来完成\n 复制滞后的解决方案 #   应用层可以提供比底层数据库更强有力的保证 ； 应用层代码处理变的复杂，容易出错。   事务在分布式数据库性能和可用性代价过高。\n 多主节点复制 #   主从缺点：主节点网络异常导致无法写入。\n  多主：每个主节点都可以写，同时也扮演其他主节点的从。\n 适用场景 #    多数据中心\n 每个数据中心，采用主从；数据中心之间，由主和其他数据中心主节点交互。\n   与主从比较\n  性能：就近访问，异步同步到其他中心 ； 容忍数据中心失效：每个数据中心独立运行 ； 容忍网络问题：数据中心内的本地网络更可靠。       离线客户端操作\n 应用断开网络后还需要继续工作。\n   协作编辑\n  处理写冲突 #    同步与异步冲突检测\n 同步检测冲突会丧失多主优势，异步检测冲突无法让用户层解决冲突。\n   避免冲突\n 对特定记录的写请求通过同一个节点，但是可能发生数据中心故障问题使该策略失效。\n   收敛于一致状态\n  每个写入分片唯一id（时间戳、随机数、UUID等），id最高的写入作为胜利者，基于时间戳，被称为最后写入者获胜 ； 每个副本分配唯一id，序号高的副本优先写入 ； 以某种方式将这些值合并在一起，例如 按字母顺序排序拼接 ； 利用预定义好的格式记录和保留冲突，依靠应用层逻辑，时候解决。    1和2可能造成数据丢失。\n   自定义冲突解决逻辑\n  在写入时执行：数据库系统在复制变更日志时检测到冲突，就会调用应用层的冲突检测程序 ； 在读取时执行：检测到冲突时，所有冲突写入值会暂时保存下来，下一次读取时，多个版本的数据返回给应用层，提示用户处理。     什么是冲突\n 不同主节点预订会议室例子。\n   拓扑结构 #    环形拓扑\n 写请求通过多个节点才能到全部副本 。\n 防止无限循环，每个节点要赋予唯一标识，遇到自己的标识，忽略 ； 一个节点发生了故障，会影响其他节点之间复制日志的转发，需要重新配置拓扑结构。     星形拓扑\n 同环形。\n   全部-至-全部拓扑\n  避免了单点故障，更好的容错性 ； 可能存在某些网络链路比其他链路更快，导致复制日志之间的覆盖（先插入后更新，但是更新先到了）。     无主节点复制 #   写请求发送到多副本 ； 或者由一个协调者代表客户端进行写入，协调者不负责写入顺序的维护。  节点失效时写入数据库 #   向三个副本发出写请求，2个成功，1个失败（失效了），如果失败的节点重新上线，可能读到过期数据。\n  解决：读数据时，向多个副本发送请求，多个值使用版本号。\n   读修复与反熵：失效节点上线后，赶上错过的写请求\n  读修复\n  读的过程检测到过期值，并修复 ； 适合频繁读取的场景。     反熵\n  后台进程不断查找副本间的差异 ； 不保证以特定顺序复制写入，并且会引入明显滞后。       读quorum：n个副本几个成功才算写入成功\n 仲裁读/写：n个副本，写入需要w个节点确认，读取必须至少查r个节点，只要w + r \u0026gt; n，读取节点一定有新值。\n  n、w、r通常可配置。常见设置n为奇数，w = r = （n + 1） / 2。读多写少可配置w = n，r = 1。\n  当 w \u0026lt; n，如果一个节点不可用，仍然可以处理写入 ； 当 r \u0026lt; n，如果一个节点不可用，仍可以读取 ； 假定 n = 3，w = 2， r = 2，则可以容忍一个不可用的节点 ； 假定 n = 5， w = 3， r = 3，则可以容忍两个不可用节点 ； 通常，读取和写入操作会发送到所有副本，w 和 r 决定要等待的节点数。    Quorum 一致性的局限性 #   可能返回旧值。\n  sloppy quorum ； 如果两个写操作同时发生，无法明确先后顺序（唯一安全解决方案：合并并发写入，时间戳会受时钟偏差影响） ； 写操作和读操作同时发生，写操作在一部分副本完成，读返回旧值还是新值不确定 ； 总的写入成功少于w，没法回滚 5.新值节点失效，恢复数据来自旧值，总的新值副本会低于w。    监控旧值\n  主从比较容易，对比偏移量的值； 无主比较难，没有固定写入顺序。     宽松的quorum与数据回传\n 放松的仲裁：无法达到w或r所要求的quorum，暂时写入一些可以访问的节点（这些节点不在n中），网络恢复后，临时节点把写请求发送到原始主节点。\n  比如没带钥匙，去邻居家休息。\n   多数据中心操作\n 不同数据库，n的定义不同，可能是所有数据中心的节点，也可能是一个数据中心的节点数。\n   检测并发写 #   网络原因，请求在不同节点呈现不同顺序。\n   最终写入者获胜\n 丢弃并发写入：每个副班总是保存最新值，允许覆盖并丢弃旧值。\n  选择最大的时间戳，LWW，可能被覆盖写；\n保证安全：只写入一次且写入值视为不可变。 每个写操作都有唯一主键。\n   Happens-before关系和并发\n 两个操作A/B：\n A在B之前 B在A之前 A、B并发    判断两个操作是否并发，不是的话可以覆盖，是的话要解决冲突；\n两个操作不需要意识到对方，可称他们为并发操作。\n   确定前后关系\n  服务器为每个主键维护一个版本号，每当主键新值写入时递增版本号，并将新版本号与写入的值一起保存 ； 客户端读取主键时返回所有当前值以及新版本号，且要求写之前必须读 ； 客户端写主键，必须包含之前读到的版本号、读到的值和新值合并后的集合，写请求响应也返回所有当前值 ； 服务器收到特定版本号的写入，覆盖该版本号或更低版本的所有值，但必须保存更高版本号的所有值。     合并同时写入的值\n 墓碑-删除标记。\n   版本矢量\n 多副本，为每个副本每个主键均定义一个版本号。\n   "},{"id":7,"href":"/docs/hbase/mds/architecture/","title":"架构","section":"Hbase","content":"Client #  提供了访问HBase的接口，并且维护了对应的cache来加速HBase的访问。\nZookeeper #  存储HBase的元数据（meta表），无论是读还是写数据，都是去Zookeeper里边拿到meta元数据告诉给客户端去哪台机器读写数据。\nHRegionServer #  处理客户端的读写请求，负责与HDFS底层交互，是真正干活的节点。\n HBase是分布式的，HBase一张表的数据会分到多台机器上的（通过RowKey切分）。一个HRegionServer可以有多个HRegion。\n HRegion #  一个HRegion上，存储HBase表的一部分数据。HRegion下面有Store。\n 一个HBase表首先要定义列族，然后列是在列族之下的，列可以随意添加。一个列族的数据是存储在一起的，所以一个列族的数据是存储在一个Store里边的。\n   Store\n Store里边有Mem Store、Store File、HFile。\n HBase在写数据的时候，会先写到Mem Store，当MemStore超过一定阈值，就会将内存中的数据刷写到硬盘上，形成StoreFile，而StoreFile底层是以HFile的格式保存，HFile是HBase中KeyValue数据的存储格式。\n  HLog #  写数据的时候是先写到内存的，为了防止机器宕机，内存的数据没刷到磁盘中就挂了。在写Mem store的时候还会写一份HLog。HLog是顺序写到磁盘的。\n总结 #   HRegionServer是真正干活的机器（用于与hdfs交互），HBase表用RowKey来横向切分表； HRegion里边会有多个Store，每个Store其实就是一个列族的数据（所以可以说HBase是基于列族存储的）； Store里边有Men Store和StoreFile(HFile)，其实就是先走一层内存，然后再刷到磁盘的结构。  读写简流程 #   client请求到Zookeeper，然后Zookeeper返回HRegionServer地址给client，client得到Zookeeper返回的地址去请求HRegionServer，HRegionServer读写数据后返回给client。\n HMaster #  HMaster会处理 HRegion 的分配或转移。如果我们HRegion的数据量太大的话，HMaster会对拆分后的Region重新分配RegionServer。（如果发现失效的HRegion，也会将失效的HRegion分配到正常的HRegionServer中）\nHMaster会处理元数据的变更和监控RegionServer的状态。\n"},{"id":8,"href":"/docs/algorithm/mds/data_structure_2/","title":"二维","section":"数据结构和算法","content":"树（tree） #  图（graph） #  二叉搜索树（binary search tree） #  遍历 #   前序：根\u0026ndash;左\u0026ndash;右 中序：左\u0026ndash;根\u0026ndash;右 后序：左\u0026ndash;右\u0026ndash;根     题目 编号     二叉树的中序遍历 94   二叉树的前序遍历 144   N叉树的后续遍历 590   N叉树的前续遍历 589   N叉树的层序遍历 429    堆（heap） #  并查集（disjoint set） #  字典树（Trie） #  "},{"id":9,"href":"/docs/mysql/mds/log/","title":"日志","section":"MySQL","content":"使用InnoDB引擎过程中，比较耳熟能详的三种日志：\n undo log：用于回滚； redo log：崩溃恢复； bin log：备份、主从同步。  WAL技术：Write-Ahead Logging，先写日志，再写磁盘。\n 如果每一次更新操作都要写入磁盘，查找+写入的IO成本很高，使用WAL技术可以避免。\n redo log 重做日志 #   InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了； 同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。  redo log的大小是固定的，可以配置为一组四个的文件，每个文件的大小是1GB，那么总共就可以记录4GB的操作。从头开始写，写到末尾就回到开头循环写。\n write pos：当前记录的位置，一边写一遍后移，写到3号文件末尾就回到0号文件开头； check point：当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件； write pos和check point之间是空白位置，可以用来记录新的操作。如果write pos追上了check point，这时不能再执行更新操作，要先停下来擦除一些记录，把check point 推进一下。   个人理解redo log其实是利用了磁盘的顺序写提高性能；redo log保证了crash-safe，已提交的数据不会丢失。\n flush #   把内存里的数据写入磁盘的过程就是flush。\n   脏页\n 当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n   flush 场景\n  InnoDB 的 redo log 写满了；\n 这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。\n   系统内存不足；\n 当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。\n  是否可以直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿 redo log 出来应用？\n  从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：\n 一种是内存里存在，内存里就肯定是正确的结果，直接返回； 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。  这样的效率最高。\n   MySQL 认为系统“空闲”的时候；\n  MySQL 正常关闭的情况。\n 此时，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。\n     flush对性能的影响\n 第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。\n   redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。\n 因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。\n   “内存不够用了，要先将脏页写到磁盘”，这种情况是常态。\n InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：\n 还没有使用的； 使用了并且是干净页； 使用了并且是脏页。    InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。\n  而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：\n如果要淘汰的是一个干净页，就直接释放出来复用；\n但如果是脏页，就必须将脏页先刷到磁盘，变成干净页后才能复用。\n  刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：\n 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。       刷脏页控制策略\n  innodb_io_capacity 参数：设置成磁盘的 IOPS。\n 磁盘的 IOPS 可以通过 fio 这个工具来测试。\n   InnoDB 的刷盘速度参考因素\n 可以这么想，如果刷太慢，会出现什么情况？首先是内存脏页太多，其次是 redo log 写满。\n   脏页比例\n 参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字。\n   redo log写盘速度\n InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。\n  InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。\n   根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。\n      innodb_flush_neighbors 参数\n 在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。\n  找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。\n  机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。\n  如果使用的是 SSD 这类 IOPS 比较高的设备的话，建议把 innodb_flush_neighbors 的值设置成 0。\n因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。\n   binlog 归档日志 #   归档：同义词为存档，指将处理完并且具有保存价值的事情或文件经系统整理后交档案室（馆）保存备案(备查)的过程。\n 与 redo log 的不同 #   redo log是InnoDB引擎特有的；bin log是MySQLServer层实现的，所有引擎都可以使用； redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑； redo log是循环写的，空间固定会被用完；binlog是可以追加写入的。追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。  为什么有两份日志 #  最开始MySQL的设计是用binlog作为归档用途，且MySQL刚开始是没有crash-safe能力的。后面出现了InnoDB引擎，通过redo log实现了crash-safe。\n三种格式 #    statement;\n binlog记录的是SQL语句原文。 在从库执行同样的SQL语句时，可能由于使用不同的索引，导致语句执行的效果不同，造成主从不一致。\n   row;\n binlog记录的是真实行的数据。 不会有主备不一致问题，但是占用空间可能比较大。\n   mixed。\n statement和row的混合。\n    最好使用row格式，尽管可能会比较占用内存，但是比较利于恢复数据。恢复数据时，最好使用mysqlbinlog工具接续出来，然后把解析的结果发给MySQL执行。\n 更新时两种日志的写入 #   执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。   最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是\u0026quot;两阶段提交\u0026quot;。\n 两阶段提交 #   是为了让两份日志之间逻辑一致。\n  先写redo log，可能导致binlog少一条，恢复临时库时与原库不同； 先写bin log，redo log少一条，崩溃恢复后没有这条数据，同样导致临时库时与原库不同。  双1配置 #   innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。 sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。  undo log #  MySQL的MVCC是基于undo log实现的，每次需要查询历史版本的数据，是通过undo log计算出来的。\n"},{"id":10,"href":"/docs/distribute/mds/data_shard/","title":"数据分区","section":"分布式数据系统","content":" 分区通常是这样定义的，即每一条数据（或者每条记录，每行或每个文档）只属于某个特定分区。每个分区都可以视为一个完整的小型数据库，虽然数据库可能存在一些跨分区的操作。\n  采用分区的主要目的是提高可扩展性。不同的分区可以放在一个无共享集群的不同节点上。这样一个大数据集可以分散在更多的磁盘上，查询负载也随之分不到更多的处理器上。\n  对单个分区进行查询时，每个节点对自己所在分区可以独立执行查询操作，因此添加更多的节点可以提高查询吞吐量。超大而复杂的查询尽管比较困难，但也可能做到跨节点的并行处理。\n 数据分区与数据复制 #   分区通常与复制结合使用，即每个分区在多个节点都存有副本。这意味着某条记录属于特定的分区，而同样的内容会保存在不同的节点上以提高系统的容错性。\n 键-值数据分区 #   分区的主要目标是将数据和查询负载均匀分布在所有节点上。\n   倾斜\n 而如果分区不均匀，则会出现某些分区节点比其他分区承担更多的数据量或查询负载，称之为倾斜。\n  倾斜会导致分区效率严重下降。在极端情况下，所有负载可能集中在一个分区节点上，这就意味着系统瓶颈在最烦忙的那个节点上。这种负载严重不成比例的分区即成为系统热点。\n   避免热点\n 避免热点最简单的方法是将记录随机分配给所有的节点上。可以比较均匀的分布数据，但当试图读取特定数据时，不得不并行查询所有节点。\n  改进上述方法，通过关键字来访问记录。\n   基于关键字区间分区 #   为每个分区分配一段连续的关键字或者关键字区间范围（以最小值和最大值来指示）。\n   关键字的区间不一定非要均匀分布，因为数据本身可能就不均匀；\n 例如，A和B开头的单词，一般比T、U、V、X、Y开头的单词多。如果只是简单的规定每个分区两个字母，可能导致有的分区比其他分区大很多。\n   分区边界可以由管理员手动确定，或者由数据库自动选择；\n  每个分区可以按照关键字排序保存；\n 这样可以轻松支持区间查询。\n   缺点：某些访问模式可能导致热点。\n 如果关键字是时间戳，假设每天一个分区，可能导致每天写入数据时候，所有写入操作都集中在一个分区，导致该分区在写入时负载过高，而其他分区空闲。\n   解决\n 使用时间戳以外的其他内容作为关键字的第一项。例如，可以在时间戳前面加上名称作为前缀，这样首先由名称，然后按时间进行分区。\n     基于关键字哈希值分区 #   对于上述数据倾斜和热点问题，许多分布式系统采用了关键字哈希函数的方式来分区。\n   一个好的哈希函数可以处理数据倾斜并使其均匀分布；\n 即使输入的字符串非常相似，返回的哈希值也会在相应数字范围内均匀分布。\n   用于数据分区目的的哈希函数不需要在加密方面很强；\n  为每个分区分配一个哈希范围；\n 关键字其根据哈希值范围划分到不同的分区。\n分区边界可以是均匀间隔，也可以是伪随机选择（一致性哈希）。\n   缺点：丧失了良好的区间查询特性。\n 丧失了良好的区间查询特性。\n  折中处理：复合主键。第一部分用于哈希分区，其他列可以用于区间查询。\n   负载倾斜与热点 #   基于哈希分区的方法可以减轻热点，但无法做到完全避免。一个极端情况是，所有的读/写操作都是针对同一个关键字，则最终所有请求都被路由到同一个分区。例如社交媒体网站，有数百万粉丝的名人用户发布一些热点事件。\n  通过应用层减轻倾斜程度。例如，如果某个关键字被确认为热点，\n 在关键字开头或者结尾添加一个随机数，只需要一个两位数的十进制随机数就可以将该关键字的写请求分配到不同的分区； 之后的任何读取都要些额外的工作，必须从所有关键字读取数据然后合并； 此外，还需要额外的元数据来标记哪些关键字进行了特殊处理。   分区与二级索引 #  基于文档分区的二级索引 #   假设color为二级索引，那么每当一辆红色汽车添加到数据库中，数据库分区会自动将其添加到索引条目为\u0026quot;color：red\u0026quot;的文档ID列表中。\n 在这种索引方法中：\n  每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中数据；\n  每当需要写数据库时，包括添加、删除或更新文档等，只需要处理包含目标文档ID的那一个分区。 因此文档分区索引也被称为本地索引；\n  读取时需要注意，需要将查询发送到所有的分区，然后合并所有返回的结果；\n  这种查询分区数据库的方法有时也称为分散/聚集， 显然这种二级索引的查询代价高\n昂。 即使采用了并行查询， 也容易导致读延迟显著放大。\n  基于词条的二级索引分区 #   另一种方法，可以对所有的数据构建全局索引，而不是每个分区维护自己的本地索引。\n而且，为避免成为瓶颈，不能将全局索引存储在一个节点上， 否则就破坏了设计分区均衡的目标。所以，全局索引也必须进行分区，且可以与数据关键字采用不同的分区策略。\n  索引本身也是分区的， 例如从a到r开始的颜色放在分区0中， 从s到z的颜色放在分区1中。\n   优点：读取更为高效\n 不需要采用scatter/gather对所有的分区都执行一遍查询，相反，客户端只需要向包含词条的那一个分区发出读请求。\n   缺点：写入速度较慢且非常复杂\n 单个文档的更新时，里面可能会涉及多个二级索引，而二级索引的分区，又可能完全不同甚至在不同的节点上，由此势必引入显著的写放大。\n    理想情况下，引应该时刻保持最新，即写入的数据要立即反映在最新的索引上。但是，对千词条分区来讲，这需要一个跨多个相关分区的分布式事务支持， 写入速度会受到极大的影响，所以现有的数据库都不支持同步更新二级索引。实践中， 对全局二级索引的更新往往都是异步的（也就意味着，如果在写入之后马上去读索引，那么刚刚发生的更新可能还没有反映在索引中）。\n 分区再平衡 #  随着时间的推移，数据库可能总会出现某些变化：\n 查询压力增加，因此需要更多的CPU来处理负载； 数据规模增加，因此需要更多的磁盘和内存来存储数据； 节点可能出现故障，因此需要其它机器来接管失效节点。  所有这些变化都要求数据和请求可以从一个节点转移到另一个节点。这样一个迁移负载的过程称为再平衡（或者动态平衡）。无论对于哪种分区方案，分区再平衡通常至少满足：\n 平衡之后，负载、数据存储、读写请求等应该在集群范围更均匀地分布； 再平衡执行过程中，数据库应该可以继续正常提供读写服务； 避免不必要的负载迁移，以加快动态再平衡，并尽量减少网络和磁盘I/O影响。  动态再平衡的策略 #    不使用取模\n 使用mod的话，如果节点数N发生了变化，会导致很多关键字需要从现有节点迁移到另一个节点。基本每次节点数变化都需要进行迁移，这种频繁的迁移操作大大增加了再平衡的成本。\n   固定数量的分区\n 创建远超实际节点数的分区数，然后为每个节点分配多个分区； 如果集群中添加了一个新节点，该节点可以从每个现有的节点上匀走几个分区，直到分区再次达到全局平衡； 如果是从集群删除节点，则采取相反的均衡措施。   选中的整个分区会在节点之间迁移，但分区的总数量仍维持不变，也不会改变关键字到分区的映射关系。唯一需要调整的是分区与节点的对应关系。\n  考虑到节点间通过网络传输数据总是需要时间，这样调整可以逐步完成，在此期间，旧的分区仍然可以接收读写请求。\n   动态分区\n 当分区的数据增长超过一个可配的参数阈值(HBase上默认值是10GB) ，它就拆分为两个分区，每个承担一半的数据量； 相反，如果大最数据被删除，并且分区缩小到某个阈值以下， 则将其与相邻分区进行合并。该过程类似于B树的分裂操作。 优点：分区数量可以自动适配数据总数。  如果只有少量的数据，少量的分区就足够了，这样系统开销很小； 如果有大量的数据， 每个分区的大小则被限制在一个可配的最大值。     对于一个空的数据库，因为没有任何先验知识可以帮助确定分区的边界，所以会从一个分区开始。可能数据集很小，但直到达到第一个分裂点之前，所有的写入操作都必须由单个节点来处理，而他节点则处于空闲状态。\n  为了缓解这个问题，HBase和MongoDB允许在一个空的数据库上配置一组初始分区（这被称为预分裂）。对于关键字区间分区，预分裂要求已经知道一些关键字的分布情况。\n   按节点比例分区\n 前两种分区策略，分区的数量与数据集大小成正比关系，与节点数无关。这种策略，使分区数和集群节点数成正比关系。\n   每个节点具有固定数量的分区；\n  当节点数不变时，每个分区的大小与数据集大小保持正比的增长关系；\n  节点数增加时，分区则会调整变小。\n 较大的数据量通常需要大量的节点来存储，这种方法也使每个分区大小保持稳定。\n     自动与手动再平衡操作 #   全自动式再平衡很方便，但是可能出现结果难以预测的情况；  再平衡是个比较昂贵的操作 节点负载过重可能导致对该节点误判   综合考虑让管理员介入再平衡。  请求路由 #   请求路由到正确的分区节点。\n  允许客户端链接任意的节点（例如，采用循环式的负载均衡器）。如果某节点恰好拥有所请求的分区，则直接处理该请求；否则，将请求转发到下一个合适的节点，接收答复， 并将答复返回给客户端； 将所有客户端的请求都发送到一个路由层，由后者负责将请求转发到对应的分区节点上。路由层本身不处理任何请求，它仅充当一个分区感知的负载均衡器； 客户端感知分区和节点分配关系。此时，客户端可以直接连接到目标节点，而不需要任何中介。   核心问题：作出路由决策的组件（可能是某个节点，路由层或客户端）如何知道分区与节点的对应关系以及其变 情况？\n   依靠独立的协调服务跟踪集群范围内的元数据\n  在节点之间使用gossip 协议来同步群集状态的变化\n 请求可以发送到任何节点，由该节点负责将其转发到目标分区节点。这种方式增了数据库节点 复杂性，但是避免了 ZooKeeper类的外部协调服务的依赖。\n   并行查询执行 #  对于大规模并行处理（ mass ve parallel proc ss ing, MPP ）这一类主要用于数据分析的关系数据库，在查询类型方面要复杂得多。\n典型的数据仓库 询包含多个联合、过滤、分组和聚合操作。 MPP 询优化器会将复杂的查询分解成许多执行阶段和分区，以便在集群的不同节点上井行执行。尤其是涉及全表扫描这样的 询操作，可以通过并行执行获益颇多。\n"},{"id":11,"href":"/docs/mysql/","title":"MySQL","section":"Docs","content":" 大部分内容总结自极客时间专栏。\n "},{"id":12,"href":"/docs/elasticsearch/mds/2_distribute/","title":"分布式原理","section":"Elasticsearch","content":"分布式特性 #   Elasticsearch 天生就是分布式架构。\n   高可用性\n 服务可用性：允许有节点停止服务； 数据可用性：部分节点丢失，不会丢失数据。    可扩展性\n 请求量提升/数据不断增长（将数据分布到所有节点上）。    带来的好处\n 存储支持水平扩容，支持PB级数据； 提高系统的可用性，部分节点停止服务，整个集群的服务不受影响。    不同集群的设置\n 不同的集群通过不同的名字来区分，默认名字 elasticsearch ； 通过配置文件修改，或者在命令行中 -E cluster.name = clustername 进行设定。    节点 #   节点是一个Elasticsearch 的实例，其本质就是一个JAVA进程。一台机器上可以运行多个Elasticsearch进程，但是生产环境一般建议一台机器上就运行一个Elasticsearch实例。\n每一个节点都有名字，通过配置文件配置，或者启动的时候 -E node.name = nodename指定；每一个节点在启动之后，会分配一个UID，保存在data目录下。\n   Coordinating Node\n 处理请求的节点，叫Coordinating Node。路由请求道正确的节点，例如创建索引的请求，需要路由到Master节点。\n  所有节点默认都是Coordinating Node； 通过将其他类型设置为False，使其成为Dedicated Coordinating Node。    Data Node\n 可以保存数据的节点，叫做Data Node，在数据扩展上起到了至关重要的作用（由Master Node决定如何把分片分发到数据节点上）。通过增加 Data Node，可以解决数据水平扩展和解决数据单点问题。\n  同一索引，主分片和副本分片不能分配在同一节点，防止某一节点宕机时数据丢失。如果某一个集群只有一个节点，此时某一个索引又存在副本分片，此时集群状态是黄色的，因为无法分配副本分片；如果该集群后续有节点加入，会在新加入的节点创建副本分片。\n  节点启动后，默认就是数据节点； 可以设置node.data:false禁止。    Master Node\n Master Node的职责：处理创建，删除索引等请求/决定分片被分配到哪个节点/负责索引的创建于删除；维护并且更新Cluster State。\n  最佳实践  Master非常重要，在部署上需要考虑解决单点的问题； 为一个集群设置多个Mastger节点/每个节点只承担Master的单一角色。      Master Eligible Node\n 一个集群，支持配置多个Master Eligible节点。这些节点可以在必要时（如Master节点出现故障，网络故障时）参与选主流程，成为Master节点；当集群内第一个Master eligible节点启动的时候，它会将自己选举成Master节点。\n  每个节点启动后，默认就是一个Master eligible节点； 可以设置node.master:false禁止。    默认节点类型\n   节点类型 配置参数 默认值     Master Eligible node.master true   data ode.data true   ingest node.ingest true   coordinating only 无 设置上面三个参数全为false   machine learning node.ml true（需要 enable x-pack）      分片 #   分片ES中最小的工作单元，是一个Lucene的Index。\n   Primary Shard - 提升系统存储容量\n 通过主分片，将数据分布在所有节点上，实现存储的水平扩展。\n主分片（Primary Shard）数在索引创建的时候指定，后续默认不能修改，如果修改，需重建索引。\n   Replica Shard - 提高数据可用性\n 通过引入副本分配（Replica Shard）\n  提高数据的可用性。一旦主分片丢失，副本分配可以Promote成主分片。副本分片数可以动态调整。每个节点上都有完备的数据。如果不设置副本分片，一旦节点硬件故障，就有可能造成数据丢失。\n  副本分片由主分片（Primary Shard）同步。通过支持增加Replica个数，一定程度可以提高读取吞吐量。\n     分片数的设定\n  主分片数过小\n 如果该索引增长的很快，集群无法通过增加节点实现对这个索引的数据扩展。\n   主分片数过大\n 导致单个Shard容量很小，引发一个节点上有过多的分片，影响性能。\n   副本分片数设置过多\n 副本分片数设置过多，会降低集群整体的写入性能。\n     倒排索引的不可变性 #   倒排索引采用Immutable Design 一旦生成，不可更改。\n   不可变性优势\n 无需考虑并发写文件的问题，避免了锁机制带来的性能问题； 一旦读入内核的文件系统缓存，便留在那里。只要文件系统存有足够的空间，大部分请求会直接请求内存，不会命中磁盘，提升了很大的性能； 缓存容易生成和维护/数据可以被压缩。    不可变性带来的挑战\n如果需要让一个新的文档可以被搜索，需要重建整个索引。\n  Lucene Index #   在Lucene中，单个倒排索引文件被称为Segment。Segment是自包含的，不可变更的。\n  多个Segments汇总在一起，称为Lucene的Index，其对应的就是Es中的Shard。\n   新文档写入时\n会生成新的Segment，查询时会同时查询所有的Segments，并且对结果汇总。Lucene中有一个文件，用来记录所有Segments信息，叫做Commit Point。\n  删除文档信息时\n保存在.del文件中，查询时会过滤掉。\n  分片生命周期 #   Refresh   将Index Buffer写入Segment的过程叫Refresh。Refresh 不执行 fsync操作。如果系统有大量的数据写入，那就会产生很多的Segment。\nRefresh后，数据就可以被搜索到了。这也是为什么Elasticsearch被称为近实时搜索。\n  Refresh 频率：默认1s发生一次，可通过index.refresh_interval 配置。 其他 Refresh时机：Index Buffer 被占满时，会触发Refresh，默认值是JVM的 10%。  Transaction Log   Segment写入磁盘的过程相对耗时，借助文件系统缓存，Refresh时，先将Segment写入缓存以开放查询；为了保证数据不会丢失，所以在Index文档时，同时写Transaction Log，高版本开始，Transaction Log默认落盘，每个分片有一个Transaction Log。\n在ES Refresh时，Index Buffer 被清空，Transaction Log 不会清空。\n Flush \u0026amp; Lucene Commit   调用Refresh，Index Buffer 清空并且 Refresh；调用fsync，将缓存中的Segments写入磁盘；清空（删除）Transaction Log.\n  频率：默认30分钟调用一次； 其他Flush 时机：Transaction Log满了会调用（默认512M）。  Merge   Segment很多，需要被定期合并。Merge可以减少Segments，真正删除已经删除的文档（.del文件）。\n ES 和 Lucene 会自动进行Merge 操作，也可以手动调用：\nPOST my_index/_forcemerge 集群 #  集群状态 #   集群状态（Cluster State），维护了一个集群中，必要的信息：\n 所有节点信息； 所有索引和其相关的Mapping和Setting信息； 分片的路由信息。    在每个节点上都保存了集群的状态信息； 只有Master节点才能修改集群的状态信息，并负责同步给其他节点。  选主过程 #   Master Eligible Node互相Ping对方，Node Id 低的成为被选举的节点； 其他节点会加入集群，但是不承担Master节点的角色； 一旦发现被选中的主节点丢失，就会被选举出新的Master节点。  脑裂 #   Split-Brain，分布式系统的经典网络问题，当出现网络问题，假设有3个节点，一个节点和其他节点无法连接，Node 2 和 Node 3会重新选举Master，Node 1 自己还是作为 Master组成一个集群，同时更新Cluster State；导致两个Master 维护不同的 cluster state。网络恢复时，无法正确恢复。\n Es中如何解决\n  设定仲裁数\n 限定一个选举条件，设置quorum（仲裁），只有在Master eligible节点数大于quorum时，才能进行选举；Quorum = (master 节点总数/ 2) + 1。\n例如：当3个master eligible时，设置discovery.zen.minimum_master_nodes为2，避免脑裂。\n   从7.0开始，无需这个配置\n  故障转移 #   下图3个节点共同组成集群。包含了1个索引，索引设置了3个Primary Shard 和 1个 Replica。\n 故障转移过程：\n Node 1 是Master 节点，节点意外出现故障。集群重新选举Master 节点； Node 3上的R0提升为 P0，集群变黄； R0 和R1 分配，集群变绿。  集群健康状态 #   Green：健康，所有主分片和副本分片都可用； Yellow：亚健康，所有的主分片可用，部分副本分片不可用； Red：不健康状态，部分主分片不可用。  文档分布式存储 #   文档会存储在具体的某个主分片和副本分片上：例如 文档1，会存储在P0和 R0分片上。\n 文档到分片的映射算法 #   确保文档能够均匀分布在所用分片上，充分利用硬件资源，避免部分机器空闲，部分机器繁忙。\n   随机/Round Robin；\n缺点：当查询文档1，分片数很多，需要多次查询才可能查到 文档1。\n  维护文档到分片的映射关系；\n缺点：当文档数据量大的时候，维护成本高。\n  实时计算，通过文档1，自动算出，需要去哪个分片获取文档。\nshard = hash(_routing) % number_of_primary_shards\n Hash算法确保文档均匀分散到分片中；默认的_routing值是文档id；可以自行制定routing数值，例如用相同国家的商品，都分配到制定的shard（如下）。\n PUT posts/_doc/100?routing=bigdata { \u0026#34;title\u0026#34; : \u0026#34;xxxx\u0026#34; }   ES一般使用算法3，这也是设置Index Settings 后，Primary 数，不能随意更改的根本原因。\n更新一个文档的流程 #  删除一个文档的流程 #  分布式搜索机制 #   Elasticsearch 的搜索，会分两阶段进行：\n 第一阶段-Query； 第二阶段-Fetch。     Query 阶段\n 假设集群有3个节点\n 用户发出搜索请求到ES 节点。节点收到请求后，会以 Coordinating 节点的身份，在6个主副分片中随机选择3个分片，发送查询请求； 被选中的分片执行查询，进行排序。然后，每个分片都会返回From + Size 个排序后的文档Id和排序值给Coordinating节点。     Fetch 阶段\n  Coordinating Node 会将 Query 阶段，从每个分片获取的排序后的文档Id列表重新进行排序。选取From 到 From + size 个文档的Id； 以Multi get请求的方式，到相应的分片获取详细的文档数据。     Query Then Fetch 潜在的问题 #    性能问题\n 每个分片上需要查的文档个数 = from +size 最终协调节点需要处理：number_of_shard * ( from + size) 深度分页    相关性算分\n 每个分片基于自己的分片上的数据进行相关度计算。这会导致打分偏离的情况，特别是数据量很少时。相关性算分在分片之间是相互独立。当文档总数很少的情况下，如果主分片大于1，主分片数越多，相关性算分会越不准。\n 解决方法：\n  数据量不大的时候，可以将主分片数设置为1;\n  当数据量足够大的时候，只要保证文档均匀分散在各个分片上，结果一般不会出现偏差；\n  使用DFS Query Then Fetch，搜索URL中指定参数 \u0026ldquo;_search?search_type=dfs_query_then_fetch\u0026rdquo;\n 到每个分片把各分片的词频和文档频率进行搜集，然后完整的进行一次相关性算分，耗费更加多的CPU和内存，执行性能低下，一般不建议使用。\n     排序 #   排序是针对字段原始内容进行的，倒排索引无法发挥作用，需要用到正排索引。通过文档ID 和字段快速得到字段原始内容。默认情况根据算分进行排序。\nElasticsearch 有两种实现方法：\n Fielddata Doc Values （列式存储，对Text 类型无效）       Doc Values Fielddata     何时创建 索引时，和倒排索引一起创建 搜索时候动态创建   创建位置 磁盘文件 JVM Heap   优点 避免大量内存占用 索引速度块，不用占用额外磁盘空间   缺点 降低索引速度，占用额外磁盘空间 文档过多时，动态创建开销大，占用过多JVM Heap   缺省值 ES 2.x 之后 ES 1.x 及之前      关闭 Doc Values\n Doc Values 默认启用，可以通过Mapping设置关闭，可以增加索引的速度/减少磁盘空间。如果重新打开，需要重建索引。\n明确不需要做排序以及聚合分析，可以关闭。\n   分页 #   默认情况下，查询按照相关度算分排序，返回前10条记录；\nfrom ：开始位置；\nSize ：期望获取文档的总数。\n 深度分页问题 #   ES 天生就是分布式的。查询信息，但是数据分别保存在多个分片，多台机器，ES天生就需要满足排序的需要（按照相关性算分）。\n当一个查询：From = 990， Size = 10：\n 会在每个分片上先获取1000 个文档； 然后通过Coordinating Node聚合所有结果； 最后再通过排序选取前 1000个文档。    页数越深，占用内存越多。为了避免深度分页带来的内存开销。ES有一个设定，默认限定10000 个文档\n   Search After\n 避免深度分页的性能问题，可以实时获取下一页文档信息。但是有限制：\n 不支持指定页数； 只能下翻。  使用：\n 第一步搜索需要指定sort，并且保证值是唯一的（可以通过加入_id保证唯一性）; 然后使用上一次，最后一个文档的sort值进行查询。   { \u0026#34;size\u0026#34;: 1, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;search_after\u0026#34;: [10,\u0026#34;ZQ0vYGsBrR8X3IP75QqX\u0026#34;], \u0026#34;sort\u0026#34;: [ {\u0026#34;age\u0026#34;: \u0026#34;desc\u0026#34;} ,{\u0026#34;_id\u0026#34;: \u0026#34;asc\u0026#34;} ] }  通过唯一排序值定位，将每次要处理的文档数都控制在 10。\n   Scroll API\n 创建一个快照，有新的数据写入以后，无法被查到；每次查询后，输入上一次的scroll id。\n POST /users/_search?scroll=5m { \u0026#34;size\u0026#34;: 1, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34; : { } } } POST /_search/scroll { \u0026#34;scroll\u0026#34; : \u0026#34;1m\u0026#34;, \u0026#34;scroll_id\u0026#34; : \u0026#34;DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAWAWbWdoQXR2d3ZUd2kzSThwVTh4bVE0QQ==\u0026#34; }   不同的搜索类型和使用场景\n  Regular\n 需要实时获取顶部的部分文档。例如查询最新的订单。\n   Scroll\n 需要全部文档，例如导出全部数据。\n   Pagination\n From 和 Size；\n如果需要深度分页，使用 Search After。\n     处理并发读写操作 #  并发空值的必要性 #   两个Web程序同时更新某个文档，如果缺乏有效的并发，会导致更改的数据丢失。\n   悲观并发控制\n 假定有变更冲突的可能。会对资源加锁，防止冲突。例如数据库行锁。\n   乐观并发控制\n 假定冲突是不会发生的，不会阻塞正在尝试的操作。如果数据在读写中被修改，更新将会失败。应用程序决定如何解决冲突，例如重试更新，使用新的数据，或者将错误报告给用户。\n  ES采用的是乐观并发控制。\n   ES的乐观并发空值 #   ES 中的文档是不可变更的。如果你更新一个文档，会将文档标记为删除，同时增加一个全新的文档。同时文档的version字段加1。\n   内部版本控制\n if_seq_no + if_primary_term\n PUT products/_doc/1?if_seq_no=1\u0026amp;if_primary_term=1 { \u0026#34;title\u0026#34;:\u0026#34;iphone\u0026#34;, \u0026#34;count\u0026#34;:100 }   使用外部版本（使用其他数据库作为主要数据存储）\n version + version_type = external\n PUT products/_doc/1?version=30000\u0026amp;version_type=external { \u0026#34;title\u0026#34;:\u0026#34;iphone\u0026#34;, \u0026#34;count\u0026#34;:100 }   "},{"id":13,"href":"/docs/algorithm/mds/data_structure_3/","title":"特殊","section":"数据结构和算法","content":"位运算（bitewise） #  布隆过滤器（bloom filter） #  LRU Cache #  "},{"id":14,"href":"/docs/mysql/mds/transaction/","title":"事务","section":"MySQL","content":"隔离性 #  隔离级别 #    读未提交（read uncommitted）；\n 一个事务还未提交时，它的变更就能被别的事务看到。（脏读问题）\n   读提交（read committed）；\n 一个事务提交之后，它做的变更才会被其他事务看到。（不可重复读、幻读问题）\n   可重复读（repeatable read）；\n 一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。\n   串行化（serializable）。\n 对于同一行记录，写会加写锁，读会加读锁。当出现读写锁冲突的时候，后访问的事务 必须等前一个事务执行完成，才能继续执行。\n   不同隔离级别，在一些场景看到的查询结果是不同的，在实现上，是通过创建一个视图，访问的时候以这个视图为准：\n 可重复读，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图； 读提交，这个视图是在每个SQL语句开始执行的时候创建的； 读未提交，直接返回记录上最新的值； 串行化，加锁避免并行访问。  事务隔离的实现 #   在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。\n 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。\n 当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。\n如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。\n对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。\n  回滚日志会在不需要的时候删除：系统里面没有比这个回滚日志更早的read-view的时候。   因此长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n MVCC #    事务id\nInnoDB每个事务都有一个唯一的事务id，叫做transaction id，是在事务开始时向事务系统申请的，按照申请顺序严格递增。\n   每行数据都有一个隐藏字段row_trx_id，这个字段的值就是transaction id。\n  图中的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来。\n  事务数组   InnoDB为每个事务构造了一个数组，用来保存这个事务启动的时候，当前正在活跃（启动但还未提交）的所有事务id； 低水位：数组里面事务id的最小值； 高水位：当前系统里面已经创建过的事务id最大值+1； 一致性视图：由事务数组和高水位组成。  数据版本的可见性，基于数据的row_trx_id和一致性视图对比的结果。对于当前事务启动瞬间来说，一个数据版本的row_trx_id可能有几种情况：\n  绿色部分：这个版本是已提交的事务或者当前事务自己生成的，这个数据是可见的；\n  红色部分：这个版本的数据是由将来启动的事务生成的，是不可见的；\n  黄色部分：a.如果如果row_trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见；b.如果row_trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。\n总结来说：\n  版本未提交，不可见；\n  版本已提交，但是实在视图创建后提交的，不可见；\n  版本已提交，而且实是在视图创建前提交的，可见。\n   一致性读和当前读   一致性读：普通查询都是一致性读，具有可重读的特点； 当前读：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”。  事务的启动方式 #    显式启动事务语句；\n begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。\n   set autocommit=0。\n 这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n    有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。\n  对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果纠结“多一次交互”的问题，可以使用commit work and chain 语法（提交事务并开启下一个事务（少执行一个begin语句））。\n 查询长事务 #  # 查找持续时间超过 60s 的事务 select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))\u0026gt;60 "},{"id":15,"href":"/docs/distribute/mds/challenge/","title":"分布式系统的挑战","section":"分布式数据系统","content":"故障与部分失效 #  不可靠的网络 #  不可靠的时钟 #  知识、真相与谎言 #  "},{"id":16,"href":"/docs/distribute/mds/transaction/","title":"事务","section":"分布式数据系统","content":" 事务将应用程序的多个读、写操作捆绑在一起成为一个逻辑操作单元。即事务中的所有读写是一个执行的整体，整个事务要么成功（提交）、要么失败（中止或回滚）。\n  事务目的是简化应用层的编程模型。\n 深入理解事务 #  ACID #   事务所提供的安全保证即大家所熟知的ACID。最早由TheoHarder和Andreas Reuter于1983年为精确描述数据库的容错机制而定义。\n  不符合ACID标准的系统有时被冠以BASE，取另外几个特性的首字母，即基本可用性（ Basically Available ），软状态（ Soft state ）和最终一致性（ Eventunal consistency)。\n   原子性\n 原子性在计算机的不同领域里有着相似但却微妙的差异。\n  例如，多线程编程中，如果某线程执行一个原子操作，这意味着其他线程是无法看到该操作的中间结果。它只能处于操作之前或操作之后的状态，而不是两者之间的状态。\n  ACID 中的原子性并不关乎多个操作的并发性，它并没有描述多个线程试图访问相同的数据会发生什么情况，后者其实是由 ACID 的隔离性所定义。\n  ACID 中原子性所定义的特征是：在出错时中止事务，并将部分完成的写入全部丢弃。\n   一致性\n ACID 中的一致性的主要是指对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或者恒等条件）。\n  例如，对于一个账单系统，账户的贷款余额应和借款余额保持平衡。如果某事务从一个有效的状态开始，并且事务中任何更新操作都没有违背约束，那么最后的结果依然符合有效状态。\n  这种一致性本质上要求应用层来维护状态一致。\n  原子性，隔离性和持久性是数据库自身的属性，而ACID中的一致性更多是应用层的属性。 应用程序可能借助数据库提供的原子性和隔离性，以达到一致性，但一致性本身并不源于数据库。\n   隔离性\n ACID语义中的隔离性意味着并发执行的多个事务相互隔离，它们不能互相交叉。\n  经典的数据库教材把隔离定义为可串行化，这意味着可以假装它是数据库上运行的唯一事务。虽然实际上它们可能同时运行，但数据库系统要确保当事务提交时，其结果与串行执行完全相同。\n   持久性\n 持久性保证一且事务提交成功，即使存在硬件故障或数据库崩溃，事务所写入的任何数据也不会消失。\n  对于单节点数据库，持久性通常意味着数据已被写入非易失性存储设备；而对于支持远程复制的数据库，持久性则意味着数据已成功复制到多个节点。\n   单对象与多对象事务操作 #   ACID中的原子性和隔离性主要针对客户端在同一事务中包含多个写操作时，数据库所提供的保证，这些定义假定在一个事务中会修改多个对象（如行， 文档， 记录等）。\n这种多对象事务目的通常是为了在多个数据对象之间保持同步。\n   单对象写入\n 原子性和隔离性也同样适用于单个对象的更新。\n   多对象事务的必要性\n 在没有原子性保证时，错误处理就会异常复杂，而缺乏隔离性则容易出现并发性方面的各种奇怪问题。\n   处理错误与终止\n 事务的一个关键特性是， 如果发生了意外， 所有操作被中止， 之后可以安全地重试。\n   弱隔离级别 #   数据库一直试图通过事务隔离来对应用开发者隐藏内部的各种并发问题。\n  可串行化的隔离会严重影响性能，而许多数据库却不愿意牺牲性能，因而更多倾向于采用较弱的隔离级别，它可以防止某些但并非全部的并发问题。\n 读-提交 #  读提交是最基本的事务隔离级别，它只提供以下两个保证：\n  防止 脏读\n 假定某个事务已经完成部分数据写入，但事务尚未提交，此时另一个事务可以看到尚未提交的数据，这就是脏读。\n脏读可能存在于以下场景：\n 如果事务需要更新多个对象，脏读意味着另一个事务可能会看到部分更新，而非全部。 如果事务发生中止，则所有写入操作都需要回滚。如果发生了脏读，这意味着它可能会看到一些稍后被回滚的数据。     防止 脏写\n 如果两个事务同时尝试更新相同的对象，后写的操作会覆盖较早的写入。\n但是，如果先前的写入是尚未提交事务的一部分，如果被覆盖，那就是脏写。\n如果事务需要更新多个对象，脏写会带来非预期的错误结果。\n  如果事务需要更新多个对象，脏写会带来非预期的错误结果。\n例如上图的二手车销售网站，Alice和Bob 两个人试图购买同一辆车。车主被改为Bob（因为 成功地抢先更新了车辆表单），但发票却发给了Alice（因为她成功的先执行了发票表单）。\n     实现读-提交\n  采用行级锁来防止脏写；\n 当事务想修改某个对象（例如行或文档）时，它必须首先获得该对象的锁；然后一直持有锁直到事务提交（或中止）。\n  给定时刻，只有一个事务可以拿到特定对象的锁，如果有另一个事务尝试更新同一个对象，则必须等待，直到前面的事务完成了提交（或中止）后，才能获得锁并继续。\n   采用维护新旧版本数据方式防止脏读。\n 对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设的新值两个版本：\n 这个事务提交前，所有其他读操作读取旧值； 提交后，才会切换到读新值。    其实也可以采用行级锁，但是会影响只读事务的响应延迟。\n     快照级别隔离与可重复读 #   可重复读指的是看到了别的事务已经提交的数据。\n 一些无法容忍可重复读的场景：\n  备份场景\n 备份过程中可能会持续写入，因此可能导致主备数据永久性的不一致。\n   分析查询与完整性检查场景\n 可能返回毫无意义的结果。\n    快照级别隔离是解决可重复读问题的常见手段：每个事务都从数据库的一致性快照读取，事务一开始所看到的是最近提交的数据，即使数据随后可能被另一个事务更改，但保证每个事务都只看到该特定时间点的旧数据。\n   实现快照级别隔离\n  采用写锁防止脏写（与读-提交隔离类似）；\n  保留了对象多个不同的提交版本（MVCC，多版本并发控制）来实现快照级别隔离。\n MVCC相较于之前读-提交隔离的防止脏读手段是更为通用的方式。支持快照级别隔离的存储引擎往往直接采用MVCC来实现读-提交隔离：\n 在读-提交隔离级别下：对每一个不同的查询单独创建一个快照； 在快照隔离级别下：使用一个快照来运行整个事务。       一致性快照的可见性规则\n 通过事务ID决定哪些对象可见，哪些不可见。\n 每笔事务开始，数据库列出所有当时正在进行中的事务，忽略这些事务完成的部分写入，即不可见； 所有终止事务所做的修改不可见； 较晚事务ID（晚于当前事务）所做的修改不可见，不管这些事务是否完成了提交； 除此之外，其他所有的写入都对应用查询可见。     索引与快照级别隔离\n 多版本数据库支持索引：\n 索引直接指向对象的所有版本，过滤当前事务不可见的那些版本。当后台垃圾回收进程决定删除某个旧对象版本时，对应的索引条目也需要随之删除。 另一种方法，使用B-tree，采用一种追加/写时复制的技术。     可重复读与命名混淆\n 快照级别隔离对于只读事务特别有效，但是许多数据库对它有不同的命名。Oracle称之为可串行化，MySQL和PostgreSql则称为可重复读。\n   防止更新丢失 #   读提交和快照级别隔离主要是为了解决只读事务遇到并发写时可以看到什么（虽然中间也涉及到脏读问题）。还存在另一种情况：两个写事务并发（脏写是写并发的一个特例）。\n  写事务并发可能会带来更新丢失的问题，更新丢失可能发生在这样一个场景：应用程序从数据库读取某些值，做出修改，然后写会新值（read-modify-write过程）；当有两个事务在同样的数据对象上执行类似操作，由于隔离性，第二个操作并不包括第一个事务修改后的值，最终会导致第一个事务的修改值可能会丢失。\n  一些其他不同场景：\n 递增计数器，或更新账户余额（read-modify-write）； 对某复杂对象的一部分内容执行修改，例如堆JSON文档中的一个列表添加新元素； 两个用户同时编辑wiki页面，且每个用户都尝试将整个页面发送到服务器。    并发写事务冲突解决方案：\n   原子写操作\nUPDATE counters SET value = value + 1 WHERE key = \u0026#39;keyName\u0026#39;;  原子操作通常采用对读取对象加独占锁的方式来实现，这样更新被提交前不会有其他事务可以读它；另一种实现方式是强制所有的原子操作都在单线程上执行。\n   显示加锁\nBEGIN TRANSACTION; SELECT * FROM figures WHERE id = 2 FOR UPDATE; UPDATE figures SET position = \u0026#39;c4\u0026#39; WHERE id = 2; COMMIT;  由应用程序显示锁定待更新对象。然后应用程序可以执行read-modify-write这样的操作序列；此时如果有其他事务尝试同时读取对象，则必须等待当前正在执行的序列全部完成。\n   自动检测更新丢失\n 原子操作和锁都是通过强制“读-修改-写回”操作序列串行来防止丢失更新。另一种思路是先让他们并发执行，但是如果事务管理器检测到了更新丢失的风险，则会终止当前事务，并强制回退到安全的“读-修改-写回”方式。\n  该方法的一个优点是数据库完全可以借助快照级别隔离来高效地检查执行。\n  PostgreSQL的可重复读，Oracle的可串行化以及SQL Server的快照级别隔离，都可以自动检测何时发生了更新丢失，然后终止那个违规事务。\n   原子比较和设置\n 在不提供事务支持的数据中，它们可能支持原子“比较和设置”操作。使用该操作可以避免更新丢失。\n   冲突解决与复制\n 对于多节点上的数据副本，不同的节点可能会并发修改数据，因此必须采取一些额外的措施来防止丢失更新。\n   保留多个冲突版本，由应用层逻辑或依靠特定的数据结构来解决、合并多版本； 如果操作可交换，则原子操作在多副本情况下也可以工作； 最后写入获胜（LWW） 容易丢失更新。     写倾斜与幻读 #   多个事务同时写入同一对象时引发了两种竞争条件，即脏写和更新丢失。多个事务同时写多个对象，可能也会发生微妙的问题。\n   定义写倾斜\n 如果两个事务读取相同的一组对象，然后更新其中一部分：不同的事务可能更新不同的对象，则可能发生写倾斜。\n  不同的事务更新的是同一个对象，可能发生脏写或更新丢失。\n  由于涉及多个对象，单对象的原子操作不起作用； 自动防止写倾斜要求真正的可串行化隔离； 不使用可串行化隔离的话，使用 FOR UPDATE 对所有返回结果加锁。    更多写倾斜的例子\n 会议室预订系统 多人游戏 声明一个用户名 防止双重开支    为何产生写倾斜\n 写倾斜的例子遵循以下类似的模式：\n 采用SELECT 查询所有满足的行； 根据查询结果，应用层代码决定下一步操作； 如果应用程序继续，它将发起数据库写入并提交事务。    这个写操作会改变步骤2做出决定的前提条件。\n上述步骤可能有不同的执行顺序，例如，可以先写入，然后查询，最后根据查询决定是否提交或者放弃。\n  如果步骤1的查询没有返回任何行，则不适合用FOR UPDATE方式来解决。\n  这种在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读。\n   实体化冲突\n 查询结果为空的话，可以人为引入一些可以加锁的对象。\n  比如会议室预订，构造一个时间-房间表，预订事务需要查询锁定对应的行。\n  这种方法称为实体化冲突（或物化冲突）。\n  有时实现起来比较困难，把控制并发机制降级为数据模型的思路不够优雅，不推荐使用。\n   串行化 #   可串行化隔离通常被认为最强的隔离级别。它保证事务可能会并发执行，但最终的结果与每次一个即串行执行的结果相同。\n 以下实现方式：\n实际串行执行 #   多线程并发在以前被认为是提升性能的关键，现在转向单线程执行，有两方面的进展促进重新作出思考：\n 内存越来越便宜，可以将整个活动数据集都加载到内存中。当事务所需的所有数据都在内存中时，事务执行的速度要比等待磁盘I/O快得多； OLTP事务通常执行很快，只产生少量的读写操作。运行时间较长的分析查询则通常是只读的，可以在一致性快照上运行，不需要运行在串行主循环里。    单线程执行有时可能会比支持并发的系统效率更高，尤其是可以避免锁开销。但是，其吞吐量上限是单个CPU核的吞吐量。为了充分利用单线程，相比于传统形式，事务也需要作出相应的调整。\n   采用存储过程封装事务\n 交互式事务：应用程序提交查询，读取结果，可能会根据前一个查询的结果来提交查询。请求与结果在应用层代码和数据库服务器之间来回交互。\n  交互式事务大量时间花费在应用程序与数据库之间的网络通信。如果不允许事务并发，而是一次处理一个，那么吞吐量会非常低数据库总是在等待应用提交下一个请求。在这种类型的数据库，需要能够同时处理多个事务。\n  采用单线程串行执行的系统往往不支持交互式的多语句事务。应用程序必须提交整个事务代码作为存储过程打包发送到数据库。\n   存储过程的优缺点\n 每家数据库厂商都有自己的存储过程语言，这些语言可能相当过时，缺乏常用的函数库； 在数据库运行代码难以管理； 数据库实例往往被多个应用服务器共享，数据库一个设计不好的存储过程要比同样低效的应用服务器代码带来更大的麻烦。   最新的存储过程已经放弃了PL / SQL，使用现有的通用编程语言。例如VoltDB使用Java或Groovy，Redis使用Lua。\n  存储过程与内存式数据存储使得单线程上执行所有事务变得可行。它们不需要等待I/O，避免加锁开销等复杂的并发控制机制，可以获得不错的吞吐量。\n   分区\n 串行执行所有事务使得并发控制变得简单，但是数据库吞吐量被限制在单机单个CPU核。只读事务可以在单独的快照上执行，但是对于高写入需求的应用程序，单线程事务处理很容易成为严重的瓶颈。\n  为了扩展到多个CPU核和多节点，可以对数据分区。VoltDB支持这种配置模式。为每个CPU核分配一个分区，则数据库的总体事务吞吐量可以到达与CPU核的数量成线性比例关系。\n  对于跨分区事务，数据库必须在涉及的所有分区之间协调事务。存储过程需要跨越所有分区加锁执行，以确保整个系统的可串行化，性能较低。\n  事务能否在单分区上执行很大程度上取决于应用层的数据结构。简单的键-值数据比较容易切分，而带有多个二级索引的数据则需要大量的跨区协调。\n   小结\n 满足一下约束条件时，串行执行事务可以实现串行隔离化：\n  事务必须简短而有效，否则一个缓慢的事务会影响到所有其他事务的执行性能； 仅限于活动集数据完全可以加载到内存的场景。有些很少访问的数据可能会被移动到磁盘，但万一但单线程事务需要访问它，会严重拖累性能； 写入吞吐量必须足够低，才能在单个CPU核上处理；否则就需要分区，最好没有跨分区事务； 跨分区事务虽然也可以支持，但是占比必须很小。    两阶段加锁 #   2PL 锁的强制性更高。多个事务可以同时读取同一个对象，但只要出现任何写操作，则必须加锁以独占访问：\n 事务A已经读取了某个对象，此时事务B想要写入该对象，那么B必须等到A提交或终止事务才能继续。确保B不会再事务A执行的过程中间去修改对象； 事务A已经修改了对象，此时事务B想要读取该对象，则B必须等到A提交或终止事务才能继续。对于2PL，不会出现读到旧值的情况。    因此2PL不仅在并发写操作间互斥，读取也会和修改互斥。快照级别隔离的口号“读写互不干扰”非常准确地点明了它和两阶段加锁的关键区别。另一方面，因为2PL提供了串行化，所以它可以防止前面讨论的所有竞争条件，包括更新丢失和写倾斜。\n   实现两阶段加锁\n 数据库的每个对象都有一个读写锁来隔离读写操作。即锁可以处于共享模式或独占模式。基本用撞如下：\n   如果事务要读取对象 ，必须先以共享模式获得锁；\n 可以有多个事务同时获得一个对象的共享锁，但是如果某个事务已经获得了对象的独占锁，则所有其他事务必须等待。\n   如果事务要修改对象，必须以独占模式获取锁；\n 不允许多个事务 同时持有良锁（包括共享或独占模式），换言之，如果对象上已被加锁， 则修改事务必须等待。\n   如果事务首先读取对象，然后尝试写入对象，则需要将共享锁升级为独占锁；\n 升级锁的流程等价于直接获得独占锁。\n   事务获得锁之后， 一直持有锁直到事务结束（包括提交或中止）。\n 这也是名字“两阶段”的来由，在第一阶段即事务执行之前要获取锁，第二阶段（即事务结束时）时释放锁。\n     两阶段加锁的性能\n 两阶段加锁的主要缺点：其事务吞吐量和查询响应时间相比于其他弱隔离级别下降非常多。\n   锁的获取和释放本身的开销 ；\n  其降低了事务的并发性 ；\n 两个并发事务如果试图做任何可能导致竞争条件的事情，其中一个必须等待对方完成。当一个事务还需要等待另一个事务时，那么最终的等待时间几乎是没有上限的。即使可以保证自己的事务足够简短、高效，但一旦出现多个事务同时访问同一对象，会形成一个等待队列，事务就必须等待队列前面所有其他事务完成之后才能继续。\n   基于加锁方式的读－提交隔离也可能发生死锁 。\n 在2PL下，取决于事务的访问模式，死锁可能变得更为频繁。因而导致另一个性能问题，即如果事务由于死锁而被强行中止，应用层就必须从头重试，假如死锁过于频繁，则最后的性能和效率必然大打折扣。\n     谓词锁\n 作用类似于之前描述的共享／独占锁，而区别在于，它并不属于某个特定的对象（ 如表的某一行），而是作用于满足某些搜索条件的所有查询对象。\n 例如：\nSELECT * FROM bookings WHERE room_id = 123 AND end_time \u0026gt; \u0026#39;2018-01-01 21:00\u0026#39; AND start_time \u0026lt; \u0026#39;2018-01-01 13:00\u0026#39;; 谓词锁会限制如下访问：\n  如果事务A想要读取某些搞足匹配条件的对象，例如采用 SELECT查询，它必须以共享模式获得查询条件的谓词锁；\n 如果另一个事务B正持有任何一个匹配对象的互斥锁，那么A必须等到B释放锁之后才能继续执行查询。\n   如果事务A想要插入、更新或删除任何对象，则必须首先检查所有旧值和新值是否与现有的任何谓词锁匹配（即冲突）。\n 如果事务B持有这样的谓词锁，那么A必须等到B完成提交（或中止）后才能继续。\n    谓词锁甚至可以保护数据库中那些尚不存在但可能马上会被插入的对象（幻读）。将两阶段加锁与谓词锁结合使用，数据库可以防止所有形式的写倾斜以及其他竞争条件，隔离变得真正可串行化。\n   索引区间锁\n 谓词锁性能不佳：如果活动事务中存在许多锁，那么检查匹配这些锁就变得非常耗时。因此，大多数使用2PL的数据库实际上实现的是索引区间锁（或者nextkey locking) , 本质上它是对谓词锁的简化或者近似。\n  简化谓词锁的方式是将其保护的对象扩大化 。例如，对于房间预订数据库，通常会在room_id列上创建索引：\n 数据库使用此索引查找123号房间的当前预订情况。数据库可以简单地将共享锁附加到此索引条目，表明事务已搜索了123号房间的所有时间段预订； 无论哪种方式，查询条件的近似值都附加到某个索引上； 如果另 一个事务想要插入、更新或删除同 一个房间和I或重叠时间段的预订，则肯定需要更新这些索引，一定就会与共享锁冲突，因此会自动处于等待状态直到共享锁释放。    这样就有效防止了写倾斜和幻读问题。\n  索引区间锁不像谓词锁那么精确（会锁定更大范围的对象，而超出了串行化所要求的部分），但由于开销低得多，可以认为是一种很好的折衷方案。\n  如果没有合适的索引可以施加区间锁，则数据库可以回退到对整个表施加共享锁。这种方式的性能肯定不好，它甚至会阻止所有其他事务的写操作，但的确可以保证安全性。\n   可串行化的快照隔离 #   可串行化的快照隔离 (Serializable Snapshot Isolation,ssl)提供了完整的可串行性保证，而性能相比于快照隔离损失很小。\n  SSI可用于单节点数据库 (PostgreSQL 9.1之后的可串行化隔离）或者分布式数据库（如FoundationDB采用了类似的算法）。\n   悲观与乐观的并发控制\n 两阶段加锁是一种典型的悲观并发控制机制。它基于这样的设计原则：如果某些操作可能出错（例如与其他并发事务发生了锁冲突），那么直接放弃，采用等待方式直到绝对安全。\n  可串行化的快照隔离则是一种乐观并发控制。在这种情况下，如果可能发生潜在冲突，事务会继续执行而不是中止，寄希望一切相安无事；而当事务提交时（只有可串行化的事务被允许提交），数据库会检查是否确实发生了冲突（即违反了隔离性原则），如果是的话，中止事务并接下来重试。\n  乐观并发控制其实是一个古老的想法, 关于其优点和缺点已经争论了很长时间。如果冲突很多，则性能不佳（许多事务试图访问相同的对象），大量的事务必须中止。如果系统已接近其最大吞吐量， 反复重试事务会使系统性能变得更差。\n  SSI基于快照隔离，也就是说，事务中的所有读取操作都是基于数据库的一致性快照。在快照隔离的基础上，SSI新增加了相关算法来检测写入之间的串行化冲突从而决定中止哪些事务。\n   基于过期的条件做决定\n 场景：事务首先查询某些数据，根据查询的结果来决定采取后续操作，例如修改数据。而在快照隔离情况下，数据可能在查询期间就已经被其他事务修改，导致原事务在提交时决策的依据信息已出现变化。\n  当应用程序执行查询时，数据库本身无法预知应用层逻辑如何使用这些查询结果。安全起见，数据库假定对查询结果（决策的前提条件）的任何变化都应使写事务失效。\n  换言之，查询与写事务之间可能存在因果依赖关系。为了提供可串行化的隔离，数据库必须检测事务是否会修改其他事务的查询结果，并在此情况下中止写事务。\n  数据库如何知道查询结果是否发生了改变，可以分以下两种情况：\n   检测是否读取了过期的MVCC对象\n  数据库需要跟踪那些由千MVCC可见性规则而被忽略的写操作。\n 当事务提交时，数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，如果是则必须中止当前事务。\n   为什么要等到提交\n  如果事务43是个只读事务，没有任何写倾斜风险，就不需要中止； 事务43读取数据库时，数据库还不知道事务是否稍后有任何写操作 ； 事务43提交时，有可能事务42发生了中止或者还处千未提交状态，因此读取的并非是过期值 。       检测写是否影响了之前的读\n 当另一个事务尝试修改时，它首先检查索引，从而确定是否最近存在一些读目标数据的其他事务。这个过程类似于在受影响的字段范围上获取写锁，但它并不会阻塞读取， 而是直到读事务提交时才进一步通知他们：所读到的数据现在已经发生了变化。\n   可串行化快照隔离的性能\n 与两阶段加锁相比，可串行化快照隔离的一大优点是事务不需要等待其他事务所持有的锁。这一点和快照隔离一样， 读写通常不会互相阻塞。这样的设计使得查询延迟更加稳定可预测。特别是， 在一致性快照上执行只读查询不需要任何锁，这对千读密集的负载非常有吸引力。\n  与串行执行相比，可串行化快照隔离可以突破单个CPU核的限制。FoundationDB将冲突检测分布在多台机器上，从而提高总体吞吐量。即使数据可能跨多台机器进行分区，事务也可以在多个分区上读、 写数据并保证可串行化隔离。\n  事务中止的比例会显著影响SSI的性能表现。例如，一个运行很长时间的事务，读取和写入了大量数据，因而产生冲突并中止的概率就会增大， 所以SSI要求读－写型事务要简短（而长时间执行的只读事务则没有此限制）。但总体讲，相比于两阶段加锁与串行执行，SSI更能容忍那些执行缓慢的事务。\n   "},{"id":17,"href":"/docs/elasticsearch/mds/3_search/","title":"搜索","section":"Elasticsearch","content":"基于词项和基于全文搜索 #  基于Term的查询 #   Term是表达语义的最小单位，在Elasticsearch中，Term查询，对输入不做分词。会将输入作为一个整体，在倒排索引中查找准确的词项，并且使用相关度算分公式，为每个包含该词项的文档进行相关度算分。\n  准确查询不需要算分，可以通过 Constant Score 将查询转换成一个Filtering，避免算分，并利用缓存，提高性能。\n   Constant Score\n{ \u0026#34;query\u0026#34;: { \u0026#34;constant_score\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;\u0026#34; } } } } }   一些TermLevelQuery\n Term Query（精确查询） Range Query（范围查询） Exists Query（存在查询） Prefix Query（前缀查询） Wildcard Query（通配符查询）    基于全文的查询 #   索引和搜索时都会进行分词，查询字符串先传递到一个合适的分词器，然后生成一个共查询的词项列表。\n查询的时候，会先对输入的查询进行分词，然后每个词项逐个进行底层的查询，最终将结果进行合并，并为每个文档生成一个算分。\n 如下，查 “Matrix reloaded”，会查到包括Matrix或者reload的所有结果。\n 一些全文Query  Match Query Match Phrase Query Query String Query    查询结果比较 #  假设有一条文档：{ \u0026ldquo;productID\u0026rdquo; : \u0026ldquo;XHDK-A-1293-#fJ3\u0026rdquo;,\u0026ldquo;desc\u0026rdquo;:\u0026ldquo;iPhone\u0026rdquo; }，desc字段是text类型，desc.keyword是keyword类型。\n{ \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;desc\u0026#34;: { // 查不到  \u0026#34;value\u0026#34;: \u0026#34;iPhone\u0026#34; // 可以查到  // \u0026#34;value\u0026#34;:\u0026#34;iphone\u0026#34;  } } } } { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;desc.keyword\u0026#34;: { // 可以查到  // \u0026#34;value\u0026#34;: \u0026#34;iPhone\u0026#34; // 查不到  \u0026#34;value\u0026#34;:\u0026#34;iphone\u0026#34; } } } } // 查询keyword类型字段时，就算使用match也不会分词 { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { // 可以查到  \u0026#34;desc.keyword\u0026#34;: \u0026#34;iPhone\u0026#34; // 查不到  \u0026#34;desc.keyword\u0026#34;:\u0026#34;iphone\u0026#34; } } } Query \u0026amp; Filtering #  ES中的查询分为：\n Query Context：相关性算分 Filter Context：不需要算分（yes or no），可以利用cache，获得更好的性能  Bool Query #   多条件查询可以使用bool查询。一个bool查询，是一个或者多个查询子句的组合，总共包括4种子句，其中2种会影响算分，2种不影响算分。\n    子语句 是否算分     must 必须匹配。贡献算分   should 选择性匹配。贡献算分   must_not Filter Context 查询子句，必须不能匹配   filter Filter Context 必须匹配，但是不贡献算分     另外，相关性并不只是全文本检索的专利。也适用于yes | no的子句，匹配的子句越多，相关性评分越高。如果多条查询子句被合并为一条复合查询语句，比如bool 查询，则每个查询子句计算得出的评分会被合并到总的相关性评分中。\n bool查询中：\n  子查询可以任意顺序出现\n  可以嵌套多个查询\n  改变权重\n// 同一层级下单竞争字段，具有相同的权重 // brown red quick dog有相同权重 POST /animals/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;brown\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;red\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;quick\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;dog\u0026#34; }} ] } } } // 通过嵌套bool查询，可以改变对算分的影响 // red和brown加起来，和上面的才有相同的权重 POST /animals/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;quick\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;dog\u0026#34; }}, { \u0026#34;bool\u0026#34;:{ \u0026#34;should\u0026#34;:[ { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;red\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;brown\u0026#34; }} ] } } ] } } }     如果bool查询中，没有must条件，should中必须至少满足一条查询\n  should 算分过程\n  查询should语句中的两个查询； 加和两个查询的评分； 乘以匹配语句的总数； 除以所有总语句数。     Boosting \u0026amp; Boosting Query #    Boosting\n// 通过boost调整算分 POST blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ {\u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;apple,ipad\u0026#34;, \u0026#34;boost\u0026#34;: 1.1 } }}, {\u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;apple,ipad\u0026#34;, \u0026#34;boost\u0026#34;:2 } }} ] } } }   Boosting Query\n// pie内容的数据往后排 POST news/_search { \u0026#34;query\u0026#34;: { \u0026#34;boosting\u0026#34;: { \u0026#34;positive\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;apple\u0026#34; } }, \u0026#34;negative\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;pie\u0026#34; } }, \u0026#34;negative_boost\u0026#34;: 0.5 } } }   Disjunction Max Query #   单字段多字符串查询\n POST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Brown fox\u0026#34; }}, { \u0026#34;match\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Brown fox\u0026#34; }} ] } } }  上面例子中，title与body相互竞争，不应该将分数简单叠加，而是应该找到单个最佳匹配字段的评分。\n  Disjunction Max Query是将任何与任一查询匹配的文档作为结果返回。采用字段上最匹配的评分最终评分返回。\n // 使用一个字段上的最高评分作为最终评分 POST blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;dis_max\u0026#34;: { \u0026#34;queries\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Brown fox\u0026#34; }}, { \u0026#34;match\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Brown fox\u0026#34; }} ] } } }  Tie Breaker是一个介于0到1之间的浮点数，0代表使用最佳匹配，1代表所有语句同样重要。\n通过Tie Breaker参数调整：\n 获得最佳匹配语句的评分； 将其他匹配语句的评分与tie_breaker相乘； 对以上评分求和并规范化。   MultiMatch #  单字符串多字段查询三种场景：\n  最佳字段（Best Fields）\n 当字段之间相互竞争，又相互关联。例如title 和body 这样的字段。评分来自最匹配字段。\n // Best Fields是默认类型，可以不用指定；Minimum should match等参数可以传递到生成的query中。 POST blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;best_fields\u0026#34;, \u0026#34;query\u0026#34;: \u0026#34;Quick pets\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;title\u0026#34;,\u0026#34;body\u0026#34;], \u0026#34;tie_breaker\u0026#34;: 0.2, \u0026#34;minimum_should_match\u0026#34;: \u0026#34;20%\u0026#34; } } }   多数字段（Most Fields）\n 处理英文内容时，一种常见的手段是，在主字段（English Analyzer），抽取词干，加入同义词，以匹配更多文档。相同的文本，加入子字段（Standard Analyzer），以提供更加精确的匹配。其他字段作为匹配文档提高相关度的信号。匹配字段越多越好。\n PUT /titles { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;english\u0026#34;, \u0026#34;fields\u0026#34;: {\u0026#34;std\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;,\u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;}} } } } } GET /titles/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;barking dogs\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;most_fields\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;title.std\u0026#34; ] } } }   混合字段（Cross Field）\n 对于某些实体，例如人名、地址、图书信息。需要在多个字段中确定信息，单个字段只能作为整体的一部分。希望在任何这些列出的字段中找到尽可能多的词。\n GET /titles/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;barking dogs road\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cross_fields\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;and\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34; ] } } }   Function Score Query #   可以在查询结束后，对每一个匹配的文档进行一系列的重新算分，根据新生成的分数进行排序。\n 提供了几种默认的计算分值的函数：\n Weight：为每一个文档设置一个简单而不被规范化的权重 Field Value Factor：使用该数值来修改_score，例如将\u0026quot;热度\u0026quot;和\u0026quot;点赞数\u0026quot;作为算分的参考要素 Randow Score：为每一个用户使用一个不同的，随机算分结果 衰减函数：以某个字段的值为标准，距离某个值越近，得分越高 Script Score：自定义脚本完全控制所需逻辑  // 按欢迎程度提升权重：搜索的评分作为排序的主要依据，同时votes多的靠前。 POST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;popularity\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;content\u0026#34; ] } }, // 新的算分 = 老的算分 * 投票数 // 票数为0或者票数很大的时候差异很大  \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;votes\u0026#34; } } } }   使用Modifier 平滑曲线\nPOST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;popularity\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;content\u0026#34; ] } }, // 新的算分 = 老的算分 * log（1 + 投票数） // 别的modifier：log、log2p、ln、ln1p、ln2p、square、sqrt、reciprocal  \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;votes\u0026#34;, \u0026#34;modifier\u0026#34;: \u0026#34;log1p\u0026#34; } } } }   引入Factor（曲线更平滑）\nPOST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;popularity\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;content\u0026#34; ] } }, // 新的算分 = 老的算分 * log（1 + factor * 投票数）  \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;votes\u0026#34;, \u0026#34;modifier\u0026#34;: \u0026#34;log1p\u0026#34; , \u0026#34;factor\u0026#34;: 0.1 } } } }   Boost Mode 和 Max Boost\n Boost Mode ： 1.Multiply：算分与函数值的乘积； 2.Sum：算分与函数值的和； 3.Min/ Max：算分与函数取 最小/最大值； 4.Replace：使用函数值取代算分。\nMax Boost 可以将算分控制在一个最大值。\n POST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;popularity\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;content\u0026#34; ] } }, \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;votes\u0026#34;, \u0026#34;modifier\u0026#34;: \u0026#34;log1p\u0026#34; , \u0026#34;factor\u0026#34;: 0.1 }, \u0026#34;boost_mode\u0026#34;: \u0026#34;sum\u0026#34;, \u0026#34;max_boost\u0026#34;: 3 } } }   一致性随机函数\nPOST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { // 不同seed值，返回结果算分不同  \u0026#34;random_score\u0026#34;: { \u0026#34;seed\u0026#34;: 911119 } } } }   Suggester #   现代的搜索引擎，一般提供Suggest as you type的功能。帮助用户在输入搜索过程中，进行自动补全或者纠错。通过协助用户输入更加精准的关键词，提高后续搜索阶段文档匹配的程度。\n  搜索引擎中类似的功能，在Elasticsearch 中是通过Suggester API实现的。 原理：将输入的文本分解为Token，然后在索引的字典里查找相似的Term 并返回。\n 根据不同的适用场景，Elasticsearch 设计了4中类别的 Suggester：\n Term \u0026amp; Phrase Suggester Complete \u0026amp; Context Suggester  搜索建议 #    Term Suggester\n Suggester 就是一种特殊类型的搜索。\n // 每个建议都包含了一个算分，相似性是通过 Levenshtein Edit Distance 的算法实现的。 // 核心思想就是一个词改动多少字符就可以和另外一个词一致。提供了很多可选参数来控制相似性的模糊程度。例如“max_edits” POST /articles/_search { \u0026#34;size\u0026#34;: 1, \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;lucen rock\u0026#34; } }, \u0026#34;suggest\u0026#34;: { \u0026#34;term-suggestion\u0026#34;: { // text 里是调用时候提供的文本，通常来自用户输入的内容  \u0026#34;text\u0026#34;: \u0026#34;lucen rock\u0026#34;, \u0026#34;term\u0026#34;: { // 当无法搜索到结果时（missing），返回建议的词  \u0026#34;suggest_mode\u0026#34;: \u0026#34;missing\u0026#34;, // 会到 指定的字段body 上搜索  \u0026#34;field\u0026#34;: \u0026#34;body\u0026#34;, \u0026#34;prefix_length\u0026#34;:0, \u0026#34;sort\u0026#34;: \u0026#34;frequency\u0026#34; } } } } Suggestion Mode：\n  Missing - 如果索引中已经存在，就不提供建议；\n  Popular - 推荐出现频率更加高的词；\n  Always - 无论是否存在，都提供建议。\n  Phrase Suggester\n Phrase Suggester 在 Term Suggester 上增加了一些额外的逻辑，例如一些参数：\n Suggest Mode：missing、popular； Max Errors：最多可以拼错的Terms 数； Confidence：限制返回结果数，默认为1。     POST /articles/_search { \u0026#34;suggest\u0026#34;: { \u0026#34;my-suggestion\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;lucne and elasticsear rock hello world \u0026#34;, \u0026#34;phrase\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;body\u0026#34;, \u0026#34;max_errors\u0026#34;:2, \u0026#34;confidence\u0026#34;:0, \u0026#34;direct_generator\u0026#34;:[{ \u0026#34;field\u0026#34;:\u0026#34;body\u0026#34;, \u0026#34;suggest_mode\u0026#34;:\u0026#34;always\u0026#34; }], \u0026#34;highlight\u0026#34;: { \u0026#34;pre_tag\u0026#34;: \u0026#34;\u0026lt;em\u0026gt;\u0026#34;, \u0026#34;post_tag\u0026#34;: \u0026#34;\u0026lt;/em\u0026gt;\u0026#34; } } } } }   自动补全和基于上下文提示 #   Completion Suggester 提供了“自动完成（Auto Complete）”的功能。用户每输入一个字符，就需要即时发送一个查询请求到后端查询匹配项； 对性能要求比较苛刻。Elasticsearch 采用了不同的数据结构，并非通过倒排索引来完成。而是将 Analyze 的数据编码成 FST 和索引 一起存放。FST 会被 ES整个加载进内存，速度很快； FST 只能用于前缀查找。\n 使用Completion Suggester 的一些步骤：\n  定义Mapping，使用“completion”type\nPUT articles { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;title_completion\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;completion\u0026#34; } } } }   索引数据\n  运行“suggest”查询，得到搜索建议\n// 会返回 elk 开头的数据 POST articles/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;suggest\u0026#34;: { \u0026#34;article-suggester\u0026#34;: { \u0026#34;prefix\u0026#34;: \u0026#34;elk \u0026#34;, \u0026#34;completion\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;title_completion\u0026#34; } } } }   Context Suggester #   Completion Suggester 的扩展，可以在搜索中加入更多的上下文信息，例如，输入“star”，\n 咖啡相关：建议“Starbucks”； 电影相关：“star wars”   两种类型的 Context：\n Category - 任意的字符串； Geo - 地理位置信息。  实现Context Suggester 的具体步骤：\n  定制一个Mapping\nPUT comments/_mapping { \u0026#34;properties\u0026#34;: { \u0026#34;comment_autocomplete\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;completion\u0026#34;, //  \u0026#34;contexts\u0026#34;:[{ \u0026#34;type\u0026#34;:\u0026#34;category\u0026#34;, \u0026#34;name\u0026#34;:\u0026#34;comment_category\u0026#34; }] } } }   索引数据，并且为每个文档加入Context 信息\n// 分类是电影 POST comments/_doc { \u0026#34;comment\u0026#34;:\u0026#34;I love the star war movies\u0026#34;, \u0026#34;comment_autocomplete\u0026#34;:{ \u0026#34;input\u0026#34;:[\u0026#34;star wars\u0026#34;], \u0026#34;contexts\u0026#34;:{ \u0026#34;comment_category\u0026#34;:\u0026#34;movies\u0026#34; } } } // 分类是咖啡 POST comments/_doc { \u0026#34;comment\u0026#34;:\u0026#34;Where can I find a Starbucks\u0026#34;, \u0026#34;comment_autocomplete\u0026#34;:{ \u0026#34;input\u0026#34;:[\u0026#34;starbucks\u0026#34;], \u0026#34;contexts\u0026#34;:{ \u0026#34;comment_category\u0026#34;:\u0026#34;coffee\u0026#34; } } }   结合Context 进行 Suggestion 查询\n// 会查出咖啡类型的数据 POST comments/_search { \u0026#34;suggest\u0026#34;: { \u0026#34;MY_SUGGESTION\u0026#34;: { \u0026#34;prefix\u0026#34;: \u0026#34;sta\u0026#34;, \u0026#34;completion\u0026#34;:{ \u0026#34;field\u0026#34;:\u0026#34;comment_autocomplete\u0026#34;, \u0026#34;contexts\u0026#34;:{ \u0026#34;comment_category\u0026#34;:\u0026#34;coffee\u0026#34; } } } } }   比较 #   精准度： Completion \u0026gt; Phrase \u0026gt; Term 召回率 Term \u0026gt; Phrase \u0026gt; Completion 性能 Completion \u0026gt; Phrase \u0026gt; Term  使用别名 #  # 可以添加过滤器 POST _aliases { \u0026#34;actions\u0026#34;: [ { \u0026#34;add\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;movies-2019\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;movies-lastest-highrate\u0026#34;, \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;rating\u0026#34;: { \u0026#34;gte\u0026#34;: 4 } } } } } ] } Search Templage #    新建一个Search Templage\nPOST _scripts/tmdb { \u0026#34;script\u0026#34;: { \u0026#34;lang\u0026#34;: \u0026#34;mustache\u0026#34;, \u0026#34;source\u0026#34;: { \u0026#34;_source\u0026#34;: [ \u0026#34;title\u0026#34; ], \u0026#34;size\u0026#34;: 20, \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;{{q}}\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;title\u0026#34;] } } } } }   查询Search Templage\nGET _scripts/tmdb   使用 Search Templage\nPOST titles/_search/template { \u0026#34;id\u0026#34;:\u0026#34;tmdb\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;q\u0026#34;: \u0026#34;barking\u0026#34; } }   配置跨集群搜索 #  水平扩展痛点 #   单集群 - 当水平扩展时，节点数不能无限增加，因为当集群的 meta 信息（节点，索引，集群状态）过多，会导致更新压力变大，单个Active Master 会成为性能瓶颈，导致整个集群无法正常工作。\n 早期版本，通过Tribe Node 可以实现多集群访问的需求，但还存在一定的问题：\n Tribe Node 会以 Client Node 的方式加入每个集群。集群中Master 节点的任务变更需要 Tribe Node 的回应才能继续； Tribe Node 不保存Cluster State 的信息，一旦重启，初始化很慢； 当多个集群存在索引重名的情况时，只能设置一种Prefer 规则。  Cross Cluster Search #   早期 Tribe Node 的方案 存在一定的问题，现在已被 Deprecated； Elasticsearch 5.3 引入了跨集群搜索的功能（Cross Cluster Search），推荐使用：\n 允许任何节点扮演 federated节点，以轻量的方式，将搜索请求进行代理； 不需要以 Client Node 的形式加入其它集群。    配置  //在每个集群上设置动态的设置 PUT _cluster/settings { \u0026#34;persistent\u0026#34;: { \u0026#34;cluster\u0026#34;: { \u0026#34;remote\u0026#34;: { \u0026#34;cluster0\u0026#34;: { \u0026#34;seeds\u0026#34;: [ \u0026#34;127.0.0.1:9300\u0026#34; ], \u0026#34;transport.ping_schedule\u0026#34;: \u0026#34;30s\u0026#34; }, \u0026#34;cluster1\u0026#34;: { \u0026#34;seeds\u0026#34;: [ \u0026#34;127.0.0.1:9301\u0026#34; ], \u0026#34;transport.compress\u0026#34;: true, \u0026#34;skip_unavailable\u0026#34;: true }, \u0026#34;cluster2\u0026#34;: { \u0026#34;seeds\u0026#34;: [ \u0026#34;127.0.0.1:9302\u0026#34; ] } } } } }  查询  // 在第一个集群搜索 GET /users,cluster1:users,cluster2:users/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gte\u0026#34;: 20, \u0026#34;lte\u0026#34;: 40 } } } } "},{"id":18,"href":"/docs/elasticsearch/","title":"Elasticsearch","section":"Docs","content":" 大部分内容总结自极客时间视频课  "},{"id":19,"href":"/docs/algorithm/mds/algorithm/","title":"算法","section":"数据结构和算法","content":"递归（recursion） #  public void recur(int level, int param) { // terminator  if (level \u0026gt; MAX_LEVEL) { // process result  return; } // process current logic  process(level, param); // drill down  recur( level: level + 1, newParam); // restore current status  }    题目 编号     爬楼梯 70   括号生成 22   翻转二叉树 226   验证二叉搜索树 98   二叉树的最大深度 104   二叉树的最小深度 111   二叉树的序列化与反序列化 297   二叉树的最近公共祖先 236   从前序与中序遍历序列构造二叉树 105   组合 77   全排列 46   全排列2 47     divide \u0026amp; conquer backtrace     题目 编号     Pow(x, y) 50   子集 78   多数元素 169   电话号码的字母组合 17   N皇后 51   二叉树的层次遍历 102   最小基因变化 433   括号生成 22   在每个树行中找最大值 515   单词接龙 127   单词接龙2 126   岛屿数量 200   扫雷游戏 529    搜索（search） #    dfs\nvisited = set() def dfs(node, visited): if node in visited: # terminator # already visited  return visited.add(node) # process current node here.  ... for next_node in node.children(): if next_node not in visited: dfs(next_node, visited) def DFS(self, tree): if tree.root is None: return [] visited, stack = [], [tree.root] while stack: node = stack.pop() visited.add(node) process (node) nodes = generate_related_nodes(node) stack.push(nodes) # other processing work   bfs\ndef BFS(graph, start, end): visited = set() queue = [] queue.append([start]) while queue: node = queue.pop() visited.add(node) process(node) nodes = generate_related_nodes(node) queue.push(nodes) # other processing work    A*\n  二分查找（binary search） #     题目 编号     X的平方根 69   有效的完全平方数 367   搜索旋转排序数组 33   搜索二维矩阵 74   寻找旋转排序数组的最小值 153    动态规划（dynamic programming） #     题目 编号     最大子序和 53    贪心（greedy） #     题目 编号     柠檬水找零 860   买卖股票的最佳时机2 122   分发饼干 455   模拟行走机器人 874   跳跃游戏 55   跳跃游戏2 45    "},{"id":20,"href":"/docs/distribute/mds/consistency/","title":"一致性与共识","section":"分布式数据系统","content":"一致性保证 #  可线性化 #  顺序保证 #  分布式事务与 共识 #  "},{"id":21,"href":"/docs/mysql/mds/1_index/","title":"索引","section":"MySQL","content":"索引的类型 #   索引的出现是为了提高数据查询的效率，就像书的目录一样。实现索引的方式也有很多种，MySQL有如下几种类型的索引。\n 哈希索引 #   哈希索引是基于哈希表这种数据结构的索引。\n   优点\n 新增、精确查询都很快，O(1)的时间复杂度。\n   缺点\n  无法用于排序和分组； 区间查询很慢。     适用场景：等值查询\n  全文索引 #   MyISAM存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。 查找条件使用MATCH AGAINST，而不是普通的WHERE。\n全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。\nInnoDB存储引擎在MySQL 5.6.4 版本中也开始支持全文索引。\n B+树索引 #  不同数据结构的出现，主要是为了解决不同场景，不同操作的效率问题。B+树是适合存在磁盘的数据结构，它有以下特点：\n  B+树的每个节点都是一页；\n 从磁盘读取数据的时候，并不是一条一条读的，而是读“一块”（好几条）数据到内存。在MySQL中，这“一块”的单位就是页，默认大小为16k。\n   B+树是N叉树，N取决于字段的大小和页的大小；\n 假设一棵二叉树高度为5，目标值在树的底部，那么在进行深度优先搜索过程中，就需要经过5个节点。对于存储在磁盘的B+树来说，经过5个节点就意味着要查询5次磁盘，是比较耗时的操作。如果这棵树的高度低一些，就意味着可以少进行几次查询磁盘的操作。\n  同样一棵树，每个节点的子节点（扇出）越多，那么它的树高也越低。所以B+树是N叉树的结构，是更适合磁盘的数据结构。\n  以整数（bigint）字段索引为例，一个key为8B，一个引用约为6B，所以一条数据的索引占据空间约为14B，一页可以存：16K/14B ≈ 1170 条数据的索引，也就是说，此时N = 1170，是1170叉树。\n   B+树的非叶子节点存key（索引字段的值）和其它页的引用，叶子节点存全部数据；\n 假想如果在非叶子节点也存全部数据（一般来说大小远超6B）的话，那么每页可以存的索引条数就会变少，也就是说每个节点的子节点会变少，进而导致树的高度变大。\n   B+树的每个节点中的key都是按照顺序排列的。\n 在每个页查找的时候，可以使用二分法查找。\n ​\n  在InnoDB中，表都是根据主键顺序，以索引（B+树）的形式存放的，这种存储方式称为索引组织表。 根据索引类型，分为两种：\n 主键索引：叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）； 非主键索引：叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。  二者区别：\n 主键查询方式，则只需要搜索 ID 这棵 B+ 树； 普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。 基于非主键索引的查询需要多扫描一棵索引树。因此，在应用中应该尽量使用主键查询。  维护 #   B+树为了维护索引的有序性，在插入新值的时候需要做必要的维护。\n 根据插入的类型，可以分为几种：\n 直接在后面插入； 插在中间，挪动后面的数据； 插入时数据满了，会造成页分裂，性能受影响，空间利用率降低； 合并：当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并，合并的过程，可以认为是分裂的逆过程。  对于以上步骤，我们可以想到：\n  为什么建表语句中最好使用自增主键？\n 在自增主键的模式下，每次都是递增的值，可以让索引的维护，每次都是追加操作，不会挪动其他记录，避免了页分裂的情况。\n  如果使用业务逻辑字段做主键，往往不容易保证有序插入，写数据成本会变高。\n除了性能方面，从存储空间的角度来看，如果业务字段的长度比较大（例如身份证号），使用业务字段作为主键，普通索引的叶子节点会变大，会使普通索引占用更多空间。\n   哪些场景适合业务字段作为主键？\n 只有一个索引； 该索引必须是唯一索引。   典型的KV场景。\n   重建索引\n 索引可能因为页分裂、删除的原因，导致数据页有空洞，重建索引可以把数据按顺序插入，让索引更紧凑更省空间。\n   重建主键索引\n  alter table T engine=InnoDB 使用优化 #  create table T ( ID int primary key, k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT \u0026#39;\u0026#39;, index k(k))engine=InnoDB; insert into T values(100,1, \u0026#39;aa\u0026#39;),(200,2,\u0026#39;bb\u0026#39;),(300,3,\u0026#39;cc\u0026#39;),(500,5,\u0026#39;ee\u0026#39;),(600,6,\u0026#39;ff\u0026#39;),(700,7,\u0026#39;gg\u0026#39;); 回表 #  select ID from T where k between 3 and 5 查询步骤：\n 在索引k上查询到k = 3的记录，得到ID = 300； 在主键索引上查询到ID = 300对应的记录； 在索引k上查询到k = 5的记录，得到ID = 500； 在主键索引上查询到ID = 500对应的记录； 在索引k上未查询到k = 6的记录，不满足条件，循环结束。   在这个过程中，回到主键索引查询的过程，称为回表。\n 覆盖索引 #  select ID from T where k between 3 and 5  我们知道在普通索引中，叶子节点存的是主键（ID），而这条SQL语句只查询ID，因此不需要再进行回表操作，索引已经覆盖了我们的查询需求，这种情况叫做覆盖索引。\n  可以想到，对于一些高频的，请求部分字段的查询，我们可以对这些字段创建一个联合索引，提升查询效率。\n 最左前缀原则 #   最左前缀可以是联合作引的最左N个字段，也可以是字符串索引的最左M个字符。\n 如何安排联合索引字段顺序：\n 如果通过调整顺序，可以少维护一个索引，这个顺序可以优先考虑； 如果既有联合查询（a,b），又有单个查询(a) ，(b)，这时候不得不维护另外一个索引，此时考虑的原则是空间，选择字段小的作为单独索引。   a小的话索引就是：(b,a)、(a)；反之则是：(a,b)、(b)。\n 索引下推 #  (name, age)为联合索引 mysql\u0026gt; select * from tuser where name like \u0026#39;张%\u0026#39; and age=10 and ismale=1;  没有索引下推优化时，会按照顺序把name第一个字为张的记录，一条条去回表；有了索引下推优化之后，会再根据age的值判断，如果不为10，则直接跳过，否则再去回表。\n  MySQL5.6之前还没有索引下推的优化。\n 使用问题 #  唯一索引和普通索引的区别 #   查询；  select id from T where k=5  普通索引：找到第一个满足条件的记录会继续查询，直到遇到第一个不满足条件的记录； 唯一索引：找到第一个满足条件的记录后会停止检索； 对比来说，性能几乎没有差别。    InnoDB每次都是读一页的数据，相同条件的数据大概率在同一页内，找到下一条记录的代价，只是一次指针寻找和一次计算； 如果恰好不在同一页，但从平均性能差异来看，可以忽略不计。    更新，记录所在的页在内存中：  insert into T values (4, 400)  普通索引：找到3和5之间的位置，直接插入； 唯一索引：找到3和5之间的位置，判断没有冲突后插入。   相比较来说，唯一索引会耗费微小的CPU时间。\n  更新，记录所在的页在不内存中：   普通索引：将更新记录在change buffer就可以了； 唯一索引：需要将数据页读入内存，判断到没有冲突后插入这个值。   将数据从磁盘读入内存涉及到IO随机访问，是数据库成本最高的操作之一。使用change buffer没有这个操作，对更新性能提升很多。\n  change buffer；   如果数据在内存， 就更新内存； 如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了； 在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。   change buffer是可持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。\n 将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge：\n 访问这个数据页会触发merge； 系统后台线程会定期merge； 数据库正常关闭的过程中，也会merge。  为什么使用change buffer：\n 减少读磁盘，语句的执行速度得到明显的提升； 数据读入内存会占用buffer pool，使用change buffer避免占用内存，提高内存使用率。  使用change buffer的限制：\n 普通索引可以使用，因为唯一索引需要判断是否违反唯一性约束； 数据页不在内存可以使用，因为数据页在内存的话，直接更新内存会更快； change buffer用的是buffer pool的内存，可以通过参数innodb_change_buffer_max_size调整。  change buffer适合写多读少的系统，例如账单类、日志类系统。\n merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。\n  如果一个系统更新后马上查询，会导致频繁触发merge，随机IO的次数不会得到减少，同时增加了change buffer维护的代价，得不偿失。\n  change buffer 和 redo log：   change buffer 也会写到redo log中； 两者比较：   change buffer节省的是随机读磁盘的IO消耗；redo log节省了随机写磁盘的IO消耗。\n  如何选择。   尽量使用普通索引； 如果更新后面会经常伴随查询，最好关闭change buffer。   在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。\n 如何给字符串加索引 #  两种方式：\n 不指定前缀长度，索引会包含整个字符串； 定义字符串的一部分作为索引。   前缀索引优点：节省空间。 前缀索引缺点：   需要额外关注字段的区分度； 可能损失区分度； 无法使用覆盖索引。   如何确定前缀索引的长度：关注区分度，区分度越高越好。使用如下方法确认长度：  mysql\u0026gt; select count(distinct email) as L from SUser; mysql\u0026gt; select count(distinct left(email,4)）as L4, count(distinct left(email,5)）as L5, count(distinct left(email,6)）as L6, count(distinct left(email,7)）as L7, from SUser;  使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。\n  字段前面区分度不高，如何使用前缀索引：   倒序存储：使用最后几位作为索引；  查询时需要使用reverse函数。 mysql\u0026gt; select field_list from t where id_card = reverse(\u0026#39;input_id_cartring\u0026#39;); 使用hash字段，增加一个整数字段作为hash值字段，同时在这个字段添加索引；  查询时也要加上本字段条件，因为hash值可能因为哈希冲突而一致。 mysql\u0026gt; select field_list from t where id_card_crc=crc32(\u0026#39;input_id_card_string\u0026#39;) and id_card=\u0026#39;input_id_card_string\u0026#39; 两种方式比较：    占用额外空间：倒序存储不会占用额外空间；hash字段方法会增加一个字段，从而要额外多需要4个字节的空间。然而一般来说，倒序存储时4个字节长度是不够的，所以两者在此方面差不多； CPU消耗：倒序需要调用reverse函数；hash字段需要调用crc32函数。reverse函数相比于crc32函数来说消耗CPU资源会更小一些； 查询效率：倒序使用的还是前缀索引，因此可能扫描多行；hash字段虽然可能有冲突，但概率较小，hash的效率更稳定一些。   为什么会选错索引 #   统计信息错误导致选错索引；   采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。 数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。\n  innodb_stats_persistent 参数： 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10； 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。\n  analyze table t 命令，可以用来重新统计索引信息。\n  索引选择异常如何处理：   force index； 修改SQL语句，引导MySQL使用我们期望的索引； 新建一个更合适的索引。  为什么有时候不走索引 #   条件字段函数操作；   如果对字段做了函数计算，就用不上索引了，这是MySQL的规定。 对字段进行函数操作，可能会破坏索引值的有序性，因此优化器放弃走索引树搜索。\n  隐式转换类型；   在MySQL的转换规则：如果字符串和数字比较，会将字符串转成数字。\n mysql\u0026gt; select * from tradelog where tradeid=110717; tradeid字段类型为varchar，因此，上面的SQL语句相当于：\nmysql\u0026gt; select * from tradelog where CAST(tradid AS signed int) = 110717; 对条件字段进行了函数操作，因此优化器弃走索引树搜索。\n 隐式字符编码转换。  mysql\u0026gt; select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/ 会先从tradelog查询id = 2的数据，再根据id = 2的这行数据中的tradeid字段，查询trade_detail 表。因此tradelog 是驱动表，trade_detail 是被驱动表。\n假设tradelog的字符集是utf8mb4，trade_detail的字符集是utf-8，那么在查询trade_detail时不会使用索引。 因为此时查询trade_detail的语句等价于：\nselect * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; 此时条件字段使用了函数。\n除了字符集问题，在连接过程中，只要被驱动表的索引字段加了函数操作，都会导致对被驱动表全表扫描。\n解决：\n 把trade_detail的字符集改为utf8mb4； 换一种写法：  mysql\u0026gt; select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; "},{"id":22,"href":"/docs/elasticsearch/mds/4_aggs/","title":"聚合","section":"Elasticsearch","content":"聚合语法 #  { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { // 与query同级的关键词  \u0026#34;\u0026lt;aggs_name\u0026gt;\u0026#34;: { // 自定义的聚合名字  \u0026#34;\u0026lt;aggs_type\u0026gt;\u0026#34;: { // 聚合的定义：不同的Type + Body  \u0026lt;aggs_body\u0026gt; }, \u0026#34;aggs\u0026#34;: {} // 子聚合查询  }, \u0026#34;\u0026lt;aggs_name_2\u0026gt;\u0026#34; : {} // 可以包含多个同级的聚合查询  } } Metric #   一些系列的统计方法，会基于数据集计算结果，除了支持在字段上进行计算，同样也支持在脚本（painless script）产生的结果之上进行计算，类比SQL中的max、min等函数。\n   单值分析：只输出一个分析结果\n   aggs_type 含义     min 最小值   max 最大值   avg 平均值   sum 求和   cardinality 去重求数量，相当于distinct count      多值分析\n   aggs_type 含义     stats 输出最低、最高、平均、求和、count的值   extended stats 多了平方和、标准差等统计值   percentile 百分位数   percentile rank 百分位排比   top hits 前几条数据      Bucket #   一组满足条件的文档，类比SQL中的Group By。\n   Terms\n 支持嵌套，嵌套后可输出 sum() group by类型聚合结果。\n 注意：keyword 类型字段默认支持doc_values；text 类型字段需要在Mappings 中开启如下配置\n\u0026#34;fielddata\u0026#34;: true 才能进行Terms Aggregation，会按照分词后的结果进行分桶。\n  优化Terms 性能\n在keyword字段上，打开eager_global_ordinals参数打开，每当有新的数据写入，term会加载到cache中。\n适用场景：1. 聚合分析经常发生；2.索引不断有文档写入。\n  排序\n指定 order，按照count 和 key进行排序。默认情况，按照count降序排列；指定size，就能返回相应的桶。\n    数字类型\n   aggs_type 含义     range 自定义数据范围作为桶，可以自定义key   Date range 日期范围   histogram 直方图   Date histogram 日期直方图      Pipeline #   对其他的聚合结果进行二次聚合，通过bucket_path 关键字指定路径。Pipeline 的分析结果会输出到原结果中，根据位置的不同，分为Sibling和Parent两类。\n   Sibling - 结果和现有分析结果同级\n   type 含义     min_bucket 最小的桶的值   max_bucket 最大的桶的值   avg_bucket 桶的值的平均数   stats_bucket 桶的值的统计值   percentiles_bucket 桶的值的百分位数      Parent - 结果内嵌到现有的聚合分析结果中\n   type 含义     dervative 求导   cumultive sum 累计求和   moving window 滑动窗口      作用范围 #   默认作用范围是 query 的查询结果集，同时支持以下方式改变作用范围：\n   Filter\n 只过滤聚合的结果集，不过滤query 的结果集。\n   Post Filter\n 只过滤 query 的结果集，不过滤聚合的结果集。\n  性能考量：post_filter会在查询之后才会被执行，因此会失去过滤在性能上帮助(比如缓存)。因此post_filter应该只和聚合一起使用，并且仅当你使用了不同的过滤条件时。    Global\n 全局聚合，不受 query 作用域的影响。\n   聚合原理 #    Min聚合分析执行流程\n  Terms聚合分析的执行流程\n  Terms Aggregation的特殊返回值\n doc_count_error_upper_bound：被遗漏的term分桶，包含的文档，可能有最大值；\n  sum_other_doc_count：除了返回结果 bucket 的terms 以外，其他terms 的文档总数（总数 - 返回的总数）。\n   当 Terms的 size为3\n  Terms 不正确demo\n Top3应该是A(12)、B(6)、D(6)。\n     解决Terms 不准的问题\n  不准的原因\n数据分散在多个分片上，Coordinating Node 无法获取数据全貌。\n  解决方案\n  当数据量不大时，设置Primary Shard 为1，实现准确性；\n  在分布式数据上，设置shard_size参数，提高精确度。\n 原理：每次从Shard上额外多获取数据，提升准确率。\n     shard_size 设定\n 调整shard_size 大小，降低doc_count_error_upper_bound来提升准确度（增加整体计算量，提高了准确度，但会降低相应时间）； shard Size 默认大小：shard size = size * 1.5 + 10      "},{"id":23,"href":"/docs/mysql/mds/lock/","title":"锁","section":"MySQL","content":"全局锁 #  对整个数据库加读锁：\nFlush tables with read lock (FTWRL) 使用这个命令之后，数据库会处于只读状态，其它线程以下这些操作会被阻塞：\n 数据更新语句（数据的增删改查）； 数据定义语句（包括建表、修改表结构等）； 更新类事务的提交语句。    使用场景；\n全库逻辑备份，也就是对整个库select出来成文本。\n  使用风险；\n   如果在主库使用，期间都无法更新，业务都要停摆； 如果在从库使用，期间无法同步从主库传过来的binlog，导致主从不一致。   备份数据时加锁的必要性； 不加锁的话，备份所得到的库不是一个逻辑时间点，无法保证数据的一致性。   比如在极客时间买课的场景，有课程表和余额表。 假设逻辑是先扣减余额，再增加课程。 备份从库的过程中，如果先同步了余额表，在同步课程表之前：用户买了一门课，此时主库的余额表-1，主库的课程表+1。 这之后从库同步了课程表，这时从库的余额表就与主库不一致了。从库的角度来看，用户没扣除余额，却增加了课程。\n  官方自带逻辑备份工具：mysqldump；   当mysqldump使用参数-single-transaction的时候，导数据之前会启动一个事务，确保拿到一致性视图。由于MVCC的支持，这个过程是可以更新的。\n  有的存储引擎（比如MyIsAM）不支持事务，没有一致性读，这个时候就只能使用FTWRL了。\n  只读配置：set global readonly=true。  全库只读还可以通过这个配置来实现，但一般我们不使用，原因如下：\n 异常处理机制的差异：执行FTWRL命令发生异常后，会自动释放全局锁，数据库会回到可更新的状态；如果是使用set global readonly=true的方式，发生异常后数据库仍然处于只读状态； 有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。  表级锁 #  表锁 #  表锁的语法：\n## 加锁 lock tables … read/write ## 主动解锁 unlock tables 在客户端断开连接时，会主动释放锁。 loack tables除了限定别的线程的读写外，也限定了本线程接下来的操作对象：\n 如果某个线程A执行lock tables t1 read, t2 write;这个语句，则其他线程写t1，读写t2的操作都会被阻塞； 线程A在执行unlock tables之前，也只能执行读t1，读写t2的操作。连写t1都不允许，自然也不能访问其他表。   没有出现更细粒度的锁的时候，表锁是最常用处理并发的方式。\n 元数据锁（meta data lock，MDL） #  MDL不需要显示使用，在访问一个表的时候会被自动加上。\n MDL的作用； 保证读写的正确性。   比如，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。\n 在MySQL 5.5版本引入了MDL，当对一个表做增删改查的时候，加MDL读锁；对表结构做变更操作的时候，要加MDL写锁：\n 读锁之前不互斥，因此多个线程可以对同一张表增删改查； 读写锁之间、写锁之间是互斥的，保证变更表结构的操作是安全的。如果有两个线程同时给一张表加字段，其中一个要等到另一个执行完才能开始执行。    MDL可能引发的问题；\n  图上分别为会话A、B、C、D。 A、B执行的时候，加了MDL读锁；C执行的时候，加了MDL写锁；到了D执行的时候，需要加MDL读锁，但是C已经加了MDL写锁，MDL读写锁是互斥的，所以会话D会被阻塞。这个时候如果查询频繁的话，数据库的线程会很快爆满。\n 事务中的MDL锁，在语句开始执行时申请，但是语句结束不会马上释放，而会等到整个事务提交后再释放。\n  安全地给小表加字段。  其实可以看出来，如果上面的会话A、B很快就结束了，也不会导致后面的问题。所以根本原因是长事务导致。解决长事务：\n 在 MySQL 的 information_schema 库的 innodb_trx 表中，可以查到当前执行的事务。如果要做DDL的表恰好有长事务在执行，考虑暂停DDL，或者kill掉长事务； 如果有这样的场景：需要执行DDL的表是一个热点表，数据量不大，但请求频繁，而又不得不加一个字段：这种时候kill可能未必好使，因为新的请求马上就来了。比较理想的机制是在alter table语句设定等待时间，如果能在等待时间内拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后重复这个过程。   MriaDB已经合并了AliSQL的这个功能，所以这两个开源分支目前都支持DDL NOWAIT/WAIT n这个语法。\n 行锁 #    两阶段锁协议；\n在InnoDB事务中，行锁是需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束的时候才释放。\n  如何更好地使用；\n如果事务中需要锁多个行，把最可能造成锁冲突、最可能影响并发的锁尽量往后放。\n  死锁；\n  出现死锁后的解决策略：\n   直接进入等待，知道超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置；   innodb_lock_wait_timeout默认值是50s，意味着如果出现死锁，第一个被锁住的线程要过50s才会超时退出，然后其他线程才能继续执行。50s对于一般的服务来说都太久了，无法接受。\n 对于参数innodb_lock_wait_timeout的设置比较难把控，太大的话业务无法接受；太小的话，在正常的锁等待场景下会造成误伤。所以使用下面的策略更合适。\n发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。通过参数innodb_deadlock_detect设置，on表示开启。   死锁检测会造成额外负担：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。\n  比如：新来的线程F，被锁了之后要检查锁住F的线程（假设为D）是否被锁，如果没有被锁，则没有造成死锁，如果被锁了，那要继续看锁住D的是谁，如果是F，那么肯定死锁了，如果不是F（假设是B），那么又要判断锁住B的是谁，一直走直到发现线程没有被锁或被F锁住才会终止。\n  所有事务都更新同一行的场景。   每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度为O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作是100万这个量级（1000个线程，每个都要判断其他999个线程）。虽然最终检测没有死锁，但是检测过程中会消耗大量CPU资源。导致CPU利用率很高，但是每秒执行不了几个事务。\n 解决：\n 如果确保业务不会出现死锁，可以临时把死锁检测关掉； 有检测的时候会回滚，业务重试后就没问题了，是业务无损的；关掉之后可能出现大量的超时，对业务是有损额。 控制并发度。 最好不在客户端实现，因为客户端可能有很多； 可以考虑中间件； 可以考虑修改MySQL源码，对于相同行的更新，在进入引擎之前排队； 从设计上优化：将一行的逻辑改成多行来减少锁冲突。   比如影院的余额可以设计为10条记录。但是在其他方面要考虑周全，比如算余额是10条记录的总和；扣减余额时要考虑一条是0的情况。\n 间隙锁 #   间隙锁的出现，主要是为了解决幻读。\n 幻读 #  幻读是指，一个失误在前后两次查询同一个范围时，后一次查询看到了前一次查询没有看到的行。\n 在可重复读隔离界级别下，普通的查询时快照读，是不会看到别的事务插入的数据的。因此幻读在 当前读 下才会出现； 幻读仅专指 新插入的行。  加锁时只对一行加锁 #   对加锁语义的破坏； 比如，select * from t where c = 5 for update，假设这条数据的id = 1；如果在另一个事务中我先把id = 0的数据，c字段更新为5，再对id = 0的这条数据，更新其他字段，就破坏了c = 5数据加锁的语义。 数据不一致； 比如，select * from t where c = 5 for update；我在另一个事务中，插入了一条c = 5的数据，但是这个执行插入的事务早提交，第一个事务在在第二个事务提交后，又执行了对c字段更新的语句，会导致binlog有问题。 幻读问题。  间隙锁 #  间隙锁，锁的就是两个值之间的空隙。 当你执行 select * from t where c=5 for update 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。\n  间隙锁之间不存在冲突关系； 跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。\n  间隙锁导致的死锁。\n  不使用间隙锁 #  RC隔离级别 + row格式binlog\n加锁的思考 #  加锁其实是锁索引，在此基础上思考。\nselect * from t where c = 5 for update  字段c有索引，且有c=5这条记录； RR：会有临键锁，也就是锁5周围的间隙以及5这条记录；如果是唯一索引，只会锁5这条记录。   普通索引，为了保证没有5这条记录再插入，所以要看住5周围不能有数据插入，比如5的前面是3，要锁住(3, 5]这个范围，因为这个范围内，都可能再插入新的c=5的记录；如果是唯一索引，只锁行就可以了，因为唯一的限制，不可能再出现c=5的新纪录。\n 字段c有索引，且没有c=5这条记录； RR：会有间隙锁。   普通索引，为了保证没有5这条记录再插入，所以要看住5周围不能有数据插入，比如5的前面是3，后面是7，要锁住的范围就是(3, 7)，因为这个范围内，都可能再插入新的c=5的记录；唯一索引仍然只会锁一行。\n 字段c没有索引，且有c=5这条记录； RR：锁全表。   没有索引，意味着可能会在主键树的任意位置，所以要锁全表。\n 字段c没有索引，且没有c=5这条记录；   不会加锁。\n 加锁规则 #   原则1：加锁的基本单位是next-key lock； 原则2：查找过程中访问到的对象才会加锁； 优化1：索引上的等值查询，给唯一索引加锁时，next-key lock会退化为行锁； 优化2：索引上的等值查询，向右遍历且最后一个值不满足等值条件时，next-key lock退化为间隙锁； 唯一索引上的范围查找，会访问到不满足条件的第一个值为止。  "},{"id":24,"href":"/docs/elasticsearch/mds/5_model_design/","title":"数据建模","section":"Elasticsearch","content":"反范式化设计 #  关系型数据库范式化设计 #   1NF - 消除 非主属性 对键的 部分函数依赖； 2NF - 消除 非主要属性 对键的 传递函数依赖； 3NF - 消除 主属性 对键的 传递函数依赖； BCNF - 主属性 不依赖于 主属性。   范式化设计（Normalization）的主要目标是“减少”不必要的更新；副作用：一个完全范式化设计的数据库会经常面临“查询缓慢”的问题，因为数据库越范式化，就需要Join 越多表。\n范式化节省了存储空间，但是存储空间却越来越便宜；范式化简化了更新，但是数据“读”操作可能更频繁。\n Denormailzation #   反范式化设计，数据“Flattening”，不使用关联关系，而是在文档中保存冗余的数据拷贝。\n   优点：无需处理 Joins 操作，数据读取性能好；\n Elasticsearch 通过压缩_source字段，减少磁盘空间开销。\n   缺点：不适合在数据频繁修改的场景。例如，一条数据（用户名）的改动，可能会引起很多数据的更新。\n  处理关联关系 #   关系型数据库，一般会考虑Normalize数据；在Elasticsearch，往往考虑Denormalize 数据；Denormalize 的好处：读的速度变快/无需表连接/ 无需行锁等。\n  对象类型 嵌套对象（Nested Object） 父子关联关系（Parent/Child） 应用端关联  对象类型数组查询问题 #  存储时，内部对象的边界没有考虑在内，JSON 格式被处理成扁平式键值对的结构，对多个字段查询时，可能会导致意外结果。\n{ \u0026#34;title\u0026#34;:\u0026#34;Speed\u0026#34;, \u0026#34;actors\u0026#34;:[ { \u0026#34;first_name\u0026#34;:\u0026#34;Keanu\u0026#34;, \u0026#34;last_name\u0026#34;:\u0026#34;Reeves\u0026#34; }, { \u0026#34;first_name\u0026#34;:\u0026#34;Dennis\u0026#34;, \u0026#34;last_name\u0026#34;:\u0026#34;Hopper\u0026#34; } ] } // 可以查询到上面的结果 { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ {\u0026#34;match\u0026#34;: {\u0026#34;actors.first_name\u0026#34;: \u0026#34;Keanu\u0026#34;}}, {\u0026#34;match\u0026#34;: {\u0026#34;actors.last_name\u0026#34;: \u0026#34;Hopper\u0026#34;}} ] } } } // 内部实际存储 { \u0026#34;actors.first_name\u0026#34; : [\u0026#34;Keanu\u0026#34;, \u0026#34;Dennis\u0026#34;], \u0026#34;actors.last_name\u0026#34; : [\u0026#34;Reeves\u0026#34;, \u0026#34;Hopper\u0026#34;] } Nested #   Nested数据类型：允许对象数组中的对象被独立索引；使用nested 和 properties 关键字，将所有actors 索引到多个分隔的文档；在内部，Nested 文档会被保存在两个 Lucene 文档中，在查询时做 join处理。\n // mapping定义 \u0026#34;properties\u0026#34; : { \u0026#34;actors\u0026#34; : { \u0026#34;type\u0026#34;: \u0026#34;nested\u0026#34;, \u0026#34;properties\u0026#34; : { \u0026#34;first_name\u0026#34; : {\u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;}, \u0026#34;last_name\u0026#34; : {\u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;} }} } // 嵌套查询 { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ {\u0026#34;match\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Speed\u0026#34;}}, { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;actors\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ {\u0026#34;match\u0026#34;: { \u0026#34;actors.first_name\u0026#34;: \u0026#34;Keanu\u0026#34; }}, {\u0026#34;match\u0026#34;: { \u0026#34;actors.last_name\u0026#34;: \u0026#34;Hopper\u0026#34;} }]}}}}]}}} // 聚合查询 { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;actors\u0026#34;: { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;actors\u0026#34; }, \u0026#34;aggs\u0026#34;: { \u0026#34;actor_name\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;actors.first_name\u0026#34;, \u0026#34;size\u0026#34;: 10}}}}}} Parent/Child #   对象 和 Nested 对象的局限性：每次更新，需要重新索引整个对象（包括根对象和嵌套对象）。\n  ES 提供了类似关系型数据库中 Join的实现。使用Join 数据类型实现，可以通过维护Parent/ Child 的关系，从而分离两个对象。\n父文档和子文档是两个独立的文档：更新父文档无需重新索引子文档。子文档被添加，更新或者删除也不会影响到父文档和其他的子文档。\n   定义父子关系：\n 父文档和子文档必须存在相同的分片上，确保查询join的性能；当指定子文档的时候，必须指定其对应父文档id。\n   设置索引的Mapping\nPUT my_blogs { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;blog_comments_relation\u0026#34;: { // 指明join类型  \u0026#34;type\u0026#34;: \u0026#34;join\u0026#34;, // 声明Parent/Child关系  \u0026#34;relations\u0026#34;: { // blog-\u0026gt;Parent名称  // comment-\u0026gt;Child名称  \u0026#34;blog\u0026#34;: \u0026#34;comment\u0026#34; } }, \u0026#34;content\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } }   索引父文档\n// blog1-\u0026gt;父文档id PUT my_blogs/_doc/blog1 { \u0026#34;title\u0026#34;:\u0026#34;Learning Elasticsearch\u0026#34;, \u0026#34;content\u0026#34;:\u0026#34;learning ELK @ geektime\u0026#34;, // 声明文档类型是父文档  \u0026#34;blog_comments_relation\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;blog\u0026#34; } }   索引子文档\n// comment1-\u0026gt;子文档id // routing=blog1，确保和父文档索引到相同分片 PUT my_blogs/_doc/comment1?routing=blog1 { \u0026#34;comment\u0026#34;:\u0026#34;I am learning ELK\u0026#34;, \u0026#34;username\u0026#34;:\u0026#34;Jack\u0026#34;, \u0026#34;blog_comments_relation\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;comment\u0026#34;, // 父文档id  \u0026#34;parent\u0026#34;:\u0026#34;blog1\u0026#34; } }   按需查询文档\n// 查询所有（父子文档都会返回） POST my_blogs/_search {} // Parent Id 查询（返回子文档） POST my_blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;parent_id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;comment\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;blog2\u0026#34; } } } // Has Child 查询,返回父文档 POST my_blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;has_child\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;comment\u0026#34;, \u0026#34;query\u0026#34; : { \u0026#34;match\u0026#34;: { \u0026#34;username\u0026#34; : \u0026#34;Jack\u0026#34; } } } } } // Has Parent 查询，返回相关的子文档 POST my_blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;has_parent\u0026#34;: { \u0026#34;parent_type\u0026#34;: \u0026#34;blog\u0026#34;, \u0026#34;query\u0026#34; : { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34; : \u0026#34;Learning Hadoop\u0026#34; } } } } }     Nested vs Parent/Child #      Nested Object Parent/Child     优点 文档存储在一起，读取性能高 父子文档可以独立更新   缺点 更新嵌套的子文档时，需要更新整个文档 需要额外的内存维护关系，读取时性能相对差   适用场景 子文档偶尔更新，以查询为主 子文档频繁更新    重建索引 #  需要重建索引的场景 #   索引的Mapping 发生变更：字段类型更改，分词器及字典更新； 索引的Settings 发生变更：索引的主分片数发生改变； 集群内，集群间需要做数据迁移。  Elasticsearch 的内置提供API #    Update By Query ：在现有索引上重建\n 比如，新增加一个子字段a，使用_update_by_query可以使历史数据的a字段都被赋值。\n   Reindex：在其他索引上重建索引\nPOST _reindex { \u0026#34;source\u0026#34;: { // 跨集群Reindex，除此之外还需要elasticsearch.yml中加上ip白名单，并重启集群  \u0026#34;remote\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;http://172.16.0.39:9200\u0026#34; }, // 支持多个，使用[]即可  \u0026#34;index\u0026#34;: \u0026#34;blogs\u0026#34;, // 不设置或设置为internal,会直接将文档转储到dest中，覆盖任何发生的具有相同类型和id的document  // 使用external的话，只有当source的version更加新的时候，才更新  \u0026#34;version_type\u0026#34;: \u0026#34;external\u0026#34;, // 过滤条件  \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;elasticsearch\u0026#34; } }, // 默认1000  \u0026#34;size\u0026#34;: 1000, // 排序  \u0026#34;sort\u0026#34;: { \u0026#34;date\u0026#34;: \u0026#34;desc\u0026#34; }, // 特定field  \u0026#34;_source\u0026#34;: [\u0026#34;user\u0026#34;, \u0026#34;tweet\u0026#34;] }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;blogs_fix\u0026#34;, // 只会创建不存在的文档，文档如果已经存在，会导致版本冲突。  \u0026#34;op_type\u0026#34;: \u0026#34;create\u0026#34;, // 使用Ingest Node  \u0026#34;pipeline\u0026#34;: \u0026#34;some_ingest_pipeline\u0026#34; }, // 默认情况下，当发生version conflict的时候，_reindex会被abort。除非把conflicts设置为“proceed”  \u0026#34;conflicts\u0026#34;: \u0026#34;proceed\u0026#34;, // 使用脚本  \u0026#34;script\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;if (ctx._source.foo == \u0026#39;bar\u0026#39;) {ctx._version++; ctx._source.remove(\u0026#39;foo\u0026#39;)}\u0026#34;, \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34; } }   使用场景：\n 修改索引的主分片数； 改变字段的Mapping 中的字段类型； 集群内数据迁移/跨集群数据迁移。    注意：\n 需要启用_source； 不会拷贝源索引settings，目标索引的mappings和settings需要已经定义好。    使用Task API查询进度\nGET _tasks?detailed=true\u0026amp;actions=*reindex   取消reindex\n// task_id，可以通过上面的Task API获取 POST _tasks/task_id:1/_cancel     Ingest Pipeline #   修复与增强写入数据，简化版logstash。\n Ingest Node #   在Elasticsearch5.0之后，引入的一种新的节点类型。默认配置下，每个节点都是Ingest Node。有如下功能：\n 具有预处理数据的能力，可以拦截Index 或 Bulk API 的请求； 对数据进行转换，并重新返回给Index 或 Bulk API。    可以对数据进行一些预处理，例如：为某个字段设置默认值；重命名某个字段的字段名；对字段值进行split操作。同时支持设置Painless 脚本，对数据进行更加复杂的加工。\n Pipeline \u0026amp; Processor #   Pipeline：管道会对通过的数据（文档），按照顺序进行加工。\n  Processor：Elasticsearch 对一些加工的行为进行了抽象包装。\nElasticsearch 有很多内置的Processor。也支持通过插件的方式，实现自己的 Processor。\n // 为ES添加一个 Pipeline PUT _ingest/pipeline/blog_pipeline { \u0026#34;description\u0026#34;: \u0026#34;a blog pipeline\u0026#34;, \u0026#34;processors\u0026#34;: [ { \u0026#34;split\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;tags\u0026#34;, \u0026#34;separator\u0026#34;: \u0026#34;,\u0026#34; } }, { \u0026#34;set\u0026#34;:{ \u0026#34;field\u0026#34;: \u0026#34;views\u0026#34;, \u0026#34;value\u0026#34;: 0 } } ] } // 查看Pipleline GET _ingest/pipeline/blog_pipeline // 使用pipeline更新数据 PUT tech_blogs/_doc/2?pipeline=blog_pipeline { \u0026#34;title\u0026#34;: \u0026#34;Introducing cloud computering\u0026#34;, \u0026#34;tags\u0026#34;: \u0026#34;openstack,k8s\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You konw, for cloud\u0026#34; } // 使用pipeline重建索引数据 POST tech_blogs/_update_by_query?pipeline=blog_pipeline { \u0026#34;query\u0026#34;: {} } 内置Processor #    Split Processor\n  Remove/Rename Processor\n （例：移除一个重命名字段）\n   Append\n （为商品增加一个新的标签）\n   Convert\n （将商品价格，从字符串转换成float类型）\n   Date / JSON\n 日期格式转换，字符串转JSON对象\n   Date Index Name Processor\n （通过该处理器的文档，分配到指定时间格式的索引中）\n   Fail Processor\n （一旦出现异常，该Pipeline指定的错误信息能返回给用户）\n   Foreach Processor\n （数组字段，数组的每个元素都会使用到一个相同的处理器）\n   Grok Processor\n （日志的日期格式切割）\n   Gsub/Join/Split\n （字符串替换/数组转换字符串/字符串转数组）Lowercase/ upcase （大小写转换）\n   Ingest Node 和 Logstash比较 #      Logstash Ingest Node     数据输入与输出 支持从不同的数据源读取，并写入不同的数据源 支持从ES Rest api获取数据，并写入ES   数据缓冲 实现了简单的数据队列，支持重写 不支持缓冲   数据处理 支持大量的插件，也支持定制开发 内置有插件，也可开发插件进行扩展   配置与使用 增加了一定的架构复杂度 无需额外部署    Painless #   Elasticsearch 5.x 后引入，专门为Elasticsearch 设计，扩展了Java 的语法；6.0 开始，Elasticsearch 只支持Painless。Grovvy，JavaScript，Python 都不再支持；Painless 支持所有Java 的数据类型及Java APi子集；Painless Script 具备以下特性：\n 高性能/安全； 支持显示类型或者动态定义类型。   用途 #    对文档字段进行加工处理：\n  更新或删除字段，处理数据聚合操作； Script Field：对返回的字段提前进行计算； Funcation Score：对文档算分进行处理。     在Ingest Pipeline 中执行脚本；\n  在Reindex API，Update By Query 时，对数据进行处理。\n  POST tech_blogs/_update/1 { \u0026#34;script\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;ctx._source.views += params.new_views\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;new_views\u0026#34;:100 } } } // 保存脚本在 Cluster State POST _scripts/update_views { \u0026#34;script\u0026#34;:{ \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;ctx._source.views += params.new_views\u0026#34; } } // 使用脚本 POST tech_blogs/_update/1 { \u0026#34;script\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;update_views\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;new_views\u0026#34;:1000 } } } // query时候加一个新字段 GET tech_blogs/_search { \u0026#34;script_fields\u0026#34;: { \u0026#34;rnd_views\u0026#34;: { \u0026#34;script\u0026#34;: { \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;\u0026#34;\u0026#34; java.util.Random rnd = new Random(); doc[\u0026#39;views\u0026#39;].value+rnd.nextInt(1000); \u0026#34;\u0026#34;\u0026#34; } } }, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } 通过Painless 脚本访问字段 #     上下文 语法     Ingestion ctx.field_name   Update ctx._source.field_name   Search \u0026amp; Aggregation doc[\u0026ldquo;field_name\u0026rdquo;]    脚本缓存 #   编译的开销比较大，Elasticsearch 会将脚本编译后缓存在Cache中，Inline scripts 和 Stored Scripts 都会被缓存（默认缓存 100 个脚本）。\n    参数 说明     script.cache.max_size 设置最大缓存数   script.cache.expire 设置缓存超时   script.max_compilations_rate 默认5分钟最多75次编译（75/5m）    数据建模 #   数据建模（Data modeling），是创建数据模型的过程，数据模型是对真实世界进行抽象描述的一种工具和方法，实现对现实世界的映射。建模的三个过程：概念模型-》 逻辑模型-》 数据模型（第三范式）。\n  数据建模需要从两方面考虑，功能需求和性能需求：\n   功能需求-逻辑模型\n  实体属性 实体之间的关系 搜索相关的配置     性能需求- 物理模型\n  索引模板：分片数量 索引 Mapping：字段配置、关系处理     字段建模 #    字段类型\n   Text；\n用于全文本字段，文本会被 Analyzer分词；默认不支持聚合分析及排序。需要设置 fielddata 为 true。\n  Keyword；\n用于id，枚举及不需要分词的文本。例如电话号码，email地址，手机号码，邮政编码，性别等；适用于Filter（精确匹配），Sorting 和 Aggregations。\n  多字段类型；\n默认会为文本类型设置为text，并且设置一个keyword的子字段；在处理人类语言时，通过增加 英文 ，拼音 和 标准 分词器， 提高搜索结构。\n  数值类型；\n尽量选择贴近的类型。例如可以用byte，就不要用long。\n  枚举类型；\n设置为keyword。即便是数字，也应该设置成keyword，获取更加好的性能。\n  其他。\n日期/布尔/地理信息。\n     是否要搜索以及分词\n 如果不需要检索，排序和聚合分析，Enable 设置成false；\n如果不需要检索：Index 设置成false；\n如果需要检索的字段，可以通过如下配置，设定存储粒度：Index options/ Norms：不需要归一化数据时，可以关闭。\n   是否要聚合以及排序\n 如果不需要检索，排序和聚合分析，Enable 设置成false；\n如果不需要排序或者聚合分析功能，Doc_values / fielddata 设置成false。\n更新频繁，聚合查询频繁的keyword 类型的字段推荐将 eager_global_ordinals设置为 true（缓存）。\n   是否需要额外存储\n  是否需要专门存储当前字段数据\n Store 设置成 true，可以存储该字段的原始内容，一般结合_source 的enabled 为 false时候使用。\n   Disable _source：节约磁盘；适用于指标型数据\n 一般建议先考虑增加压缩比；无法看到_source字段，无法ReIndex，无法做Update。\n     Mapping设置 #    Enabled - 设置成fasle，仅做存储，不支持搜索和聚合分析（数据保存在_source中）； _Index - 是否构倒排索引。设置为 false，无法被搜索，但还支持aggregation，并且出现在_source中； Norms - 如果字段用来过滤和聚合分析，可以关闭，节约存储； Doc_values - 是否启动doc_values，用于排序和聚合分析； Field_data - 如果要对text类型启用排序和聚合分析，需要设置为true； Store - 默认不存储，数据默认存储在_source； Coerce - 默认开启，是否开启数据类型的自动转换（例如，字符串转数字）； Multifields 多字段特性；Dynamic - true/false/strict 控制Mapping的自动更新。   一些相关的API #    Index Template \u0026amp; Dynamic Template\n 根据索引名字匹配不同的Mappings 和 Settings；可以在一个Mapping 上动态的设定字段类型\n   Index Alias\n 无需停机，无需修改程序，即可进行修改。\n   Update By Query \u0026amp; Reindex\n  最佳实践 #  处理关联关系 #  避免过多字段 #   一个文档中，最好避免大量的字段，因为：\n  过多的字段数不容易维护；\n  Mapping 信息保存在Cluster State 中，数据量过大，对集群性能会有影响（Cluster State信息需要 和所有的节点同步）；\n  删除或者修改数据需要reindex。\n     默认最大字段是 1000， 参数：index.mapping.total_fields.limit；\n  Dynamic vs Strict\n Dynamic （生产环境，尽量不要打开Dynamic）  true - 未知字段会被自动加入； false - 新字段不会被索引。但是会保存在_source； strict - 新增字段不会被索引，文档写入失败。      使用Nested类型，解决字段膨胀问题。\n 通过Nested 对象保存Key/Value，解决Cluster State保存过多Meta信息，但是：\n 导致查询语句复杂度增加； 不利于在Kibana 中实现可视化分析。     避免正则查询 #   正则，通配符查询，前缀查询数据Term 查询，但是性能不够好，特别是将通配符放在开头，会导致性能的灾难。\n 解决：\n 将字符串转化为对象； 比如版本信息，7.1.2，用四个字段存储。  避免空值引起聚合不准 #   设置null_value属性。\n 为索引的mapping 加入meta信息 #  PUT softwares/ { \u0026#34;mappings\u0026#34;: { \u0026#34;_meta\u0026#34;: { \u0026#34;software_version_mapping\u0026#34;: \u0026#34;1.0\u0026#34; } } }  Mappings 设置非常重要，需要从两个维度进行考虑  功能：搜索，聚合，排序 性能：存储的开销；内存的开销；搜索的开销     Mappings 设置是一个迭代的过程\n加入新的字段很容易（必要时需要update_by_query）\n更新删除字段不允许（需要Reindex重建数据）\n最好能对Mappings 加入Meta信息，更好的进行版本管理可以考虑将 Mapping 文件上传git 进行管理\n "},{"id":25,"href":"/docs/elasticsearch/mds/6_scale_out/","title":"水平扩展集群","section":"Elasticsearch","content":"常见的集群部署方式 #  单一职责节点 #   在开发环境中，一个节点可承担多种角色。在生产环境，根据数据量，写入和查询的吞吐量，选择合适的部署方式，建议设置单一角色节点（dedicated node）。\n一个节点在默认情况下会同时扮演：master eligible、data node、coordinating node 和 ingest node，通过参数配置，让一个节点只承担一个角色。\n   参数配置\n   单一节点 配置     Master node.master: true、node.ingest: false、node.data: false   Data node.master: false、node.ingest: false、node.data: true   Coordinate node.master: false、node.ingest: true、node.data: false   Ingest node.master: false、node.ingest: false、node.data: false      职责分离的优势\n 对于不同角色的节点，可以使用不同的配置。\n   Dedicated master eligible nodes\n 负责集群状态的管理，使用低配置的CPU、RAM和磁盘。\n  从高可用 \u0026amp; 避免脑裂的角度出发，一般在生产环境中配置3台；一个集群只有一台活跃的主节点。如果与数据节点、Coordinate 节点混合部署，数据节点相对有比较大的内存占用，Coordinate 节点有时候可能会有开销很高的查询，导致OOM，这些都有可能影响Master 节点，导致集群不稳定。\n   Dedicated data nodes\n 负责数据的存储及处理客户端请求，使用高配置的CPU、RAM和磁盘。\n   Dedicated ingest nodes\n 负责数据处理，使用高配置的CPU、中等配置的RAM、低配置的磁盘。\n   Dedicated Coordinating Only Node\n  扮演 Load Balancers，降低 Master 和 Data Nodes 的负载； 负责搜索结果的Gather/Reduce。  生产环境中，建议为一些大的集群配置Coordinating Only Node，使用中高配置的CPU、中高配置的RAM、低配置的磁盘。\n     部署方式 #    增加节点，水平扩展\n 当磁盘容量无法满足需求时，可以增加数据节点；磁盘读写压力大时，增加数据节点。\n   Coordinate Only Node\n 当系统中有大量的复杂查询及聚合的时候，增加Coordinating节点，增加查询性能。LB指的是loadbalance。\n   读写分离\n  在集群中部署kibana\n 官方建议kibana 安装到Coordinating node。\n   异地多活的部署\n Global Traffic Manager，一种负载均衡。\n   Shard Filtering #   通过设置和标记，可以很好的空值分片的分配。\nnode.attr - 标记节点\nIndex.routing.allocation - 分配索引到节点\n    设置 分配索引节点，节点的属性规则     Index.routing.allocation.include.{attr} 至少包含一个值   Index.routing.allocation.exclude.{attr} 不能包含任何一个值   Index.routing.allocation.require.{attr} 所有值都需要包含    Hot \u0026amp; Warm Architecture #   数据通常不会有Update 操作：适用于Time Based 索引数据（生命周期管理），同时数据量比较大的场景。\n   Hot Nodes\n 用于数据的写入，Indexing 对 CPU 和 IO 都有很高的要求，所以需要使用高配置的机器，存储的性能要好，建议使用SSD。\n   Warm Nodes\n 用于保存只读的索引，比较旧的数据，通常使用大容量的磁盘（通常是Spinning Disks）。\n   配置\n   使用Shard Filtering，分为一下几步：\n   标记节点（Tagging）\n 通过“node.attr”来标记一个节点，节点的attribute 可以是任何的key/value，可以通过elasticsearch.yml 或者通过 -E 命令指定。\n # 标记一个 Hot 节点 bin/elasticsearch -E node.name=hotnode -E cluster.name=cluster1 -E path.data=hot_data -E node.attr.my_node_type=hot # 标记一个 warm 节点 bin/elasticsearch -E node.name=warmnode -E cluster.name=cluster1 -E path.data=warm_data -E node.attr.my_node_type=warm # 查看节点 GET /_cat/nodeattrs?v   配置索引到Hot Node\n 创建索引时，指定将其创建在 hot节点上。\n PUT logs-2019-06-27 { \u0026#34;settings\u0026#34;:{ \u0026#34;number_of_shards\u0026#34;:2, \u0026#34;number_of_replicas\u0026#34;:0, \u0026#34;index.routing.allocation.require.my_node_type\u0026#34;:\u0026#34;hot\u0026#34; } } // 查看分片信息 GET _cat/shards?v   配置索引到Warm Node\n 将某个索引移动到warm node。\nindex.routing.allocation 是一个索引级别的 dynamic setting，可以通过API 在后期进行设定。\n PUT PUT logs-2019-06-27/_settings { \u0026#34;index.routing.allocation.require.my_node_type\u0026#34;:\u0026#34;warm\u0026#34; }   Rack Awareness #   ES 节点可能分布在不同的机架，当一个机架断电，可能会同时丢失几个节点。如果一个索引相同的主分片和副本分片，同时在这个机架上，就可能导致数据丢失；通过Rack Awareness的机制，就可以尽可能避免将同一个索引的主副分片分配在一个机架的节点上。\n如下图，如果Rack 1断电，那么P0/R0对应的索引可能产生数据丢失。\n  配置   与Hot \u0026amp; Warm Architecture配置类似。\n   标记Rack 节点\n# 标记一个 rack 1 bin/elasticsearch -E node.name=node1 -E cluster.name=geektime -E path.data=node1_data -E node.attr.my_rack_id=rack1 # 标记一个 rack 2 bin/elasticsearch -E node.name=node2 -E cluster.name=geektime -E path.data=node2_data -E node.attr.my_rack_id=rack2   配置集群\n// 这样设置后，ES会自动把主分片和副本分片发送到不同的rack上 PUT _cluster/settings { \u0026#34;persistent\u0026#34;: { \u0026#34;cluster.routing.allocation.awareness.attributes\u0026#34;: \u0026#34;my_rack_id\u0026#34; } }   Force Awareness\nPUT _cluster/settings { \u0026#34;persistent\u0026#34;: { \u0026#34;cluster.routing.allocation.awareness.attributes\u0026#34;: \u0026#34;my_rack_id\u0026#34;, // 强制要求主副本分片分散到rack1和rack2上面，如果只有rack1节点，那么索引分片无法正常分配  \u0026#34;cluster.routing.allocation.awareness.force.my_rack_id.values\u0026#34;: \u0026#34;rack1,rack2\u0026#34; } } // 查看分片无法正常分配原因 GET _cluster/allocation/explain?pretty   分片设计及管理 #   之前会默认创建5个主分片，7.0开始，新创建一个索引时，默认只有一个主分片。\n单个分片，查询算分，聚合不准的问题都可以得以避免，但是单个索引，单个分片的时候，集群无法实现水平扩展。\n  集群新加一个节点后，Elasticsearch 会自动进行分片的移动，也叫Shard Rebalanceing。比如一个索引有2个分片，本来有一个节点A，这是节点A就有俩分片，后来加了一个节点B，那么此时A和B各有一个分片。\n   当分片数 \u0026gt; 节点数时\n 一旦集群中有新的数据节点加入，分片可以自动进行分配，分配在重新分配时，系统不会有downtime。\n   多分片的好处：一个索引如果分布在不同的节点，多个节点可以并行执行\n 查询可以并行执行；数据写入可以分散到多个机器。\n   分片过多所带来的的副作用\n 每个分片是一个Lucene的索引，会使用机器资源。过多的分片会导致额外的性能开销。\n 每次搜索的请求，需要从每个分片上获取数据； 分片的meta 信息由Master node维护，过多会增加管理负担； 经验值，控制分片总数在10w以内。     确定主分片数\n  从存储的物理角度看：\n 官方推荐：日志类应用，单个分片不要大于 50GB；搜索类应用，单个分片不要超过20GB。\n   为什么要控制分片存储大小：\n 提高Update 的性能；Merge 时，减少所需的资源；丢失节点后，具备更快的恢复速度 / 便于分片在集群内 Rebalancing。\n     确定副本分片数\n 副本会降低数据的索引速度：有几份副本就有几倍的CPU资源消耗在索引上；会减缓对主分片的查询压力，但是会消耗同样的内存资源。\n如果机器资源充分，提高副本数，可以提高整体查询的QPS。\n   调整分片总数设定，避免分配不均衡\n ES的分片策略会尽量保证节点上的分片数大致相同，但是，扩容的新节点没有数据，可能导致新索引集中在新的节点，热点数据过于集中，可能产生性能问题。\n  index.routing.allocation.total_shards_per_node：设置某个索引每个节点可以有几个分片。 cluster.routing.allocation.total_shards_per_node：全局配置。    集群容量规划 #   规划上需要保持一定的余量，当负载出现波动，节点出现丢失，还能正常运行。\n做容量规划时，一些需要考虑的因素：\n 机器的软硬件配置； 单条文档的尺寸/ 文档的总数据量 / 索引的总数据量 （time base 数据保留的时间）/ 副本分片数； 文档是如何写入的（Bulk的尺寸）； 文档的复杂度，文档是如何进行读取的。   评估业务的性能需求 #    数据吞吐及性能需求\n 数据写入的吞吐量，每秒要求写入多少数据；查询的吞吐量；单挑查询可接受的最大返回时间。\n   了解你的数据\n 数据的格式和数据的Mapping；实际的查询和聚合长的是什么样的。\n   应用分类\n   搜索：固定大小的数据集。搜索的数据集增长相对比较缓慢。\n  日志：基于时间序列的数据。使用 ES 存放日志与性能指标。数据每天不断写入，增长速度较快；结合 Warm Node 做数据的老化处理。\n     硬件配置\n 选择合理的硬件，数据节点尽可能使用 SSD； 搜索等性能要求高的场景，建议SSD；按照1 ： 10的比例配置内存和硬盘； 日志类和查询并发低的场景，可以考虑使用机械硬盘存储；按照1:50的比例配置内存和硬盘； 单节点数据建议控制在 2 TB以内，最大不建议超过5 TB； JVM 配置机器内存的一半， JVM 内存配置不建议超过32G。    部署方式\n 按需选择合理的部署方式：如果考虑可靠性高可用，建议部署3台 dedicated 的Master 节点；如果有复杂的查询和聚合，建议设置Coordinating 节点。\n   搜索类应用 #    一些案例：唱片信息库/ 产品信息\n  特性\n 被搜索的数据集很大，但是增长相对比较慢（不会有大量的写入），更关心搜索和聚合的读取性能。\n数据的重要性与时间范围无关。关注的是搜索的相关度。\n   估算索引的数据量，确定分片的大小\n 单个分片的数据不要超过20GB； 可以通过增加副本分片，提高查询的吞吐量。    拆分索引\n  如果业务上有大量的查询时基于一个字段进行Filter，该字段又是一个数量有限的枚举值（例如订单所在的地区），可以考虑以这个字段拆分为多个索引；\n  如果在单个索引有大量的数据，可以考虑将索引拆分成多个索引；\n 查询性能可以得到提高；如果要对多个索引进行查询，还是可以在查询中指定多个索引得以实现。\n   如果业务上有大量的查询是基于一个字段进行Filter，该字段数值并不固定。\n 可以启用Routing功能，按照filter 字段的值分布到集群中不同的shard，降低查询时相关的shard，提高CPU利用率。\n     日志类应用 #    相关的用案：日志/ 指标 / 安全性相关的Events；舆情分析\n  特性\n   每条数据都有时间戳；文档基本不会被更新（日志和指标数据）；\n  用户更多的会查询近期的数据；对旧的数据查询相对较少；\n  对数据的写入性能要求比较高。\n     创建 time-based 索引\n  在索引的名字中增加时间信息； 按照 每天/ 每周 / 每月 的方式进行划分。     优势\n 更加合理的组织索引，例如随着时间推移，便于对索引做的老化处理：\n 利用 Hot \u0026amp; Warm Architecture 备份和删除以及删除的效率高。（delete by query 执行速度慢，底层也不会立即释放空间，而Merge时又很消耗资源）。       写入时间序列的数据：基于 Data Math 的方式 #   容易使用，但如果时间规则变化，需要重新部署代码。\n假设现在是2019-08-01T00:00:00\n    公式 含义     \u0026lt;logs-{now/d}\u0026gt; logs-2022.01.01   \u0026lt;logs-{now{YYYY.MM}}\u0026gt; logs-2022.01   \u0026lt;logs-{now/w}\u0026gt; 这周的开始     另外可以通过别名的方式，更新每天的索引。\n 扩容 #    增加 Coordinating / Ingest Node\n 解决CPU 和 内存开销问题。\n   增加 Data Node\n 解决存储的容量问题。为避免分配不均的问题，需要提前监控磁盘空间，提前清理数据或增加节点（70%）。\n   "},{"id":26,"href":"/docs/elasticsearch/mds/7_cluster_setting/","title":"集群运维","section":"Elasticsearch","content":"常用配置 #  开发模式和生产模式 #   从ES 5开始，支持 Development和Production 两种运行模式。\n Bootstrap Checks #   一个集群在Production Mode时，启动时必须通过所有Bootstrap 检测，否则会启动失败。Bootstrap Checks 可以分为两类 JVM \u0026amp; Linux Checks。Linux Checks只针对Linux系统。\n JVM设定 #   从ES 6开始，只支持 64 位的JVM，JVM的设置可以在config/jvm.options中设置。尽量避免修改默认配置：\n 将内存 Xms 和 Xmx 设置成一样，避免heap resize 时引发停顿 Xmx设置不要超过物理内存的 50%（lucene索引会用内存）；单个节点，最大内存建议不超过32G（JVM内存小于32G时会使用指针压缩技术） 生产环境，JVM必须使用Server模式 关闭JVM Swapping   集群配置设定 #    静态设定\n 静态配置文件尽量简洁：按照文档设置所有相关系统参数。elasticsearch.yml 配置文件中尽量只写必备参数。\n   动态设定\n 其他的设置项可以通过 API 动态进行设定。动态设定分 transient 和 persistent 两种，都会覆盖 elasticsearch.yml 中的设置。transient 在集群重启后会丢失；persistent 在集群重启后不会丢失。\n    优先级 设置     1 Transient Settings   2 Persistent Settings   3 Command-line Settings   4 Config file Settings      系统设置 #   参照文档 Setup ELasticsearch \u0026gt; Important System Configuration。\n 最佳实践 #    网络\n 单个集群不要跨数据中心进行部署（不要使用WAN） 节点之间的hops 越少越好 如果有多块网卡，最好将transport 和http 绑定到不同的网卡，并设置不同的防火墙 Rules 按需为 Coordinating Node 或 Ingest Node 配置负载均衡    内存设定计算实例\n  内存大小要根据Node 需要存储的数据来进行估算：搜索类的比例建议 1:16；日志类：1:48 - 1:96 之间。\n 假设总数据量1T，设置一个副本 = 2T 总数据量。\n 搜索类项目，每个节点 31（JVM内存） * 16 = 496 G，加上预留空间。所以每个节点最多400G 数据，至少需要5 个数据节点； 日志类项目，每个节点 31 * 50 = 1550 GB， 两个数据节点即可。       存储\n 推荐使用SSD，使用本地存储（Local Disk），避免使用 SAN NFS/ AWS / Azure filesystem 可以在本地指定多个 \u0026ldquo;path.data\u0026rdquo;，以支持使用多块磁盘 ES 本来提供了很好的HA 机制，无需使用RAID 1/5/10 可以在Warm 节点上使用Spinning Disk，但是需要关闭Concurrent Merges Trim 你的SSD    服务器硬件\n 建议使用中等配置的机器，不建议使用过于强劲的硬件配置（建议使用中等配置的机器，不建议使用过于强劲的硬件配置） 不建议在一台服务器上运行多个节点    Throttles限流\n 为 Relocation 和Recovery 设置限流，避免过多任务对集群产生性能影响。\n   Recovery\nCluster.routing.allocation.node_concurrent_recoveries：2   Relocation\nCluster.routing.allocation.cluster_concurrent_rebalance：2     集群设置 #    关闭 Dynamic Indexes\nPUT _cluster/settings { \u0026#34;persistend\u0026#34; : { \u0026#34;actino.auto_create_index\u0026#34; : false } } // 也可以设置白名单 PUT _cluster/settings { \u0026#34;persistend\u0026#34; : { \u0026#34;actino.auto_create_index\u0026#34; : \u0026#34;logstash-*, .kibana*\u0026#34; } }   安全设定\n 打开Authentication \u0026amp; Authorization 实现索引和字段级的安全控制 节点间通信加密 Enable HTTPS Audit logs    监控集群 #  Stats相关API #    Node Stats\n// 节点级别统计信息 GET _nodes/stats   CLuster Stats\n// 集群级别统计信息，文档总数、索引总数等 GET _cluster/stats   Index Stats\n// 索引级别统计信息 GET 索引名/_stats   Task API #    Task\n// 查看所有的 tasks GET _tasks // Pending Cluster Tasks GET _cluster/pending_tasks   Thread Pools\nGET _nodes/thread_pool GET _nodes/stats/thread_pool GET _cat/thread_pool?v GET _nodes/hot_threads GET _nodes/stats/thread_pool   Query Slow Log #  PUT my_index/_settings { \u0026#34;index.indexing.slowlog\u0026#34;:{ \u0026#34;threshold.index\u0026#34;:{ \u0026#34;warn\u0026#34;:\u0026#34;10s\u0026#34;, \u0026#34;info\u0026#34;: \u0026#34;4s\u0026#34;, \u0026#34;debug\u0026#34;:\u0026#34;2s\u0026#34;, \u0026#34;trace\u0026#34;:\u0026#34;0s\u0026#34; }, \u0026#34;level\u0026#34;:\u0026#34;trace\u0026#34;, \u0026#34;source\u0026#34;:1000 } } PUT my_index/ { \u0026#34;settings\u0026#34;: { \u0026#34;index.search.slowlog.threshold\u0026#34;: { \u0026#34;query.warn\u0026#34;: \u0026#34;10s\u0026#34;, \u0026#34;query.info\u0026#34;: \u0026#34;3s\u0026#34;, \u0026#34;query.debug\u0026#34;: \u0026#34;2s\u0026#34;, \u0026#34;query.trace\u0026#34;: \u0026#34;0s\u0026#34;, \u0026#34;fetch.warn\u0026#34;: \u0026#34;1s\u0026#34;, \u0026#34;fetch.info\u0026#34;: \u0026#34;600ms\u0026#34;, \u0026#34;fetch.debug\u0026#34;: \u0026#34;400ms\u0026#34;, \u0026#34;fetch.trace\u0026#34;: \u0026#34;0s\u0026#34; } } }   支持将分片上，Search 和 Fetch 阶段的慢查询写入文件\n  支持为Query 和Fetch 分别定义阈值\n  索引级的动态设置，可以按需设置，或者通过 Index Template 统一设定\n  Slog log 文件通过log4j2.properties配置\n  创建监控dashboard #   开发 Elasticsearch plugin，通过读取相关的监控 API，将数据发送到 ES，或者TSDB 使用Metricbeats 搜索相关指标 使用Kibana 或者 Graffna 创建 Dashboard 可以开发Elasticsearch Exporter，通过 Promtheus 监控 Elasticsearch 集群  潜在问题 #    集群健康状态\n 是否有节点丢失\n   索引合理性\n 索引总数不能过大/ 副本分片尽量不要设置为0 / 主分片尺寸检测 / 索引的字段总数 / 索引是否分配不均衡 / 索引 segment 大小诊断分析\n   资源使用合理性\n CPU 内存 和磁盘使用情况分析 / 是否存在节点负载不平衡 / 是否需要增加节点\n   业务操作合理性\n 集群状态变更频率，是否在业务高峰期有频繁操作；慢查询监控与分析\n   集群 Yellow 与 Red 问题 #   分片健康：\n 红：至少有一个主分片没有分配 黄：至少有一个副本分片没有分配 绿：主副本分片全部正常分配。  Red \u0026amp; Yellow 是集群运维中常见的问题。除了集群故障，一些创建，增加副本等操作，都会导致集群短暂的Red 和Yellow，所以监控和报警时都需要设置一定的延时；通过检查节点数，使用ES 提供的相关API，找到真正的原因；可以指定Move 或者Reallocate分片。\n    GET _cluster/health 集群的状态（检查节点数量）     GET cluster/health?level=indices 所有索引的健康状态（查看有问题的索引）   GET cluster/health/my_index 耽搁索引的健康状态（查看具体的索引）   GET cluster/health?level=shards 分片级的索引   GET cluster/allocation/explain 返回第一个未分配Shard 的原因      案例\n  症状：集群变红； 分析，通过 Allocation Explain API 发现 创建索引失败，因为无法找到标记了相应 box type 的节点； 解决：删除索引，集群变绿。重新创建索引，并且指定正确的 routing box type，索引创建成功，集群保持绿色。     症状：集群变黄； 分析，通过 Allocation Explain API 发现 无法在相同的节点上创建副本； 解决：将索引的副本数设置为0，或者通过增加节点解决。     短暂的Yellow or Red\n INDEX_CREATE：创建索引导致。在索引的全部分片分配完成之前，会有短暂的 Red，不一定代表有问题 CLUSTER_RECOVER：集群重启阶段，也可能变黄 INDEX_REOPEN：Open 一个之前 CLose 的索引 DANGLING_INDEX_IMPORTED：一个节点离开集群期间，有索引被删除。这个节点重新返回时，会有Dangling问题，重新删除这个索引即可。    常见问题与解决方法\n  集群变红\n 需要检查是否有节点离线。如果有，通常通过重启离线的节点可以解决问题\n   由于配置导致的问题（例如错误的box_type，错误的副本数）\n 需要修复相关的配置；如果是测试的索引，可以直接删除\n   因为磁盘空间限制，分片规则（shard filtering）引发的\n 需要调整规则或者增加节点\n   对于节点返回集群，导致dangling变红\n 可以直接删除 dangling索引\n     提升写性能 #   ES 默认配置，已经综合考虑了数据可靠性，搜索的实时性质，写入速度，一般不要盲目修改 一切优化，都要基于高质量的数据建模  一般方法 #    客户端\n 多线程，批量写。可以通过性能测试，确定最佳文档数量；多线程时候需要观察是否有HTTP 429 返回，实现Retry 以及线程数量 的自动调节。\n单个bulk请求体的数据量不要太大，官方建议大约5-15mb；写入端的bulk请求超时超时需求足够长，建议60s以上；写入端尽量将数据轮训打到不同节点。\n   服务器端\n 单个性能问题，往往是多个因素造成的。需要先分解问题，在单个节点上进行调整并且结合测试，尽可能压榨硬件资源，以达到最高吞吐量。可以使用更好的硬件，观察CPU / IO Block；线程切换 / 堆栈情况。\n   服务端优化 #    降低IO操作\n 使用 ES 自动生成的文档ID，/一些相关的ES 配置，如提升Refresh Interval；\n   降低 CPU 和 存储开销\n 减少不必要分词 / 避免不需要的doc_values / 文档的字段尽量保证相同的顺序，可以提高文档的压缩率\n   尽可能做到写入和分片的均衡负载，实现水平扩展\n Shard Filtering / Write Load Balancer\n   调整 Bulk 线程池和队列\n 索引创建属于计算密集型任务，应该使用固定大小的线程池来配置，线程数应该配置成CPU 核心数 + 1，避免过多的上下文切换 来不及处理的放入队列，队列大小可以适当增加，不要过大，否则占用的内存会成为GC的负担    关闭无用的功能 #    Index设置为 false\n 适合只需要聚合不需要搜索\n   Norms 设置成 false\n 适合不需要算分\n   不要对字符串使用默认的 dynamic mapping\n 字段数量过多，会对性能产生表达的影响\n   Index_options控制在创建倒排索引时，哪些内容会被添加到 倒排索引中\n 优化这些配置，一定程度可以节约CPU\n   关闭_source，减少IO 操作\n 适合指标型数据\n   取舍 #   如果需要追求极致的写入速度，可以牺牲数据可靠性及搜索实时性以换取性能。\n 牺牲可靠性：将副本分片设置为0，写入完毕再调整回去 牺牲搜索实时性：增加Refresh Interval 的时间 牺牲可靠性：修改Translog 的配置   数据写入过程的可优化点 #    Refresh Interval\n 增加refresh_interval 的数值，降低Refresh 的频率。默认值为 1S，如果设置成-1，会禁止自动 refresh。此举避免过于频繁的refresh而生产过多的segment文件，但是会降低搜索的实时性。另外需要修改参数 indices.memory.index_buffer_size（默认是10%，会导致自动触发refresh）。\n   Translog\n 降低写磁盘的频率，但是会降低容灾能力。\n Index.translog.durability：默认是request，每个请求都落盘。设置成async，异步写入 index.translog.sync_interval 设置成60s，每分钟执行一次 index.translog.flush_threshod_size：默认521 mb，可以适当调大。当translog超过改值，会触发flush     分片设定\n  副本在写入时设为0，完成后再增加\n  合理设置主分片数，确保均匀分配在所有数据节点上\n index.routing.allocation.total_share_per_node：限定每个索引在每个节点可分配的主分片数；\n比如5个节点的集群，所有有5个主分片，一个副本，每个节点的分片数：（5 + 5） / 5 = 2，生产环境要适当调大这个数字，避免有节点下线时，分片无法正常迁移。\n     PUT myindex { \u0026#34;settings\u0026#34;: { \u0026#34;index\u0026#34;: { // 30s一次Refresh  \u0026#34;refresh_interval\u0026#34;: \u0026#34;30s\u0026#34;, \u0026#34;number_of_shards\u0026#34;: \u0026#34;2\u0026#34; }, \u0026#34;routing\u0026#34;: { \u0026#34;allocation\u0026#34;: { // 控制分片，避免数据热点  \u0026#34;total_shards_per_node\u0026#34;: \u0026#34;3\u0026#34; } }, \u0026#34;translog\u0026#34;: { // 降低translog落盘  \u0026#34;sync_interval\u0026#34;: \u0026#34;30s\u0026#34;, \u0026#34;durability\u0026#34;: \u0026#34;async\u0026#34; }, \u0026#34;number_of_replicas\u0026#34;: 0 }, \u0026#34;mappings\u0026#34;: { // 避免不必要的字段索引。必要时可以通过update by query 索引必要的字段  \u0026#34;dynamic\u0026#34;: false, \u0026#34;properties\u0026#34;: {} } } 提升读性能 #  数据建模 #   尽量Denormalize 数据 尽量将数据先行计算，然后保存到Elasticsearch 中，尽量避免查询时的Script 计算 尽量使用 Filter Context，利用缓存机制，减少不必要的算分 结合profile，explain API 分析慢查询的问题，持续优化数据模型 严禁 使用 * 开头通配符 Terms查询  优化分片 #   避免 Over Sharing一个查询需要访问每一个分片，分片过多，会导致不必要的查询开销 结合应用场景，控制单个分片的尺寸：  Search 20G Logging 40G Force-merge Read-only索引 使用基于时间序列的索引，将只读的索引进行force merge，减少segment数量。    段合并优化及注意事项 #  Merge优化 #   ES 和 Lucene 会自动进行Merge操作，Merge操作相对比较重，需要优化，降低对系统的影响。\n 降低分段产生的数量/频率；  可以将Refresh Interval 调整到分钟级别/ indices.memory.index_buffer_size（默认是10%） 尽量避免文档的更新操作   降低最大分段大小，避免较大的分段继续参加Merge，节省系统资源。（最终会有多个分段）  Index.merge.policy.segments_per_tier，默认为 10，越小需要越多的合并操作 Index.merge.policy.max_merged_segment，默认 5GB，操作此大小以后，就不再参与后续的合并操作     Force Merge #   当 Index 不再有写入操作的时候，建议对其进行force merge，可以提升查询速度 / 减少内存开销。\n POST my_index/_forcemerge?max_num_segments=1 GET _cat/segments/my_index?v  最终分成的segments越少越好，最好可以 force merge成1个。但是，Force Merge 会占用大量网络资源、IO和CPU。如果不能再业务高峰期之前做完，就需要考虑增大最终的分段数，加快force_merge完成的时间。\n 缓存及使用Breaker限制内存使用 #  缓存分类 #    Node Query Cache\n 每一个节点都有一个Node Query缓存，由该节点的所有Shard 共享，只缓存Filter Context 相关内容，采用LRU算法。\n   静态配置（需要设置在每个 Data Node 上）\n Node Level - indices.queries.cache.size : 10%\nIndex level - index.queries.cache.enabled:true\n   缓存失效\n 保存的是Segment 级缓存命中的结果。Segment 被合并后，缓存会失效。\n     Shard Request Cache\n 缓存每个分片上的查询结果，只会缓存设置了 size = 0 的查询对应的结果。不会缓存hits。但是会缓存Aggregation 和Suggestions。\n使用LRU算法，将整个JSON 查询串作为Key，与JSON对象的顺序有关。\n   静态配置\n 数据节点 ：indices.requests.cache.size：1%\n   缓存失效\n 分配Refresh 的时候，Shard Request Cache 会失效。如果Shard 对应的数据频繁发生变化，该缓存的效率会很差。\n     Fielddata Cache\n 除了Text 类型，默认都采用doc_values，节约了内存。Text 类型的字段需要打开Fileddata 才能对其进行聚合和排序，但是Text 经过分词，排序和聚合效果不佳，建议不要轻易使用。\nAggregation 的 Global ordinals 也保存在Fielddata cache中。\n   配置\n 可以控制 Indices.fielddata.cache.size ，避免产生GC（默认无限制）\n   缓存失效\n Segment 被合并后会失效。\n     内存管理与断路器 #   Elasticsearch 高效运维依赖于内存的合理分配，可用内存一半分配给JVM，一半留给操作系统，缓存索引文件。内存问题，可能引发的问题：\n 长时间GC，影响节点，导致集群相应缓慢； OOM，导致丢节点。     查看各个节点内存状况\nGET _cat/nodes?v GET _nodes/stats/indices?pretty GET _cat/nodes?v\u0026amp;h=name,queryCacheMemory,queryCacheEvictions,requestCacheMemory,requestCacheHitCount,request_cache.miss_count GET _cat/nodes?h=name,port,segments.memory,segments.index_writer_memory,fielddata.memory_size,query_cache.memory_size,request_cache.memory_size\u0026amp;v   常见的内存问题\n  Segments 个数过多，导致 full GC\n 现象：集群整体响应缓慢，没有特别多的数据读写。但是发现节点在持续进行 Full GC\n分析：查看Elasticsearch 的内存使用，发现 segments.memory占用很大空间\n解决：通过 force merge，把segments合并成一个\n建议：对于不再写入和更新的索引，可以将其设置为只读。同时，进行 force merge操作。如果问题依然存在，则需要考虑扩容。\n   Field data cache 过大，导致 full GC\n 现象：集群整体响应缓慢，也没有特别多的数据读写。但是发现节点在持续进行 Full GC\n分析：查看Elasticsearch 的内存使用，发现fielddata.memory.size 占用很大空间。同时。数据不存在写入和更新，也执行过segments merge。\n解决：将 indices.fielddata.cache.size 设小，重启节点，堆内存恢复正常\n建议：Field data cache 的构建比较重，Elasticsearch 不会主动释放，所以这个值设置的保守一些。如果业务上确实有所需要，可以通过增加节点，扩容解决。\n   复杂的嵌套聚合，导致集群full GC\n 现象：节点响应缓慢，持续进行 Full GC\n分析：导出 Dump 分析。发现内存中有大量 bucket对象，查看日志发现复杂的嵌套聚合\n解决：优化聚合\n建议：在大量数据集上进行嵌套聚合查询，需要很大的堆内存来完成。如果业务场景确实需要，则需要增加硬件进行扩展。同时，为了避免这类查询影响整个集群，需要设置 Circuit Breaker 和 search.max.buckets 的数值\n     Circuit Breaker\n 断路器，避免不合理操作引发的 OOM，每个断路器可以指定内存使用的限制。\n Parent circuit breaker：设置所有的熔断器可以使用的内存的总量 Fielddata circult breaker：加载fielddata 所需要的内存 Request circuit breaker：防止每个请求级数据结构超过一定的内存（例如聚合计算的内存） In fight circuit breaker：Request中的断路器 Accounting request circuit breaker：请求结束后不能释放对象所占用的内存   // Circuit Breaker统计信息 // Tripped 大于0，说明有过熔断 // Limit size 与 estimated size越接近，越可能引发熔断 GET /_nodes/stats/breaker?  不要触发了熔断，就盲目调大参数，有可能会导致集群出问题，也不要盲目调小，需要进行评估。将集群升到 7.x，更好的Circuit Breaker 实现机制：增加了 indices.breaker.total.use_real_memory 配置项，可以更加精准的分析内存情况，避免OOM。\n   "},{"id":27,"href":"/docs/elasticsearch/mds/8_index_lifecycle/","title":"索引生命周期管理","section":"Elasticsearch","content":"索引管理API #    Open / Close Index\n 索引关闭后无法进行读写，但是索引数据不会被删除。\n // 关闭索引 POST /索引名/_close // 索引存在 HEAD 索引名 // 打开索引 POST /索引名/_open   Shrink Index\n 可以将索引的主分片数收缩到较小的值。使用场景：\n 索引保存的数据量比较小，需要重新设定主分片； 索引从Hot 移动到 Warm后，需要降低主分片数。    会使用和索引源相同的配置创建一个新的索引，仅仅降低主分片数。源分片数必须是目标分片数的倍数。如果源分片数是素数，目标分片数只能为1；如果文件系统支持硬链接，会将Segments 硬连接到目标索引，所以性能好（相比较于Reindex）。完成后，可以删除源索引。\n  使用要求：\n 分片必须只读； 所有分片必须在同一个节点上； 集群健康状态为 Green。   POST my_source_index/_shrink/my_target_index { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_replicas\u0026#34;: 0, \u0026#34;index.number_of_shards\u0026#34;: 2, \u0026#34;index.codec\u0026#34;: \u0026#34;best_compression\u0026#34; }, \u0026#34;aliases\u0026#34;: { \u0026#34;my_search_indices\u0026#34;: {} } }   Split Index\n 可以扩大主分片个数。使用要求：\n 目标索引必须不存在； 目标分片数是源分片数倍数； 源索引分片数小于目标索引； 分片必须只读； 相应分片会被复制到同样的节点。   POST my_source_index/_split/my_target_index { \u0026quot;settings\u0026quot;: { \u0026quot;index.number_of_shards\u0026quot;: 8, \u0026quot;index.number_of_replicas\u0026quot;:0 } }   Rollover Index\n 类似 Log4J 记录日志的方式，索引尺寸或者时间超过一定值后，创建新的索引。当满足一系列的条件（存活的时间 / 最大文档数 / 最大的文件尺寸），Rollver API 支持将一个 Alias 指向一个新的索引。\n  Rollover不会自动触发，一般需要和Index Lifecycle Management Policies 结合使用。\n // 不设定 is_write_true // 名字符合命名规范，以-数字结尾 PUT /nginx-logs-000001 { \u0026#34;aliases\u0026#34;: { \u0026#34;nginx_logs_write\u0026#34;: {} } } // 多于5条的文档会被移动到nginx-logs-000002索引，且nginx-logs-000001不再有别名 POST /nginx_logs_write/_rollover { \u0026#34;conditions\u0026#34;: { \u0026#34;max_age\u0026#34;: \u0026#34;1d\u0026#34;, \u0026#34;max_docs\u0026#34;: 5, \u0026#34;max_size\u0026#34;: \u0026#34;5gb\u0026#34; } } // 设置 is_write_index PUT apache-logs1 { \u0026#34;aliases\u0026#34;: { \u0026#34;apache_logs\u0026#34;: { \u0026#34;is_write_index\u0026#34;:true } } } // 需要指定 target 的名字 // 多于1条的文档会被移动到apache-logs2索引，但是前面设置了is_write_index，apache-logs1依然有别名apache_logs，但是新的数据只会写入apache-logs2 POST /apache_logs/_rollover/apache-logs2 { \u0026#34;conditions\u0026#34;: { \u0026#34;max_age\u0026#34;: \u0026#34;1d\u0026#34;, \u0026#34;max_docs\u0026#34;: 1, \u0026#34;max_size\u0026#34;: \u0026#34;5gb\u0026#34; } }   Rollup Index\n 对数据进行处理后，重新写入，减少数据量\n   时间序列索引 #   特点：索引中的数据随着时间持续不断增长 优势：按照时间序列划分索引，会使得管理更加简单。例如：完整删除一个索引，性能比 delete by query好 挑战：自动化管理，减少人工操作（从Hot 移动到 Warm；定期关闭或者删除索引） 生命周期常见的阶段  Hot：索引还存在着大量的读写操作； Warm：索引不存在写操作，还有被查询的需要； Cold：数据不存在写操作，读操作也不多； Delete：索引不再需要，可以被安全删除。    Index Lifecycle Management #   Elasticsearch 6.6 推出的新功能，基于 X-Pack Basic License，可免费使用。\n引入Policy、Phase、Action概念。\n "},{"id":28,"href":"/docs/mysql/mds/questions/","title":"Questions","section":"MySQL","content":"1 #   如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？\n 2 #   定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？\n 3 #   系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n 4 #  alter table T drop index k; alter table T add index(k); alter table T drop primary key; alter table T add primary key(id);  对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？\n 5 #  CREATE TABLE `geek` ( `a` int(11) NOT NULL, `b` int(11) NOT NULL, `c` int(11) NOT NULL, `d` int(11) NOT NULL, PRIMARY KEY (`a`,`b`), KEY `c` (`c`), KEY `ca` (`c`,`a`), KEY `cb` (`c`,`b`) ) ENGINE=InnoDB; 公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。但是，学过本章内容的小吕又纳闷了，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？同事告诉他，是因为他们的业务里面有这样的两种语句：\nselect * from geek where c=N order by a limit 1; select * from geek where c=N order by b limit 1;  我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？\n 6 #   备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？\n 7 #   如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：第一种，直接执行 delete from T limit 10000;第二种，在一个连接中循环执行 20 次 delete from T limit 500;第三种，在 20 个连接中同时执行 delete from T limit 500。你会选择哪一种方法呢？为什么呢？\n 8 #   我用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有“字段 c 和 id 值相等的行”的 c 值清零，但是却发现了一个“诡异”的、改不掉的情况。请你构造出这种情况，并说明其原理。\n mysql\u0026gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB; insert into t(id, c) values(1,1),(2,2),(3,3),(4,4); ![image-20220313140731738](/../../../Library/Application Support/typora-user-images/image-20220313140731738.png)\n9 #   change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。会不会出现这种情况呢？\n 12 #   一个内存配置为 128GB、innodb_io_capacity 设置为 20000 的大规格实例，正常会建议你将 redo log 设置成 4 个 1GB 的文件。\n但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？又为什么会出现这样的情况呢？\n 13 #   假设现在有人碰到了一个“想要收缩表空间，结果适得其反”的情况，看上去是这样的：一个表 t 文件大小为 1TB；对这个表执行 alter table t engine=InnoDB；发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了 1.01TB。你觉得可能是什么原因呢 ？\n "},{"id":29,"href":"/docs/mysql/mds/file/","title":"表数据","section":"MySQL","content":"  参数 innodb_file_per_table\n 表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：\n OFF - 表的数据放在系统共享表空间，也就是跟数据字典放在一起； ON - 每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。  从 MySQL 5.6.6 版本开始，它的默认值就是 ON 。\n  建议不论使用 MySQL 的哪个版本，都将这个值设置为 ON。\n因为，一个表单独存储为一个文件更容易管理，而且在不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。\n   删除 #  数据删除流程 #    删记录\n 在Innodb中，删除一条记录只会把这条记录标记为删除。后续如果插入别的记录，可能会复用这个位置，但磁盘文件的的大小不会缩小。\n  记录的复用，只限于符合范围条件的数据。\n   删数据页\n InnoDB 的数据是按页存储的，如果删掉一个数据页上的所有记录，整个数据页就可以被复用了。\n  与记录的复用不同，当整个页从B+ 树里面摘掉之后，可以复用任何位置，注意是任何位置。\n  如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。\n   delete\n 用 delete 命令把整个表的数据删除，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。\n  delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。\n   空洞\n 插入数据同样可能造成空洞。\n  如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。\n  另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。\n   重建表 #   经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。\n  重建表，就可以达到这样的目的。\n  假设现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉，可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。\n由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。表 B 的主键索引更紧凑，数据页的利用率也更高。\n把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。\n # 重建表命令 alter table A engine=InnoDB  在 MySQL 5.5 版本之前，这个命令的执行流程跟前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。\n花时间最多的步骤是往临时表插入数据的过程，在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。\n在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。\n  在 MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。\n Online DDL ，重建表的流程：\n 建立一个临时文件，扫描表 A 主键的所有数据页； 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中； 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态； 用临时文件替换表 A 的数据文件。   由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。\n   MDL锁\n alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。\n   退化原因\n 为了实现 Online，MDL 读锁不会阻塞增删改操作。\n   为什么加锁\n 为了保护自己，禁止其他线程对这个表同时做 DDL。\n      对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。\n  上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，推荐使用 GitHub 开源的 gh-ost 来做。\n Online 和 inplace #   非 inplace   把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。\n alter table t engine=innodb,ALGORITHM=copy;  当使用 ALGORITHM=copy 的时候，表示的是强制拷贝表，对应的流程相当于MySQL 5.5 版本之前重建表的过程。\n  Online DDL   根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。\n # alter table t engine=InnoDB 隐含意思： alter table t engine=innodb,ALGORITHM=inplace; 两者关系：\n DDL 过程如果是 Online 的，就一定是 inplace 的； 反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。  "},{"id":30,"href":"/docs/redis/","title":"Redis","section":"Docs","content":"title: \u0026ldquo;Redis\u0026rdquo; date: 2022-01-31T15:47:28+08:00 weight: 5\n"},{"id":31,"href":"/docs/%E5%BE%AE%E6%9C%8D%E5%8A%A1/","title":"微服务","section":"Docs","content":"title: \u0026ldquo;微服务\u0026rdquo; weight: 7\n"}]