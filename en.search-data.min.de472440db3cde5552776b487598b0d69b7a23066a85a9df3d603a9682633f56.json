[{"id":0,"href":"/docs/elasticsearch/mds/0_pre/","title":"前置知识","section":"Elasticsearch","content":"倒排索引 #  核心组成 #    单词词典（Term Dictionary）\n 记录所有文档的单词，记录单词到倒排列表的关联关系；一般比较大，可以通过B+树或者哈希拉链法实现，以满足高性能的插入与查询。\n   倒排索引表（Posting List）\n 记录了单词对应的文档集合，由倒排索引项组成。倒排索引项（Posting）：\n 文档ID； 词频TF：该单词在文档中出现的次数，用于相关性评分； 位置（Position）：单词在文档中分词的位置。用于语句搜索（phrase query）； 偏移（Offset）：记录单词的开始结束位置，实现高亮显示。       默认使用 #   Elasticsearch的JSON文档中的每个字段，都有自己的倒排索引；\n可以指定对某些字段不做索引：优点：节省空间；缺点：字段无法被搜索。\n 搜索的相关性 #  搜索是用户和搜索引擎的对话，用户关心的是搜索引擎结果的相关性：\n 是否可以找到所有相关的内容 有多少不相关的内容被返回了 文档的打分是否合理 结合业务需求，平衡结果排  衡量相关性：\n Precision（查准率）：尽可能返回较少无关文档 Recall（查全率）：尽量返回较多相关文档 Ranking：能否按照相关度排序   绿色代表应该被搜索到的结果，黄色代表不应该被搜索到的结果。\n Precision = True Postive / (True and False Positives)\nRecall = True Postive / (True Positives + False Negtives)\n相关性算分 #   搜索的相关性算分，描述了一个文档和查询语句的匹配程度。Elasticsearch会对每个匹配查询条件的结果进行算分_score； 打分的本质是排序，需要把最符合用户需求的文档排在前面。ES5之前，默认的相关性算分采用TF-IDF，现在采用BM 25。  词频 #    Term Frequency：检索词在一篇文档中出现的频率，计算公式： TF = 检索词出现的次数 / 文档的总字数。\n 度量一条查询和结果文档相关性的简单方法：简单将搜索中的每一个词的TF进行相加。比如说搜索\u0026quot;区块链的应用\u0026quot;，相关性 = TF（区块链） + TF（的） + TF（应用）。\n   Stop word：有些词出现再多次也无需计算到相关性中。比如，的”在文档中出现了很多次，但是对贡献相关度几乎没有用处，不应该考虑他们的TF。\n  逆文档频率 #  DF：检索词在所有文档中出现的频率。 Inverse Document Frequency：简单说 = log（全部文档数/检索词出现过得文档总数）；\n 假设搜索\u0026quot;区块链的应用\u0026quot;，“区块链”在相对较少的文档中出现；“应用”在相对比较多的文档中出现；“Stop Word”在大量文档中出现。所以“区块链”这个词比“应用”这个词共享度更高。\n TF-IDF本质就是将TF求和变成了加权求和： TF（区块链）* IDF（区块链） + IDF（的）* TF（的） + TF（应用）* IDF（应用）\nTF-IDF的概念 #  TF-IDF被公认为是信息检索领域最重要的发明； 除了在信息检索，在文献分类和其他相关领域有这非常广泛的应用； IDF的概念，最早是剑桥大学的“斯巴克 琼斯”提出：\n 1972年-“关键词特殊性的统计解释和它在文献检索中的应用”；但是没有理论上解释IDF应该使用log（全部文档数/检索词出现过得文档总数），而不是其他函数。也没有做进一步的研究。\n  Lucene的TF-IDF评分公式：  BM25 #  控制算分 #   Boosting 是控制相关度的一种手段，可以对索引、字段、或查询条件使用。\n 参数boost的含义：\n 当boost \u0026gt; 1 时，打分的相关度相对性提升； 当0\u0026lt; boost \u0026lt; 1时，打分的权重相对性降低； 当boost \u0026lt; 0时，贡献负分。  分词 #  Analysis与Analyzer #   Analysis   文本分析是把全文本转换一系列单词（term/token）的过程，也叫分词。\n  Analyzer   Analysis通过Analyzer来实现。\n ES在数据写入时转换词条，匹配Query语句时也需要用相同的分析器对查询语句进行分析。\nAnalyzer的组成 #   Character Filters   针对原始文本处理，例如去除html。\n  Tokenizer   按照规则切分为单词，比如按照空格。\n  Token Filter   将切分的单词进行加工，小写，删除stopwords（停用词），增加同义词。\n ES 内置的分词器 #    Standard Analyzer：默认分词器，按词切分，小写处理；\n  Simple Analyzer：按照非字母切分（符号被过滤），小写处理；\n  Stop Analyzer：小写处理，停用词过滤（the，a，is）；\n  Whitespace Analyzer：按照空格切分，不转小写；\n  Keyword Analyzer：不分词，直接将输入当做输出；\n  Patter Analyzer：正则表达式，默认\\W+（分字符分隔）；\n  Language：提供了30多种常见语言的分词器；\n  Customer Analyzer：自定义分词器。\n  _analyzer API #    指定Analyzer进行测试\nGET /_analyze { \u0026#34;analyzer\u0026#34; : \u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34; : \u0026#34;Master Elasticsearch, elasticsearch in Action\u0026#34; }   指定索引的字段进行测试\nPOST 索引名/_analyze { \u0026#34;field\u0026#34; : \u0026#34;title\u0026#34;, \u0026#34;text\u0026#34; : \u0026#34;Master Elasticsearch, elasticsearch in Action\u0026#34; }   自定义分词器进行测试\nPOST /_analyze { \u0026#34;tokenizer\u0026#34; : \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34; : [\u0026#34;lowercase\u0026#34;], \u0026#34;text\u0026#34; : \u0026#34;Master Elasticsearch, elasticsearch in Action\u0026#34; }   自然语言与查询Recall #  当处理人类自然语言时，有些情况，尽管搜索和原文不完全匹配，但是希望搜到一些内容；Quick brown fox 和 fast brown fox / Jumping fox 和 Jumped foxes。\n一些可采取的优化：归一化词元：清除变音符号；抽取词根：清除单复数和时态差异；包含同义词；拼写错误：拼写错误，或者同音异形词。\n多语言混合的挑战 #    一些具体的多语言场景\n 不同索引使用不同的语言；同一索引中，不同的字段使用不同的语言；一个文档的一个字段内混合不同的语言。\n   混合语言存在的一些挑战\n 词干提取：以色列文档，包含了希伯来语、阿拉伯语、俄语和英文；不正确的文档频率：英文为主的文章中，德文算分高（稀有）；需要判断用户搜索时使用的语言，语言识别。例如，根据语言，查询不同的索引。\n   分词的挑战 #    英文分词\n You\u0026rsquo;re分成一个还是多个？Half-backed\n   中文分词\n 分词标准：哈工大标准中，姓和名分开。HanLP是在一起的。具体情况需制定不同的标准；\n歧义（组合型歧义，交集型歧义，真歧义）：中华人民共和国/美国会通过对台收武法案/上海仁和服装厂。\n   中文分词方法的演变 #    查字典\n 最容易想到的分词方法（北京航空大学的梁南元教授提出）；一个句子从左到右扫描一遍。遇到有的词就标示出来。找到复合词，就找最长的；不认识的字符就分割成单个字词。\n   最小词数的分词理论\n 哈工大王晓龙博士把查字典的方法理论化，一句话应该分成数量最少的词串；遇到二义性的分隔，无能为力（例如：发展中国家、上海大学城书店）；用各种文化规则来解决二义性，都并不成功。\n   统计语言模型\n 1990年前后，清华大学电子工程系郭进博士。解决了二义性问题，将中文分词的错误率降低了一个数量级。概率问题，动态规划 + 利用维特比算法快速找到最佳分词。\n   基于统计的机器学习算法\n 这类目前常用的算法是HMM、CRF、SVM、深度学习等算法；\n   中文分词器现状 #   中文分词器以统计语言模型为基础，经过几十年的发展，今天基本已经可以看做是一个已经解决的问题。不同分词器的好坏，主要的差别在于数据的使用和工程使用的精度。常见的分词器都是使用机器学习算法和词典相结合，一方面能够提高分词准确率，另一方面能够改善领域适应性。\n 一些中文分词器 #    HanLP\n  IK\n  Pinyin\n  "},{"id":1,"href":"/docs/elasticsearch/mds/1_basic/","title":"基本使用","section":"Elasticsearch","content":"基本概念 #  文档（Document） #    Elasticsearch是面向文档的，文档是所有课搜索数据的最小单位；\n 可以理解为关系型数据库中的一条记录。\n   文档会被序列化成JSON格式，保存在Elasticsearch 中；\n JSON对象由字段组成；每个字段都有对应的字段类型（字符串/数值/布尔/日期/二进制/范围类型）。\n   每个文档都有一个Unique ID。\n 可以自己指定ID；或者通过Elasticsearch自动生成。\n   JSON文档 #   字段的类型可以通过指定或者通过Elasticsearch自动推算； 支持数组/嵌套。  文档元数据 #   _index：文档所属的索引名； _type：文档所属的类型名； _id：文档的唯一ID； _source：文档的原始JSON数据； _all：整合所有字段内容到该字段，已被废除； _version：文档的版本信息； _score：相关性打分。  Response元数据 #   took：花费的时间； total：符合条件的总文档数； hits：结果集，默认前十个文档； _index：索引名； _id：文档的id； _score：相关度评分； _source：文档原始信息。  索引（Index） #   索引是文档的容器，是一类文档的集合。Index体现了逻辑空间的概念：每个索引都有自己的Mapping定义，用于定义包含的文档字段名和字段类型；Shard体现了物理空间的概念：索引中的数据分散在Shard上。\n   Mapping定义文档字段的类型\n  Setting定义不同的数据分布\n  Type\n 7.0之前，一个Index可以设置多个Types；6.0开始，Type已经被Deprecated。7.0开始，一个索引只能创建一个Type-\u0026quot;_doc\u0026quot;。\n   索引的不同语义 #   名词：一个Elasticsearch集群中，可以创建很多个不同的索引； 动词：保存一个文档到Elasticsearch的过程也叫索引（indexing）； ES中，创建一个倒排索引的过程。名词：一个B树索引，一个倒排索引。  与关系型数据库对比 #     RDBMS Elasticsearch     Table Index（Type）   Row Document   Column Field   Schema Mapping   SQL DSL   高性能全文检索 事务性/Join    基本操作 #  Rest api #    创建索引\nPUT movies   查看所有索引\n_cat/indices   查看索引相关信息\nGET 索引名   查看索引文档总数\nGET 索引名/_count   查看状态为绿的索引\nGET /_cat/indices?v\u0026amp;health=green   按照文档个数排序\nGET /_cat/indices?v\u0026amp;s=docs.count:desc   查看具体的字段\nGET /_cat/indices/关键字*?pri\u0026amp;v\u0026amp;h=health,index,pri,rep,docs.count,mt   占用多少内存\nGET /_cat/indices?v\u0026amp;h=i,tm\u0026amp;s=tm:desc   CRUD #   create document. 自动生成 _id  POST users/_doc { \u0026#34;user\u0026#34; : \u0026#34;Mike\u0026#34;, \u0026#34;post_date\u0026#34; : \u0026#34;2019-04-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Kibana\u0026#34; }  create document. 指定Id。如果id已经存在，报错  PUT users/_doc/1?op_type=create { \u0026#34;user\u0026#34; : \u0026#34;Jack\u0026#34;, \u0026#34;post_date\u0026#34; : \u0026#34;2019-05-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Elasticsearch\u0026#34; }  create document. 指定 ID 如果已经存在，就报错  PUT users/_create/1 { \u0026#34;user\u0026#34; : \u0026#34;Jack\u0026#34;, \u0026#34;post_date\u0026#34; : \u0026#34;2019-05-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Elasticsearch\u0026#34; }  Update 指定 ID (先删除，在写入)  PUT users/_doc/1 { \u0026#34;user\u0026#34; : \u0026#34;Mike\u0026#34; }  在原文档上增加字段  POST users/_update/1/ { \u0026#34;doc\u0026#34;:{ \u0026#34;post_date\u0026#34; : \u0026#34;2019-05-15T14:12:12\u0026#34;, \u0026#34;message\u0026#34; : \u0026#34;trying out Elasticsearch\u0026#34; } } PUT 必须指定id；POST 则非必须指定id。\n HTTP协议规定，POST方法修改资源状态时，URL指示的是该资源的父级资源，待修改资源的ID信息在请求体中携带。而PUT方法修改资源状态时，URL直接指示待修改资源。因此，同样是创建资源，重复提交POST请求可能产生两个不同的资源，而重复提交PUT请求只会对其URL中指定的资源起作用，也就是只会创建一个资源。\n  删除文档  DELETE users/_doc/1 Bulk API #   Bulk 操作  { \u0026#34;index\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; } } { \u0026#34;field1\u0026#34; : \u0026#34;value1\u0026#34; } { \u0026#34;delete\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34; } } { \u0026#34;create\u0026#34; : { \u0026#34;_index\u0026#34; : \u0026#34;test2\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;3\u0026#34; } } { \u0026#34;field1\u0026#34; : \u0026#34;value3\u0026#34; } { \u0026#34;update\u0026#34; : {\u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;} } { \u0026#34;doc\u0026#34; : {\u0026#34;field2\u0026#34; : \u0026#34;value2\u0026#34;} }  mget 操作  GET /_mget { \u0026#34;docs\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; }, { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34; } ] } GET /_mget { \u0026#34;docs\u0026#34; : [ { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34;, \u0026#34;_source\u0026#34; : false }, { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;2\u0026#34;, \u0026#34;_source\u0026#34; : [\u0026#34;field3\u0026#34;, \u0026#34;field4\u0026#34;] }, { \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;3\u0026#34;, \u0026#34;_source\u0026#34; : { \u0026#34;include\u0026#34;: [\u0026#34;user\u0026#34;], \u0026#34;exclude\u0026#34;: [\u0026#34;user.location\u0026#34;] } } ] }  URI中指定index  GET /test2/_mget { \u0026#34;docs\u0026#34; : [ { \u0026#34;_id\u0026#34; : \u0026#34;1\u0026#34; }, { \u0026#34;_id\u0026#34; : \u0026#34;3\u0026#34; } ] }  msearch 操作  POST kibana_sample_data_ecommerce/_msearch {} {\u0026#34;query\u0026#34; : {\u0026#34;match_all\u0026#34; : {}},\u0026#34;size\u0026#34;:1} {\u0026#34;index\u0026#34; : \u0026#34;kibana_sample_data_flights\u0026#34;} {\u0026#34;query\u0026#34; : {\u0026#34;match_all\u0026#34; : {}},\u0026#34;size\u0026#34;:2} 常见错误返回 #     问题 原因     无法连接 网络故障或集群挂了   连接无法关闭 网络故障或节点出错   429 集群过于繁忙   4xx 请求体格式有错   500 集群内部错误    Search API #  URI Search #   在URL中使用查询参数。\n   参数\n q：指定查询语句，使用Query String Syntax； df：默认字段，不指定时，会对所有字段进行查询； Sort排序 / from 和 Size 用于分页； Profile 可以查看查询时如何执行。    Query String Syntax\n  指定字段\n# 查询title字段包含2021的数据，使用的是 TermQuery（title字段是text类型） GET /movies/_search?q=2012\u0026amp;df=title # 另一种写法 GET /movies/_search?q=title:2021 # 带上sort等参数 GET /movies/_search?q=2012\u0026amp;df=title\u0026amp;sort=year:desc\u0026amp;from=0\u0026amp;size=10\u0026amp;timeout=1s   泛查询\n# 查询所有字段包含或等于2021的数据，使用的是 DisjunctionMaxQuery  GET /movies/_search?q=2012   Term vs Phrase\n# 查询title字段中包含Beautiful 和 Mind的数据，使用的是 PhraseQuery，Phrase查询，还要求前后顺序保持一致 GET /movies/_search?q=title:\u0026#34;Beautiful Mind\u0026#34; # 查询title字段包含Beautiful 或其他字段包含 Mind的数据，使用TermQuery（对title字段）和DisjunctionMaxQuery （对所有字段） GET /movies/_search?q=title:Beautiful Mind   分组与引号\n TermQuery 使用括号括起来；PhraseQuery 使用引号括起来。\n # 查询title字段包含Beautiful 或Mind 的数据，使用的是 TermQuery  GET /movies/_search?q=title:(Beautiful Mind)   布尔操作\n 两个TermQuery在一起，默认是or的关系，其他关系操作符： AND / OR / NOT\n   分组\n +表示 msut -表示 must_not\n # 查询title中包含了Beautiful 和Mind 的数据，使用的是BooleanQuery GET /movies/_search?q=title:(Beautiful AND Mind) # 查询title中包含了Beautiful 但不包含Mind 的数据，使用的是BooleanQuery GET /movies/_search?q=title:(Beautiful NOT Mind) # 等价于上一句 GET /movies/_search?q=title:(+Beautiful -Mind) # 查询title包含了Mind和可能包含Beautiful 的数据，使用的是BooleanQuery GET /movies/_search?q=title:(Beautiful %2BMind)   范围查询\n 区间表示：[]闭区间，{}开区间\n # 查询year字段大于1980的数据，使用的是IndexOrDocValuesQuery GET /movies/_search?q=year:\u0026gt;=1980 # 查询 year字段大于2010小于2018的数据，使用的是IndexOrDocValuesQuery GET /movies/_search?q=year:[2010 TO 2018]   通配符查询（通配符查询效率低，占用内存大，不建议使用）\n ? 代表1个字符，* 代表0个或多个字符\n # 查询title字段中有b开头的term的数据，使用的是MultiTermQueryConstantScoreWrapper GET /movies/_search?q=title:b*   模糊匹配 \u0026amp; 近似匹配\n# 查询title字段中类似beautifl（有一个字符的误差）的数据，使用的是BoostQuery GET /movies/_search?q=title:beautifl~1 # 查询title字段中有类似Lord Rings的短语，中间可以有小于2个间隔，使用的是PhraseQuery GET /movies/_search?q=title:\u0026#34;Lord Rings\u0026#34;~2     Request Body Search #   使用Elasticsearch提供的，基于JSON格式的更加完备的Query Domain Specific Language（DSL）。\n   分页：from，size\n  排序：sort：[{\u0026ldquo;字段名\u0026rdquo; : \u0026ldquo;desc\u0026rdquo;}]\n  _source filtering\n 如果_source没有存储，那就只返回匹配的文档的元数据；_source支持使用通配符：_source[\u0026ldquo;name*\u0026quot;]。\n   脚本字段：\n 使用painless脚本，计算出一个结果作为字段。\n # order_date字段和hello拼接作为一个新字段 GET kibana_sample_data_ecommerce/_search { \u0026#34;script_fields\u0026#34;: { \u0026#34;new_field\u0026#34;: { \u0026#34;script\u0026#34;: { \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;doc[\u0026#39;order_date\u0026#39;].value+\u0026#39;hello\u0026#39;\u0026#34; } } }, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } }   使用Match\n# operator为and表示两个term是and的关系，默认为or的关系 POST movies/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;last christmas\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;and\u0026#34; } } } }   短语搜索 - Match Phrase\n# slop表示短语之间可以有多少个位置 POST movies/_search { \u0026#34;query\u0026#34;: { \u0026#34;match_phrase\u0026#34;: { \u0026#34;title\u0026#34;:{ \u0026#34;query\u0026#34;: \u0026#34;one love\u0026#34;, \u0026#34;slop\u0026#34;: 1 } } } }   Query String\n 类似于URI查询\n # 检索内容中可以有操作符，例如AND 、OR POST 索引名/_search { \u0026#34;query\u0026#34; : { \u0026#34;query_string\u0026#34; : { \u0026#34;default field\u0026#34; : \u0026#34;字段名\u0026#34;, \u0026#34;query\u0026#34; : \u0026#34;检索内容\u0026#34; } } }   Simple Query String\n  类似于Query String，但会忽略错误的语法，同时只支持部分查询语法； 不支持 AND OR NOT，会当做字符串处理； Term 之间默认关系是OR，可以指定Operator。   POST 索引名/_search { \u0026#34;query\u0026#34; : { \u0026#34;simple_query_string\u0026#34; : { \u0026#34;fields\u0026#34; : [\u0026#34;字段名\u0026#34;], \u0026#34;query\u0026#34; : \u0026#34;检索内容\u0026#34;, \u0026#34;default_operator\u0026#34; : \u0026#34;AND\u0026#34; } } }   Mapping #   Mapping类似数据库中的schema的定义，作用如下：\n定义索引中的字段的名称；\n定义字段的数据类型，例如字符串、数字、布尔；\n字段，倒排索引的相关配置（Analyzed or Not Analyzed）。\nMapping会把JSON文档映射成Lucene所需要的的扁平格式；\n一个Mapping属于一个索引的Type：每个文档都属于一个Type；一个Type有一个Mapping定义；7.0开始，不需要再Mapping定义中指定type信息。\n 字段的数据类型 #    简单类型\n  Text/Keyword Date Integer/Floating Boolean IPv4 \u0026amp; IPv6     复杂类型\n 对象类型/嵌套类型    特殊类型\n geo_point \u0026amp; geo_shape / percolator     假设要实现多字段类型，厂商名字实现精确匹配：\n 增加一个keyword字段 使用不同的analyzer：  不同语言 拼音字段的搜索 还支持为搜索和索引指定不同的analyzer     Dynamic Mapping #   写入文档时，如果索引不存在，会自动创建索引；Dynamic Mapping 的机制，使得我们无需手动定义Mappings。Elasticsearch会自动根据文档信息，推算出字段的类型；有时候会推算的不对，例如地理位置信息；类型设置不对时，会导致一些功能无法正常运行，例如Range查询。\n   类型字段识别\n   JSON类型 Elasticsearch类型     字符串 匹配日期格式，设置成Date   字符串 配置数字设置为float或者long，该选项默认关闭   字符串 设置为Text，并增加keyword子字段   布尔值 boolean   浮点数 float   整数 long   对象 Object   数组 由第一个非空数值的类型决定   空值 忽略      修改Mapping的字段类型\n  新增加字段\n   Dynamic 新增字段时候的表现     true 一旦有新增字段的文档写入，Mapping也同时被更新   false Mapping不会被更新，新增字段的数据无法被索引，但信息会出现在_source中   strict 文档写入失败      对已有字段\n 一旦已有数据写入，就不再支持修改字段定义。Lucene实现的倒排索引，一旦生产后，就不允许修改。\n   如果希望改变字段类型，必须Reindex API，重建索引。\n 如果修改了字段的数据类型，会导致已被索引的属于无法被搜索；如果是增加新的字段，就不会有这样的影响。\n     显示Mapping #  PUT 索引名 { \u0026#34;mappings\u0026#34; : {} }  手写，减少工作量，减少出错概率：\n创建一个临时的index，写入一些样本数据；\n通过访问Mapping API 获得该临时文件的动态Mapping定义；\n修改后用，使用该配置创建索引；\n删除临时索引。\n 常见参数 #    index-控制当前字段是否被索引。默认为true\n  Index Options\n  docs-记录doc id； freqs-记录doc id 和 term frequencies； positions-记录doc id / term frequencies / term position； offsets-记录doc id / term frequencies / term position / character offects。    Text 类型默认记录positions，其他默认 docs。\n   null_value；\n 需要对Null值实现搜索； 只有Keyword类型支持设定null_value。    copy_to；\n _all 在 7中被copy_to所替代；满足一些特定的搜索需求；copy_to将字段的数值拷贝到目标字段，实现类似_all的作用；copy_to的目标字段不出现在_source中。\n   数组类型；\n 任何字段，都可以包含多个相同类型的数值。\n   Index Template #   设定Mappings和Settings，并按照一定的规则，自动匹配到新创建的索引之上。也就是新创建索引时，不需要显示设置Mappings和Setting。\n 模板仅在一个索引被创建时，才会产生作用。修改模板不会影响已创建的索引； 可以设定多个索引模板，这些设置会被“merge”在一起； 可以指定“order”的数值，控制“merging”的过程。     工作方式\n 当一个索引被创建时：\n 应用Elasticsearch默认的settings 和 mappings； 应用order数值低的Index Template中的设定； 应用order高的Index Template中的设定，之前的设定会被覆盖； 应用创建索引时，用户所指定的Settings和Mappings，并覆盖之前模板中的设定。 优先级：用户指定 \u0026gt; order高 \u0026gt; order低 \u0026gt; ES默认     demo\n  创建Index Template\n# 匹配所有索引，设置主分片为1，副本分片为1 PUT _template/template_default { \u0026#34;index_patterns\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;order\u0026#34; : 0, \u0026#34;version\u0026#34;: 1, \u0026#34;settings\u0026#34;: { \u0026#34;number_of_shards\u0026#34;: 1, \u0026#34;number_of_replicas\u0026#34;:1 } } # 匹配名字为test开头的索引， PUT /_template/template_test，设置主分片为1，副本分片为1，关闭日期推测，打开数字推测 { \u0026#34;index_patterns\u0026#34; : [\u0026#34;test*\u0026#34;], \u0026#34;order\u0026#34; : 1, \u0026#34;settings\u0026#34; : { \u0026#34;number_of_shards\u0026#34;: 1, \u0026#34;number_of_replicas\u0026#34; : 2 }, \u0026#34;mappings\u0026#34; : { \u0026#34;date_detection\u0026#34;: false, \u0026#34;numeric_detection\u0026#34;: true } }   查看template\n# 查看名为template_default的模板 GET /_template/template_default # 查看名字以temp开头的模板 GET /_template/temp*   创建索引\nPUT testmy { \u0026#34;settings\u0026#34;:{ \u0026#34;number_of_replicas\u0026#34;:5 } } # 查看索引 GET testmy/_mapping GET testmy/_settings     Dynamic Template #   应用在某个索引上面，根据Elasticsearch识别的数据类型，结合字段名称，来动态设定字段类型。\n例如：\n 所有字符串类型都设定成keyword，或者关闭keyword字段； is开头的字段都设置成boolean； long开头的字段都设置成long类型。     demo\n# 类型为string设置字段为keyword类型，类型为string且名字以字段名is开头，设置字段为boolean类型 PUT my_index { \u0026#34;mappings\u0026#34;: { \u0026#34;dynamic_templates\u0026#34;: [ { \u0026#34;strings_as_boolean\u0026#34;: { \u0026#34;match_mapping_type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;match\u0026#34;:\u0026#34;is*\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; } } }, { \u0026#34;strings_as_keywords\u0026#34;: { \u0026#34;match_mapping_type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } ] } } # 匹配字段名为name.*的字段，不匹配字段名为*.middle的字段 PUT my_index { \u0026#34;mappings\u0026#34;: { \u0026#34;dynamic_templates\u0026#34;: [ { \u0026#34;full_name\u0026#34;: { \u0026#34;path_match\u0026#34;: \u0026#34;name.*\u0026#34;, \u0026#34;path_unmatch\u0026#34;: \u0026#34;*.middle\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;copy_to\u0026#34;: \u0026#34;full_name\u0026#34; } } } ] } }   "},{"id":2,"href":"/docs/elasticsearch/mds/2_distribute/","title":"分布式原理","section":"Elasticsearch","content":"分布式特性 #   Elasticsearch 天生就是分布式架构。\n   高可用性\n 服务可用性：允许有节点停止服务； 数据可用性：部分节点丢失，不会丢失数据。    可扩展性\n 请求量提升/数据不断增长（将数据分布到所有节点上）。    带来的好处\n 存储支持水平扩容，支持PB级数据； 提高系统的可用性，部分节点停止服务，整个集群的服务不受影响。    不同集群的设置\n 不同的集群通过不同的名字来区分，默认名字 elasticsearch ； 通过配置文件修改，或者在命令行中 -E cluster.name = clustername 进行设定。    节点 #   节点是一个Elasticsearch 的实例，其本质就是一个JAVA进程。一台机器上可以运行多个Elasticsearch进程，但是生产环境一般建议一台机器上就运行一个Elasticsearch实例。\n每一个节点都有名字，通过配置文件配置，或者启动的时候 -E node.name = nodename指定；每一个节点在启动之后，会分配一个UID，保存在data目录下。\n   Coordinating Node\n 处理请求的节点，叫Coordinating Node。路由请求道正确的节点，例如创建索引的请求，需要路由到Master节点。\n  所有节点默认都是Coordinating Node； 通过将其他类型设置为False，使其成为Dedicated Coordinating Node。    Data Node\n 可以保存数据的节点，叫做Data Node，在数据扩展上起到了至关重要的作用（由Master Node决定如何把分片分发到数据节点上）。通过增加 Data Node，可以解决数据水平扩展和解决数据单点问题。\n  同一索引，主分片和副本分片不能分配在同一节点，防止某一节点宕机时数据丢失。如果某一个集群只有一个节点，此时某一个索引又存在副本分片，此时集群状态是黄色的，因为无法分配副本分片；如果该集群后续有节点加入，会在新加入的节点创建副本分片。\n  节点启动后，默认就是数据节点； 可以设置node.data:false禁止。    Master Node\n Master Node的职责：处理创建，删除索引等请求/决定分片被分配到哪个节点/负责索引的创建于删除；维护并且更新Cluster State。\n  最佳实践  Master非常重要，在部署上需要考虑解决单点的问题； 为一个集群设置多个Mastger节点/每个节点只承担Master的单一角色。      Master Eligible Node\n 一个集群，支持配置多个Master Eligible节点。这些节点可以在必要时（如Master节点出现故障，网络故障时）参与选主流程，成为Master节点；当集群内第一个Master eligible节点启动的时候，它会将自己选举成Master节点。\n  每个节点启动后，默认就是一个Master eligible节点； 可以设置node.master:false禁止。    默认节点类型\n   节点类型 配置参数 默认值     Master Eligible node.master true   data ode.data true   ingest node.ingest true   coordinating only 无 设置上面三个参数全为false   machine learning node.ml true（需要 enable x-pack）      分片 #   分片ES中最小的工作单元，是一个Lucene的Index。\n   Primary Shard - 提升系统存储容量\n 通过主分片，将数据分布在所有节点上，实现存储的水平扩展。\n主分片（Primary Shard）数在索引创建的时候指定，后续默认不能修改，如果修改，需重建索引。\n   Replica Shard - 提高数据可用性\n 通过引入副本分配（Replica Shard）\n  提高数据的可用性。一旦主分片丢失，副本分配可以Promote成主分片。副本分片数可以动态调整。每个节点上都有完备的数据。如果不设置副本分片，一旦节点硬件故障，就有可能造成数据丢失。\n  副本分片由主分片（Primary Shard）同步。通过支持增加Replica个数，一定程度可以提高读取吞吐量。\n     分片数的设定\n  主分片数过小\n 如果该索引增长的很快，集群无法通过增加节点实现对这个索引的数据扩展。\n   主分片数过大\n 导致单个Shard容量很小，引发一个节点上有过多的分片，影响性能。\n   副本分片数设置过多\n 副本分片数设置过多，会降低集群整体的写入性能。\n     倒排索引的不可变性 #   倒排索引采用Immutable Design 一旦生成，不可更改。\n   不可变性优势\n 无需考虑并发写文件的问题，避免了锁机制带来的性能问题； 一旦读入内核的文件系统缓存，便留在那里。只要文件系统存有足够的空间，大部分请求会直接请求内存，不会命中磁盘，提升了很大的性能； 缓存容易生成和维护/数据可以被压缩。    不可变性带来的挑战\n如果需要让一个新的文档可以被搜索，需要重建整个索引。\n  Lucene Index #   在Lucene中，单个倒排索引文件被称为Segment。Segment是自包含的，不可变更的。\n  多个Segments汇总在一起，称为Lucene的Index，其对应的就是Es中的Shard。\n   新文档写入时\n会生成新的Segment，查询时会同时查询所有的Segments，并且对结果汇总。Lucene中有一个文件，用来记录所有Segments信息，叫做Commit Point。\n  删除文档信息时\n保存在.del文件中，查询时会过滤掉。\n  分片生命周期 #   Refresh   将Index Buffer写入Segment的过程叫Refresh。Refresh 不执行 fsync操作。如果系统有大量的数据写入，那就会产生很多的Segment。\nRefresh后，数据就可以被搜索到了。这也是为什么Elasticsearch被称为近实时搜索。\n  Refresh 频率：默认1s发生一次，可通过index.refresh_interval 配置。 其他 Refresh时机：Index Buffer 被占满时，会触发Refresh，默认值是JVM的 10%。  Transaction Log   Segment写入磁盘的过程相对耗时，借助文件系统缓存，Refresh时，先将Segment写入缓存以开放查询；为了保证数据不会丢失，所以在Index文档时，同时写Transaction Log，高版本开始，Transaction Log默认落盘，每个分片有一个Transaction Log。\n在ES Refresh时，Index Buffer 被清空，Transaction Log 不会清空。\n Flush \u0026amp; Lucene Commit   调用Refresh，Index Buffer 清空并且 Refresh；调用fsync，将缓存中的Segments写入磁盘；清空（删除）Transaction Log.\n  频率：默认30分钟调用一次； 其他Flush 时机：Transaction Log满了会调用（默认512M）。  Merge   Segment很多，需要被定期合并。Merge可以减少Segments，真正删除已经删除的文档（.del文件）。\n ES 和 Lucene 会自动进行Merge 操作，也可以手动调用：\nPOST my_index/_forcemerge 集群 #  集群状态 #   集群状态（Cluster State），维护了一个集群中，必要的信息：\n 所有节点信息； 所有索引和其相关的Mapping和Setting信息； 分片的路由信息。    在每个节点上都保存了集群的状态信息； 只有Master节点才能修改集群的状态信息，并负责同步给其他节点。  选主过程 #   Master Eligible Node互相Ping对方，Node Id 低的成为被选举的节点； 其他节点会加入集群，但是不承担Master节点的角色； 一旦发现被选中的主节点丢失，就会被选举出新的Master节点。  脑裂 #   Split-Brain，分布式系统的经典网络问题，当出现网络问题，假设有3个节点，一个节点和其他节点无法连接，Node 2 和 Node 3会重新选举Master，Node 1 自己还是作为 Master组成一个集群，同时更新Cluster State；导致两个Master 维护不同的 cluster state。网络恢复时，无法正确恢复。\n Es中如何解决\n  设定仲裁数\n 限定一个选举条件，设置quorum（仲裁），只有在Master eligible节点数大于quorum时，才能进行选举；Quorum = (master 节点总数/ 2) + 1。\n例如：当3个master eligible时，设置discovery.zen.minimum_master_nodes为2，避免脑裂。\n   从7.0开始，无需这个配置\n  故障转移 #   下图3个节点共同组成集群。包含了1个索引，索引设置了3个Primary Shard 和 1个 Replica。\n 故障转移过程：\n Node 1 是Master 节点，节点意外出现故障。集群重新选举Master 节点； Node 3上的R0提升为 P0，集群变黄； R0 和R1 分配，集群变绿。  集群健康状态 #   Green：健康，所有主分片和副本分片都可用； Yellow：亚健康，所有的主分片可用，部分副本分片不可用； Red：不健康状态，部分主分片不可用。  文档分布式存储 #   文档会存储在具体的某个主分片和副本分片上：例如 文档1，会存储在P0和 R0分片上。\n 文档到分片的映射算法 #   确保文档能够均匀分布在所用分片上，充分利用硬件资源，避免部分机器空闲，部分机器繁忙。\n   随机/Round Robin；\n缺点：当查询文档1，分片数很多，需要多次查询才可能查到 文档1。\n  维护文档到分片的映射关系；\n缺点：当文档数据量大的时候，维护成本高。\n  实时计算，通过文档1，自动算出，需要去哪个分片获取文档。\nshard = hash(_routing) % number_of_primary_shards\n Hash算法确保文档均匀分散到分片中；默认的_routing值是文档id；可以自行制定routing数值，例如用相同国家的商品，都分配到制定的shard（如下）。\n PUT posts/_doc/100?routing=bigdata { \u0026#34;title\u0026#34; : \u0026#34;xxxx\u0026#34; }   ES一般使用算法3，这也是设置Index Settings 后，Primary 数，不能随意更改的根本原因。\n更新一个文档的流程 #  删除一个文档的流程 #  分布式搜索机制 #   Elasticsearch 的搜索，会分两阶段进行：\n 第一阶段-Query； 第二阶段-Fetch。     Query 阶段\n 假设集群有3个节点\n 用户发出搜索请求到ES 节点。节点收到请求后，会以 Coordinating 节点的身份，在6个主副分片中随机选择3个分片，发送查询请求； 被选中的分片执行查询，进行排序。然后，每个分片都会返回From + Size 个排序后的文档Id和排序值给Coordinating节点。     Fetch 阶段\n  Coordinating Node 会将 Query 阶段，从每个分片获取的排序后的文档Id列表重新进行排序。选取From 到 From + size 个文档的Id； 以Multi get请求的方式，到相应的分片获取详细的文档数据。     Query Then Fetch 潜在的问题 #    性能问题\n 每个分片上需要查的文档个数 = from +size 最终协调节点需要处理：number_of_shard * ( from + size) 深度分页    相关性算分\n 每个分片基于自己的分片上的数据进行相关度计算。这会导致打分偏离的情况，特别是数据量很少时。相关性算分在分片之间是相互独立。当文档总数很少的情况下，如果主分片大于1，主分片数越多，相关性算分会越不准。\n 解决方法：\n  数据量不大的时候，可以将主分片数设置为1;\n  当数据量足够大的时候，只要保证文档均匀分散在各个分片上，结果一般不会出现偏差；\n  使用DFS Query Then Fetch，搜索URL中指定参数 \u0026ldquo;_search?search_type=dfs_query_then_fetch\u0026rdquo;\n 到每个分片把各分片的词频和文档频率进行搜集，然后完整的进行一次相关性算分，耗费更加多的CPU和内存，执行性能低下，一般不建议使用。\n     排序 #   排序是针对字段原始内容进行的，倒排索引无法发挥作用，需要用到正排索引。通过文档ID 和字段快速得到字段原始内容。默认情况根据算分进行排序。\nElasticsearch 有两种实现方法：\n Fielddata Doc Values （列式存储，对Text 类型无效）       Doc Values Fielddata     何时创建 索引时，和倒排索引一起创建 搜索时候动态创建   创建位置 磁盘文件 JVM Heap   优点 避免大量内存占用 索引速度块，不用占用额外磁盘空间   缺点 降低索引速度，占用额外磁盘空间 文档过多时，动态创建开销大，占用过多JVM Heap   缺省值 ES 2.x 之后 ES 1.x 及之前      关闭 Doc Values\n Doc Values 默认启用，可以通过Mapping设置关闭，可以增加索引的速度/减少磁盘空间。如果重新打开，需要重建索引。\n明确不需要做排序以及聚合分析，可以关闭。\n   分页 #   默认情况下，查询按照相关度算分排序，返回前10条记录；\nfrom ：开始位置；\nSize ：期望获取文档的总数。\n 深度分页问题 #   ES 天生就是分布式的。查询信息，但是数据分别保存在多个分片，多台机器，ES天生就需要满足排序的需要（按照相关性算分）。\n当一个查询：From = 990， Size = 10：\n 会在每个分片上先获取1000 个文档； 然后通过Coordinating Node聚合所有结果； 最后再通过排序选取前 1000个文档。    页数越深，占用内存越多。为了避免深度分页带来的内存开销。ES有一个设定，默认限定10000 个文档\n   Search After\n 避免深度分页的性能问题，可以实时获取下一页文档信息。但是有限制：\n 不支持指定页数； 只能下翻。  使用：\n 第一步搜索需要指定sort，并且保证值是唯一的（可以通过加入_id保证唯一性）; 然后使用上一次，最后一个文档的sort值进行查询。   { \u0026#34;size\u0026#34;: 1, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;search_after\u0026#34;: [10,\u0026#34;ZQ0vYGsBrR8X3IP75QqX\u0026#34;], \u0026#34;sort\u0026#34;: [ {\u0026#34;age\u0026#34;: \u0026#34;desc\u0026#34;} ,{\u0026#34;_id\u0026#34;: \u0026#34;asc\u0026#34;} ] }  通过唯一排序值定位，将每次要处理的文档数都控制在 10。\n   Scroll API\n 创建一个快照，有新的数据写入以后，无法被查到；每次查询后，输入上一次的scroll id。\n POST /users/_search?scroll=5m { \u0026#34;size\u0026#34;: 1, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34; : { } } } POST /_search/scroll { \u0026#34;scroll\u0026#34; : \u0026#34;1m\u0026#34;, \u0026#34;scroll_id\u0026#34; : \u0026#34;DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAWAWbWdoQXR2d3ZUd2kzSThwVTh4bVE0QQ==\u0026#34; }   不同的搜索类型和使用场景\n  Regular\n 需要实时获取顶部的部分文档。例如查询最新的订单。\n   Scroll\n 需要全部文档，例如导出全部数据。\n   Pagination\n From 和 Size；\n如果需要深度分页，使用 Search After。\n     处理并发读写操作 #  并发空值的必要性 #   两个Web程序同时更新某个文档，如果缺乏有效的并发，会导致更改的数据丢失。\n   悲观并发控制\n 假定有变更冲突的可能。会对资源加锁，防止冲突。例如数据库行锁。\n   乐观并发控制\n 假定冲突是不会发生的，不会阻塞正在尝试的操作。如果数据在读写中被修改，更新将会失败。应用程序决定如何解决冲突，例如重试更新，使用新的数据，或者将错误报告给用户。\n  ES采用的是乐观并发控制。\n   ES的乐观并发空值 #   ES 中的文档是不可变更的。如果你更新一个文档，会将文档标记为删除，同时增加一个全新的文档。同时文档的version字段加1。\n   内部版本控制\n if_seq_no + if_primary_term\n PUT products/_doc/1?if_seq_no=1\u0026amp;if_primary_term=1 { \u0026#34;title\u0026#34;:\u0026#34;iphone\u0026#34;, \u0026#34;count\u0026#34;:100 }   使用外部版本（使用其他数据库作为主要数据存储）\n version + version_type = external\n PUT products/_doc/1?version=30000\u0026amp;version_type=external { \u0026#34;title\u0026#34;:\u0026#34;iphone\u0026#34;, \u0026#34;count\u0026#34;:100 }   "},{"id":3,"href":"/docs/elasticsearch/mds/3_search/","title":"搜索","section":"Elasticsearch","content":"基于词项和基于全文搜索 #  基于Term的查询 #   Term是表达语义的最小单位，在Elasticsearch中，Term查询，对输入不做分词。会将输入作为一个整体，在倒排索引中查找准确的词项，并且使用相关度算分公式，为每个包含该词项的文档进行相关度算分。\n  准确查询不需要算分，可以通过 Constant Score 将查询转换成一个Filtering，避免算分，并利用缓存，提高性能。\n   Constant Score\n{ \u0026#34;query\u0026#34;: { \u0026#34;constant_score\u0026#34;: { \u0026#34;filter\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;\u0026#34; } } } } }   一些TermLevelQuery\n Term Query（精确查询） Range Query（范围查询） Exists Query（存在查询） Prefix Query（前缀查询） Wildcard Query（通配符查询）    基于全文的查询 #   索引和搜索时都会进行分词，查询字符串先传递到一个合适的分词器，然后生成一个共查询的词项列表。\n查询的时候，会先对输入的查询进行分词，然后每个词项逐个进行底层的查询，最终将结果进行合并，并为每个文档生成一个算分。\n 如下，查 “Matrix reloaded”，会查到包括Matrix或者reload的所有结果。\n 一些全文Query  Match Query Match Phrase Query Query String Query    查询结果比较 #  假设有一条文档：{ \u0026ldquo;productID\u0026rdquo; : \u0026ldquo;XHDK-A-1293-#fJ3\u0026rdquo;,\u0026ldquo;desc\u0026rdquo;:\u0026ldquo;iPhone\u0026rdquo; }，desc字段是text类型，desc.keyword是keyword类型。\n{ \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;desc\u0026#34;: { // 查不到  \u0026#34;value\u0026#34;: \u0026#34;iPhone\u0026#34; // 可以查到  // \u0026#34;value\u0026#34;:\u0026#34;iphone\u0026#34;  } } } } { \u0026#34;query\u0026#34;: { \u0026#34;term\u0026#34;: { \u0026#34;desc.keyword\u0026#34;: { // 可以查到  // \u0026#34;value\u0026#34;: \u0026#34;iPhone\u0026#34; // 查不到  \u0026#34;value\u0026#34;:\u0026#34;iphone\u0026#34; } } } } // 查询keyword类型字段时，就算使用match也不会分词 { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { // 可以查到  \u0026#34;desc.keyword\u0026#34;: \u0026#34;iPhone\u0026#34; // 查不到  \u0026#34;desc.keyword\u0026#34;:\u0026#34;iphone\u0026#34; } } } Query \u0026amp; Filtering #  ES中的查询分为：\n Query Context：相关性算分 Filter Context：不需要算分（yes or no），可以利用cache，获得更好的性能  Bool Query #   多条件查询可以使用bool查询。一个bool查询，是一个或者多个查询子句的组合，总共包括4种子句，其中2种会影响算分，2种不影响算分。\n    子语句 是否算分     must 必须匹配。贡献算分   should 选择性匹配。贡献算分   must_not Filter Context 查询子句，必须不能匹配   filter Filter Context 必须匹配，但是不贡献算分     另外，相关性并不只是全文本检索的专利。也适用于yes | no的子句，匹配的子句越多，相关性评分越高。如果多条查询子句被合并为一条复合查询语句，比如bool 查询，则每个查询子句计算得出的评分会被合并到总的相关性评分中。\n bool查询中：\n  子查询可以任意顺序出现\n  可以嵌套多个查询\n  改变权重\n// 同一层级下单竞争字段，具有相同的权重 // brown red quick dog有相同权重 POST /animals/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;brown\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;red\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;quick\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;dog\u0026#34; }} ] } } } // 通过嵌套bool查询，可以改变对算分的影响 // red和brown加起来，和上面的才有相同的权重 POST /animals/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;quick\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;dog\u0026#34; }}, { \u0026#34;bool\u0026#34;:{ \u0026#34;should\u0026#34;:[ { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;red\u0026#34; }}, { \u0026#34;term\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;brown\u0026#34; }} ] } } ] } } }     如果bool查询中，没有must条件，should中必须至少满足一条查询\n  should 算分过程\n  查询should语句中的两个查询； 加和两个查询的评分； 乘以匹配语句的总数； 除以所有总语句数。     Boosting \u0026amp; Boosting Query #    Boosting\n// 通过boost调整算分 POST blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ {\u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;apple,ipad\u0026#34;, \u0026#34;boost\u0026#34;: 1.1 } }}, {\u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;apple,ipad\u0026#34;, \u0026#34;boost\u0026#34;:2 } }} ] } } }   Boosting Query\n// pie内容的数据往后排 POST news/_search { \u0026#34;query\u0026#34;: { \u0026#34;boosting\u0026#34;: { \u0026#34;positive\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;apple\u0026#34; } }, \u0026#34;negative\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: \u0026#34;pie\u0026#34; } }, \u0026#34;negative_boost\u0026#34;: 0.5 } } }   Disjunction Max Query #   单字段多字符串查询\n POST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Brown fox\u0026#34; }}, { \u0026#34;match\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Brown fox\u0026#34; }} ] } } }  上面例子中，title与body相互竞争，不应该将分数简单叠加，而是应该找到单个最佳匹配字段的评分。\n  Disjunction Max Query是将任何与任一查询匹配的文档作为结果返回。采用字段上最匹配的评分最终评分返回。\n // 使用一个字段上的最高评分作为最终评分 POST blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;dis_max\u0026#34;: { \u0026#34;queries\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Brown fox\u0026#34; }}, { \u0026#34;match\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Brown fox\u0026#34; }} ] } } }  Tie Breaker是一个介于0到1之间的浮点数，0代表使用最佳匹配，1代表所有语句同样重要。\n通过Tie Breaker参数调整：\n 获得最佳匹配语句的评分； 将其他匹配语句的评分与tie_breaker相乘； 对以上评分求和并规范化。   MultiMatch #  单字符串多字段查询三种场景：\n  最佳字段（Best Fields）\n 当字段之间相互竞争，又相互关联。例如title 和body 这样的字段。评分来自最匹配字段。\n // Best Fields是默认类型，可以不用指定；Minimum should match等参数可以传递到生成的query中。 POST blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;best_fields\u0026#34;, \u0026#34;query\u0026#34;: \u0026#34;Quick pets\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;title\u0026#34;,\u0026#34;body\u0026#34;], \u0026#34;tie_breaker\u0026#34;: 0.2, \u0026#34;minimum_should_match\u0026#34;: \u0026#34;20%\u0026#34; } } }   多数字段（Most Fields）\n 处理英文内容时，一种常见的手段是，在主字段（English Analyzer），抽取词干，加入同义词，以匹配更多文档。相同的文本，加入子字段（Standard Analyzer），以提供更加精确的匹配。其他字段作为匹配文档提高相关度的信号。匹配字段越多越好。\n PUT /titles { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;english\u0026#34;, \u0026#34;fields\u0026#34;: {\u0026#34;std\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;,\u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;}} } } } } GET /titles/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;barking dogs\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;most_fields\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;title.std\u0026#34; ] } } }   混合字段（Cross Field）\n 对于某些实体，例如人名、地址、图书信息。需要在多个字段中确定信息，单个字段只能作为整体的一部分。希望在任何这些列出的字段中找到尽可能多的词。\n GET /titles/_search { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;barking dogs road\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cross_fields\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;and\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34; ] } } }   Function Score Query #   可以在查询结束后，对每一个匹配的文档进行一系列的重新算分，根据新生成的分数进行排序。\n 提供了几种默认的计算分值的函数：\n Weight：为每一个文档设置一个简单而不被规范化的权重 Field Value Factor：使用该数值来修改_score，例如将\u0026quot;热度\u0026quot;和\u0026quot;点赞数\u0026quot;作为算分的参考要素 Randow Score：为每一个用户使用一个不同的，随机算分结果 衰减函数：以某个字段的值为标准，距离某个值越近，得分越高 Script Score：自定义脚本完全控制所需逻辑  // 按欢迎程度提升权重：搜索的评分作为排序的主要依据，同时votes多的靠前。 POST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;popularity\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;content\u0026#34; ] } }, // 新的算分 = 老的算分 * 投票数 // 票数为0或者票数很大的时候差异很大  \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;votes\u0026#34; } } } }   使用Modifier 平滑曲线\nPOST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;popularity\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;content\u0026#34; ] } }, // 新的算分 = 老的算分 * log（1 + 投票数） // 别的modifier：log、log2p、ln、ln1p、ln2p、square、sqrt、reciprocal  \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;votes\u0026#34;, \u0026#34;modifier\u0026#34;: \u0026#34;log1p\u0026#34; } } } }   引入Factor（曲线更平滑）\nPOST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;popularity\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;content\u0026#34; ] } }, // 新的算分 = 老的算分 * log（1 + factor * 投票数）  \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;votes\u0026#34;, \u0026#34;modifier\u0026#34;: \u0026#34;log1p\u0026#34; , \u0026#34;factor\u0026#34;: 0.1 } } } }   Boost Mode 和 Max Boost\n Boost Mode ： 1.Multiply：算分与函数值的乘积； 2.Sum：算分与函数值的和； 3.Min/ Max：算分与函数取 最小/最大值； 4.Replace：使用函数值取代算分。\nMax Boost 可以将算分控制在一个最大值。\n POST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;popularity\u0026#34;, \u0026#34;fields\u0026#34;: [ \u0026#34;title\u0026#34;, \u0026#34;content\u0026#34; ] } }, \u0026#34;field_value_factor\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;votes\u0026#34;, \u0026#34;modifier\u0026#34;: \u0026#34;log1p\u0026#34; , \u0026#34;factor\u0026#34;: 0.1 }, \u0026#34;boost_mode\u0026#34;: \u0026#34;sum\u0026#34;, \u0026#34;max_boost\u0026#34;: 3 } } }   一致性随机函数\nPOST /blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;function_score\u0026#34;: { // 不同seed值，返回结果算分不同  \u0026#34;random_score\u0026#34;: { \u0026#34;seed\u0026#34;: 911119 } } } }   Suggester #   现代的搜索引擎，一般提供Suggest as you type的功能。帮助用户在输入搜索过程中，进行自动补全或者纠错。通过协助用户输入更加精准的关键词，提高后续搜索阶段文档匹配的程度。\n  搜索引擎中类似的功能，在Elasticsearch 中是通过Suggester API实现的。 原理：将输入的文本分解为Token，然后在索引的字典里查找相似的Term 并返回。\n 根据不同的适用场景，Elasticsearch 设计了4中类别的 Suggester：\n Term \u0026amp; Phrase Suggester Complete \u0026amp; Context Suggester  搜索建议 #    Term Suggester\n Suggester 就是一种特殊类型的搜索。\n // 每个建议都包含了一个算分，相似性是通过 Levenshtein Edit Distance 的算法实现的。 // 核心思想就是一个词改动多少字符就可以和另外一个词一致。提供了很多可选参数来控制相似性的模糊程度。例如“max_edits” POST /articles/_search { \u0026#34;size\u0026#34;: 1, \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;lucen rock\u0026#34; } }, \u0026#34;suggest\u0026#34;: { \u0026#34;term-suggestion\u0026#34;: { // text 里是调用时候提供的文本，通常来自用户输入的内容  \u0026#34;text\u0026#34;: \u0026#34;lucen rock\u0026#34;, \u0026#34;term\u0026#34;: { // 当无法搜索到结果时（missing），返回建议的词  \u0026#34;suggest_mode\u0026#34;: \u0026#34;missing\u0026#34;, // 会到 指定的字段body 上搜索  \u0026#34;field\u0026#34;: \u0026#34;body\u0026#34;, \u0026#34;prefix_length\u0026#34;:0, \u0026#34;sort\u0026#34;: \u0026#34;frequency\u0026#34; } } } } Suggestion Mode：\n  Missing - 如果索引中已经存在，就不提供建议；\n  Popular - 推荐出现频率更加高的词；\n  Always - 无论是否存在，都提供建议。\n  Phrase Suggester\n Phrase Suggester 在 Term Suggester 上增加了一些额外的逻辑，例如一些参数：\n Suggest Mode：missing、popular； Max Errors：最多可以拼错的Terms 数； Confidence：限制返回结果数，默认为1。     POST /articles/_search { \u0026#34;suggest\u0026#34;: { \u0026#34;my-suggestion\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;lucne and elasticsear rock hello world \u0026#34;, \u0026#34;phrase\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;body\u0026#34;, \u0026#34;max_errors\u0026#34;:2, \u0026#34;confidence\u0026#34;:0, \u0026#34;direct_generator\u0026#34;:[{ \u0026#34;field\u0026#34;:\u0026#34;body\u0026#34;, \u0026#34;suggest_mode\u0026#34;:\u0026#34;always\u0026#34; }], \u0026#34;highlight\u0026#34;: { \u0026#34;pre_tag\u0026#34;: \u0026#34;\u0026lt;em\u0026gt;\u0026#34;, \u0026#34;post_tag\u0026#34;: \u0026#34;\u0026lt;/em\u0026gt;\u0026#34; } } } } }   自动补全和基于上下文提示 #   Completion Suggester 提供了“自动完成（Auto Complete）”的功能。用户每输入一个字符，就需要即时发送一个查询请求到后端查询匹配项； 对性能要求比较苛刻。Elasticsearch 采用了不同的数据结构，并非通过倒排索引来完成。而是将 Analyze 的数据编码成 FST 和索引 一起存放。FST 会被 ES整个加载进内存，速度很快； FST 只能用于前缀查找。\n 使用Completion Suggester 的一些步骤：\n  定义Mapping，使用“completion”type\nPUT articles { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;title_completion\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;completion\u0026#34; } } } }   索引数据\n  运行“suggest”查询，得到搜索建议\n// 会返回 elk 开头的数据 POST articles/_search { \u0026#34;size\u0026#34;: 0, \u0026#34;suggest\u0026#34;: { \u0026#34;article-suggester\u0026#34;: { \u0026#34;prefix\u0026#34;: \u0026#34;elk \u0026#34;, \u0026#34;completion\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;title_completion\u0026#34; } } } }   Context Suggester #   Completion Suggester 的扩展，可以在搜索中加入更多的上下文信息，例如，输入“star”，\n 咖啡相关：建议“Starbucks”； 电影相关：“star wars”   两种类型的 Context：\n Category - 任意的字符串； Geo - 地理位置信息。  实现Context Suggester 的具体步骤：\n  定制一个Mapping\nPUT comments/_mapping { \u0026#34;properties\u0026#34;: { \u0026#34;comment_autocomplete\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;completion\u0026#34;, //  \u0026#34;contexts\u0026#34;:[{ \u0026#34;type\u0026#34;:\u0026#34;category\u0026#34;, \u0026#34;name\u0026#34;:\u0026#34;comment_category\u0026#34; }] } } }   索引数据，并且为每个文档加入Context 信息\n// 分类是电影 POST comments/_doc { \u0026#34;comment\u0026#34;:\u0026#34;I love the star war movies\u0026#34;, \u0026#34;comment_autocomplete\u0026#34;:{ \u0026#34;input\u0026#34;:[\u0026#34;star wars\u0026#34;], \u0026#34;contexts\u0026#34;:{ \u0026#34;comment_category\u0026#34;:\u0026#34;movies\u0026#34; } } } // 分类是咖啡 POST comments/_doc { \u0026#34;comment\u0026#34;:\u0026#34;Where can I find a Starbucks\u0026#34;, \u0026#34;comment_autocomplete\u0026#34;:{ \u0026#34;input\u0026#34;:[\u0026#34;starbucks\u0026#34;], \u0026#34;contexts\u0026#34;:{ \u0026#34;comment_category\u0026#34;:\u0026#34;coffee\u0026#34; } } }   结合Context 进行 Suggestion 查询\n// 会查出咖啡类型的数据 POST comments/_search { \u0026#34;suggest\u0026#34;: { \u0026#34;MY_SUGGESTION\u0026#34;: { \u0026#34;prefix\u0026#34;: \u0026#34;sta\u0026#34;, \u0026#34;completion\u0026#34;:{ \u0026#34;field\u0026#34;:\u0026#34;comment_autocomplete\u0026#34;, \u0026#34;contexts\u0026#34;:{ \u0026#34;comment_category\u0026#34;:\u0026#34;coffee\u0026#34; } } } } }   比较 #   精准度： Completion \u0026gt; Phrase \u0026gt; Term 召回率 Term \u0026gt; Phrase \u0026gt; Completion 性能 Completion \u0026gt; Phrase \u0026gt; Term  使用别名 #  # 可以添加过滤器 POST _aliases { \u0026#34;actions\u0026#34;: [ { \u0026#34;add\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;movies-2019\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;movies-lastest-highrate\u0026#34;, \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;rating\u0026#34;: { \u0026#34;gte\u0026#34;: 4 } } } } } ] } Search Templage #    新建一个Search Templage\nPOST _scripts/tmdb { \u0026#34;script\u0026#34;: { \u0026#34;lang\u0026#34;: \u0026#34;mustache\u0026#34;, \u0026#34;source\u0026#34;: { \u0026#34;_source\u0026#34;: [ \u0026#34;title\u0026#34; ], \u0026#34;size\u0026#34;: 20, \u0026#34;query\u0026#34;: { \u0026#34;multi_match\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;{{q}}\u0026#34;, \u0026#34;fields\u0026#34;: [\u0026#34;title\u0026#34;] } } } } }   查询Search Templage\nGET _scripts/tmdb   使用 Search Templage\nPOST titles/_search/template { \u0026#34;id\u0026#34;:\u0026#34;tmdb\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;q\u0026#34;: \u0026#34;barking\u0026#34; } }   配置跨集群搜索 #  水平扩展痛点 #   单集群 - 当水平扩展时，节点数不能无限增加，因为当集群的 meta 信息（节点，索引，集群状态）过多，会导致更新压力变大，单个Active Master 会成为性能瓶颈，导致整个集群无法正常工作。\n 早期版本，通过Tribe Node 可以实现多集群访问的需求，但还存在一定的问题：\n Tribe Node 会以 Client Node 的方式加入每个集群。集群中Master 节点的任务变更需要 Tribe Node 的回应才能继续； Tribe Node 不保存Cluster State 的信息，一旦重启，初始化很慢； 当多个集群存在索引重名的情况时，只能设置一种Prefer 规则。  Cross Cluster Search #   早期 Tribe Node 的方案 存在一定的问题，现在已被 Deprecated； Elasticsearch 5.3 引入了跨集群搜索的功能（Cross Cluster Search），推荐使用：\n 允许任何节点扮演 federated节点，以轻量的方式，将搜索请求进行代理； 不需要以 Client Node 的形式加入其它集群。    配置  //在每个集群上设置动态的设置 PUT _cluster/settings { \u0026#34;persistent\u0026#34;: { \u0026#34;cluster\u0026#34;: { \u0026#34;remote\u0026#34;: { \u0026#34;cluster0\u0026#34;: { \u0026#34;seeds\u0026#34;: [ \u0026#34;127.0.0.1:9300\u0026#34; ], \u0026#34;transport.ping_schedule\u0026#34;: \u0026#34;30s\u0026#34; }, \u0026#34;cluster1\u0026#34;: { \u0026#34;seeds\u0026#34;: [ \u0026#34;127.0.0.1:9301\u0026#34; ], \u0026#34;transport.compress\u0026#34;: true, \u0026#34;skip_unavailable\u0026#34;: true }, \u0026#34;cluster2\u0026#34;: { \u0026#34;seeds\u0026#34;: [ \u0026#34;127.0.0.1:9302\u0026#34; ] } } } } }  查询  // 在第一个集群搜索 GET /users,cluster1:users,cluster2:users/_search { \u0026#34;query\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gte\u0026#34;: 20, \u0026#34;lte\u0026#34;: 40 } } } } "},{"id":4,"href":"/docs/elasticsearch/mds/4_aggs/","title":"聚合","section":"Elasticsearch","content":"聚合语法 #  { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { // 与query同级的关键词  \u0026#34;\u0026lt;aggs_name\u0026gt;\u0026#34;: { // 自定义的聚合名字  \u0026#34;\u0026lt;aggs_type\u0026gt;\u0026#34;: { // 聚合的定义：不同的Type + Body  \u0026lt;aggs_body\u0026gt; }, \u0026#34;aggs\u0026#34;: {} // 子聚合查询  }, \u0026#34;\u0026lt;aggs_name_2\u0026gt;\u0026#34; : {} // 可以包含多个同级的聚合查询  } } Metric #   一些系列的统计方法，会基于数据集计算结果，除了支持在字段上进行计算，同样也支持在脚本（painless script）产生的结果之上进行计算，类比SQL中的max、min等函数。\n   单值分析：只输出一个分析结果\n   aggs_type 含义     min 最小值   max 最大值   avg 平均值   sum 求和   cardinality 去重求数量，相当于distinct count      多值分析\n   aggs_type 含义     stats 输出最低、最高、平均、求和、count的值   extended stats 多了平方和、标准差等统计值   percentile 百分位数   percentile rank 百分位排比   top hits 前几条数据      Bucket #   一组满足条件的文档，类比SQL中的Group By。\n   Terms\n 支持嵌套，嵌套后可输出 sum() group by类型聚合结果。\n 注意：keyword 类型字段默认支持doc_values；text 类型字段需要在Mappings 中开启如下配置\n\u0026#34;fielddata\u0026#34;: true 才能进行Terms Aggregation，会按照分词后的结果进行分桶。\n  优化Terms 性能\n在keyword字段上，打开eager_global_ordinals参数打开，每当有新的数据写入，term会加载到cache中。\n适用场景：1. 聚合分析经常发生；2.索引不断有文档写入。\n  排序\n指定 order，按照count 和 key进行排序。默认情况，按照count降序排列；指定size，就能返回相应的桶。\n    数字类型\n   aggs_type 含义     range 自定义数据范围作为桶，可以自定义key   Date range 日期范围   histogram 直方图   Date histogram 日期直方图      Pipeline #   对其他的聚合结果进行二次聚合，通过bucket_path 关键字指定路径。Pipeline 的分析结果会输出到原结果中，根据位置的不同，分为Sibling和Parent两类。\n   Sibling - 结果和现有分析结果同级\n   type 含义     min_bucket 最小的桶的值   max_bucket 最大的桶的值   avg_bucket 桶的值的平均数   stats_bucket 桶的值的统计值   percentiles_bucket 桶的值的百分位数      Parent - 结果内嵌到现有的聚合分析结果中\n   type 含义     dervative 求导   cumultive sum 累计求和   moving window 滑动窗口      作用范围 #   默认作用范围是 query 的查询结果集，同时支持以下方式改变作用范围：\n   Filter\n 只过滤聚合的结果集，不过滤query 的结果集。\n   Post Filter\n 只过滤 query 的结果集，不过滤聚合的结果集。\n  性能考量：post_filter会在查询之后才会被执行，因此会失去过滤在性能上帮助(比如缓存)。因此post_filter应该只和聚合一起使用，并且仅当你使用了不同的过滤条件时。    Global\n 全局聚合，不受 query 作用域的影响。\n   聚合原理 #    Min聚合分析执行流程\n  Terms聚合分析的执行流程\n  Terms Aggregation的特殊返回值\n doc_count_error_upper_bound：被遗漏的term分桶，包含的文档，可能有最大值；\n  sum_other_doc_count：除了返回结果 bucket 的terms 以外，其他terms 的文档总数（总数 - 返回的总数）。\n   当 Terms的 size为3\n  Terms 不正确demo\n Top3应该是A(12)、B(6)、D(6)。\n     解决Terms 不准的问题\n  不准的原因\n数据分散在多个分片上，Coordinating Node 无法获取数据全貌。\n  解决方案\n  当数据量不大时，设置Primary Shard 为1，实现准确性；\n  在分布式数据上，设置shard_size参数，提高精确度。\n 原理：每次从Shard上额外多获取数据，提升准确率。\n     shard_size 设定\n 调整shard_size 大小，降低doc_count_error_upper_bound来提升准确度（增加整体计算量，提高了准确度，但会降低相应时间）； shard Size 默认大小：shard size = size * 1.5 + 10      "},{"id":5,"href":"/docs/elasticsearch/mds/5_model_design/","title":"数据建模","section":"Elasticsearch","content":"反范式化设计 #  关系型数据库范式化设计 #   1NF - 消除 非主属性 对键的 部分函数依赖； 2NF - 消除 非主要属性 对键的 传递函数依赖； 3NF - 消除 主属性 对键的 传递函数依赖； BCNF - 主属性 不依赖于 主属性。   范式化设计（Normalization）的主要目标是“减少”不必要的更新；副作用：一个完全范式化设计的数据库会经常面临“查询缓慢”的问题，因为数据库越范式化，就需要Join 越多表。\n范式化节省了存储空间，但是存储空间却越来越便宜；范式化简化了更新，但是数据“读”操作可能更频繁。\n Denormailzation #   反范式化设计，数据“Flattening”，不使用关联关系，而是在文档中保存冗余的数据拷贝。\n   优点：无需处理 Joins 操作，数据读取性能好；\n Elasticsearch 通过压缩_source字段，减少磁盘空间开销。\n   缺点：不适合在数据频繁修改的场景。例如，一条数据（用户名）的改动，可能会引起很多数据的更新。\n  处理关联关系 #   关系型数据库，一般会考虑Normalize数据；在Elasticsearch，往往考虑Denormalize 数据；Denormalize 的好处：读的速度变快/无需表连接/ 无需行锁等。\n  对象类型 嵌套对象（Nested Object） 父子关联关系（Parent/Child） 应用端关联  对象类型数组查询问题 #  存储时，内部对象的边界没有考虑在内，JSON 格式被处理成扁平式键值对的结构，对多个字段查询时，可能会导致意外结果。\n{ \u0026#34;title\u0026#34;:\u0026#34;Speed\u0026#34;, \u0026#34;actors\u0026#34;:[ { \u0026#34;first_name\u0026#34;:\u0026#34;Keanu\u0026#34;, \u0026#34;last_name\u0026#34;:\u0026#34;Reeves\u0026#34; }, { \u0026#34;first_name\u0026#34;:\u0026#34;Dennis\u0026#34;, \u0026#34;last_name\u0026#34;:\u0026#34;Hopper\u0026#34; } ] } // 可以查询到上面的结果 { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ {\u0026#34;match\u0026#34;: {\u0026#34;actors.first_name\u0026#34;: \u0026#34;Keanu\u0026#34;}}, {\u0026#34;match\u0026#34;: {\u0026#34;actors.last_name\u0026#34;: \u0026#34;Hopper\u0026#34;}} ] } } } // 内部实际存储 { \u0026#34;actors.first_name\u0026#34; : [\u0026#34;Keanu\u0026#34;, \u0026#34;Dennis\u0026#34;], \u0026#34;actors.last_name\u0026#34; : [\u0026#34;Reeves\u0026#34;, \u0026#34;Hopper\u0026#34;] } Nested #   Nested数据类型：允许对象数组中的对象被独立索引；使用nested 和 properties 关键字，将所有actors 索引到多个分隔的文档；在内部，Nested 文档会被保存在两个 Lucene 文档中，在查询时做 join处理。\n // mapping定义 \u0026#34;properties\u0026#34; : { \u0026#34;actors\u0026#34; : { \u0026#34;type\u0026#34;: \u0026#34;nested\u0026#34;, \u0026#34;properties\u0026#34; : { \u0026#34;first_name\u0026#34; : {\u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;}, \u0026#34;last_name\u0026#34; : {\u0026#34;type\u0026#34; : \u0026#34;keyword\u0026#34;} }} } // 嵌套查询 { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ {\u0026#34;match\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Speed\u0026#34;}}, { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;actors\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ {\u0026#34;match\u0026#34;: { \u0026#34;actors.first_name\u0026#34;: \u0026#34;Keanu\u0026#34; }}, {\u0026#34;match\u0026#34;: { \u0026#34;actors.last_name\u0026#34;: \u0026#34;Hopper\u0026#34;} }]}}}}]}}} // 聚合查询 { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { \u0026#34;actors\u0026#34;: { \u0026#34;nested\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;actors\u0026#34; }, \u0026#34;aggs\u0026#34;: { \u0026#34;actor_name\u0026#34;: { \u0026#34;terms\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;actors.first_name\u0026#34;, \u0026#34;size\u0026#34;: 10}}}}}} Parent/Child #   对象 和 Nested 对象的局限性：每次更新，需要重新索引整个对象（包括根对象和嵌套对象）。\n  ES 提供了类似关系型数据库中 Join的实现。使用Join 数据类型实现，可以通过维护Parent/ Child 的关系，从而分离两个对象。\n父文档和子文档是两个独立的文档：更新父文档无需重新索引子文档。子文档被添加，更新或者删除也不会影响到父文档和其他的子文档。\n   定义父子关系：\n 父文档和子文档必须存在相同的分片上，确保查询join的性能；当指定子文档的时候，必须指定其对应父文档id。\n   设置索引的Mapping\nPUT my_blogs { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;blog_comments_relation\u0026#34;: { // 指明join类型  \u0026#34;type\u0026#34;: \u0026#34;join\u0026#34;, // 声明Parent/Child关系  \u0026#34;relations\u0026#34;: { // blog-\u0026gt;Parent名称  // comment-\u0026gt;Child名称  \u0026#34;blog\u0026#34;: \u0026#34;comment\u0026#34; } }, \u0026#34;content\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } } }   索引父文档\n// blog1-\u0026gt;父文档id PUT my_blogs/_doc/blog1 { \u0026#34;title\u0026#34;:\u0026#34;Learning Elasticsearch\u0026#34;, \u0026#34;content\u0026#34;:\u0026#34;learning ELK @ geektime\u0026#34;, // 声明文档类型是父文档  \u0026#34;blog_comments_relation\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;blog\u0026#34; } }   索引子文档\n// comment1-\u0026gt;子文档id // routing=blog1，确保和父文档索引到相同分片 PUT my_blogs/_doc/comment1?routing=blog1 { \u0026#34;comment\u0026#34;:\u0026#34;I am learning ELK\u0026#34;, \u0026#34;username\u0026#34;:\u0026#34;Jack\u0026#34;, \u0026#34;blog_comments_relation\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;comment\u0026#34;, // 父文档id  \u0026#34;parent\u0026#34;:\u0026#34;blog1\u0026#34; } }   按需查询文档\n// 查询所有（父子文档都会返回） POST my_blogs/_search {} // Parent Id 查询（返回子文档） POST my_blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;parent_id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;comment\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;blog2\u0026#34; } } } // Has Child 查询,返回父文档 POST my_blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;has_child\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;comment\u0026#34;, \u0026#34;query\u0026#34; : { \u0026#34;match\u0026#34;: { \u0026#34;username\u0026#34; : \u0026#34;Jack\u0026#34; } } } } } // Has Parent 查询，返回相关的子文档 POST my_blogs/_search { \u0026#34;query\u0026#34;: { \u0026#34;has_parent\u0026#34;: { \u0026#34;parent_type\u0026#34;: \u0026#34;blog\u0026#34;, \u0026#34;query\u0026#34; : { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34; : \u0026#34;Learning Hadoop\u0026#34; } } } } }     Nested vs Parent/Child #      Nested Object Parent/Child     优点 文档存储在一起，读取性能高 父子文档可以独立更新   缺点 更新嵌套的子文档时，需要更新整个文档 需要额外的内存维护关系，读取时性能相对差   适用场景 子文档偶尔更新，以查询为主 子文档频繁更新    重建索引 #  需要重建索引的场景 #   索引的Mapping 发生变更：字段类型更改，分词器及字典更新； 索引的Settings 发生变更：索引的主分片数发生改变； 集群内，集群间需要做数据迁移。  Elasticsearch 的内置提供API #    Update By Query ：在现有索引上重建\n 比如，新增加一个子字段a，使用_update_by_query可以使历史数据的a字段都被赋值。\n   Reindex：在其他索引上重建索引\nPOST _reindex { \u0026#34;source\u0026#34;: { // 跨集群Reindex，除此之外还需要elasticsearch.yml中加上ip白名单，并重启集群  \u0026#34;remote\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;http://172.16.0.39:9200\u0026#34; }, // 支持多个，使用[]即可  \u0026#34;index\u0026#34;: \u0026#34;blogs\u0026#34;, // 不设置或设置为internal,会直接将文档转储到dest中，覆盖任何发生的具有相同类型和id的document  // 使用external的话，只有当source的version更加新的时候，才更新  \u0026#34;version_type\u0026#34;: \u0026#34;external\u0026#34;, // 过滤条件  \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;elasticsearch\u0026#34; } }, // 默认1000  \u0026#34;size\u0026#34;: 1000, // 排序  \u0026#34;sort\u0026#34;: { \u0026#34;date\u0026#34;: \u0026#34;desc\u0026#34; }, // 特定field  \u0026#34;_source\u0026#34;: [\u0026#34;user\u0026#34;, \u0026#34;tweet\u0026#34;] }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;blogs_fix\u0026#34;, // 只会创建不存在的文档，文档如果已经存在，会导致版本冲突。  \u0026#34;op_type\u0026#34;: \u0026#34;create\u0026#34;, // 使用Ingest Node  \u0026#34;pipeline\u0026#34;: \u0026#34;some_ingest_pipeline\u0026#34; }, // 默认情况下，当发生version conflict的时候，_reindex会被abort。除非把conflicts设置为“proceed”  \u0026#34;conflicts\u0026#34;: \u0026#34;proceed\u0026#34;, // 使用脚本  \u0026#34;script\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;if (ctx._source.foo == \u0026#39;bar\u0026#39;) {ctx._version++; ctx._source.remove(\u0026#39;foo\u0026#39;)}\u0026#34;, \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34; } }   使用场景：\n 修改索引的主分片数； 改变字段的Mapping 中的字段类型； 集群内数据迁移/跨集群数据迁移。    注意：\n 需要启用_source； 不会拷贝源索引settings，目标索引的mappings和settings需要已经定义好。    使用Task API查询进度\nGET _tasks?detailed=true\u0026amp;actions=*reindex   取消reindex\n// task_id，可以通过上面的Task API获取 POST _tasks/task_id:1/_cancel     Ingest Pipeline #   修复与增强写入数据，简化版logstash。\n Ingest Node #   在Elasticsearch5.0之后，引入的一种新的节点类型。默认配置下，每个节点都是Ingest Node。有如下功能：\n 具有预处理数据的能力，可以拦截Index 或 Bulk API 的请求； 对数据进行转换，并重新返回给Index 或 Bulk API。    可以对数据进行一些预处理，例如：为某个字段设置默认值；重命名某个字段的字段名；对字段值进行split操作。同时支持设置Painless 脚本，对数据进行更加复杂的加工。\n Pipeline \u0026amp; Processor #   Pipeline：管道会对通过的数据（文档），按照顺序进行加工。\n  Processor：Elasticsearch 对一些加工的行为进行了抽象包装。\nElasticsearch 有很多内置的Processor。也支持通过插件的方式，实现自己的 Processor。\n // 为ES添加一个 Pipeline PUT _ingest/pipeline/blog_pipeline { \u0026#34;description\u0026#34;: \u0026#34;a blog pipeline\u0026#34;, \u0026#34;processors\u0026#34;: [ { \u0026#34;split\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;tags\u0026#34;, \u0026#34;separator\u0026#34;: \u0026#34;,\u0026#34; } }, { \u0026#34;set\u0026#34;:{ \u0026#34;field\u0026#34;: \u0026#34;views\u0026#34;, \u0026#34;value\u0026#34;: 0 } } ] } // 查看Pipleline GET _ingest/pipeline/blog_pipeline // 使用pipeline更新数据 PUT tech_blogs/_doc/2?pipeline=blog_pipeline { \u0026#34;title\u0026#34;: \u0026#34;Introducing cloud computering\u0026#34;, \u0026#34;tags\u0026#34;: \u0026#34;openstack,k8s\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You konw, for cloud\u0026#34; } // 使用pipeline重建索引数据 POST tech_blogs/_update_by_query?pipeline=blog_pipeline { \u0026#34;query\u0026#34;: {} } 内置Processor #    Split Processor\n  Remove/Rename Processor\n （例：移除一个重命名字段）\n   Append\n （为商品增加一个新的标签）\n   Convert\n （将商品价格，从字符串转换成float类型）\n   Date / JSON\n 日期格式转换，字符串转JSON对象\n   Date Index Name Processor\n （通过该处理器的文档，分配到指定时间格式的索引中）\n   Fail Processor\n （一旦出现异常，该Pipeline指定的错误信息能返回给用户）\n   Foreach Processor\n （数组字段，数组的每个元素都会使用到一个相同的处理器）\n   Grok Processor\n （日志的日期格式切割）\n   Gsub/Join/Split\n （字符串替换/数组转换字符串/字符串转数组）Lowercase/ upcase （大小写转换）\n   Ingest Node 和 Logstash比较 #      Logstash Ingest Node     数据输入与输出 支持从不同的数据源读取，并写入不同的数据源 支持从ES Rest api获取数据，并写入ES   数据缓冲 实现了简单的数据队列，支持重写 不支持缓冲   数据处理 支持大量的插件，也支持定制开发 内置有插件，也可开发插件进行扩展   配置与使用 增加了一定的架构复杂度 无需额外部署    Painless #   Elasticsearch 5.x 后引入，专门为Elasticsearch 设计，扩展了Java 的语法；6.0 开始，Elasticsearch 只支持Painless。Grovvy，JavaScript，Python 都不再支持；Painless 支持所有Java 的数据类型及Java APi子集；Painless Script 具备以下特性：\n 高性能/安全； 支持显示类型或者动态定义类型。   用途 #    对文档字段进行加工处理：\n  更新或删除字段，处理数据聚合操作； Script Field：对返回的字段提前进行计算； Funcation Score：对文档算分进行处理。     在Ingest Pipeline 中执行脚本；\n  在Reindex API，Update By Query 时，对数据进行处理。\n  POST tech_blogs/_update/1 { \u0026#34;script\u0026#34;: { \u0026#34;source\u0026#34;: \u0026#34;ctx._source.views += params.new_views\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;new_views\u0026#34;:100 } } } // 保存脚本在 Cluster State POST _scripts/update_views { \u0026#34;script\u0026#34;:{ \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;ctx._source.views += params.new_views\u0026#34; } } // 使用脚本 POST tech_blogs/_update/1 { \u0026#34;script\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;update_views\u0026#34;, \u0026#34;params\u0026#34;: { \u0026#34;new_views\u0026#34;:1000 } } } // query时候加一个新字段 GET tech_blogs/_search { \u0026#34;script_fields\u0026#34;: { \u0026#34;rnd_views\u0026#34;: { \u0026#34;script\u0026#34;: { \u0026#34;lang\u0026#34;: \u0026#34;painless\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;\u0026#34;\u0026#34; java.util.Random rnd = new Random(); doc[\u0026#39;views\u0026#39;].value+rnd.nextInt(1000); \u0026#34;\u0026#34;\u0026#34; } } }, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } 通过Painless 脚本访问字段 #     上下文 语法     Ingestion ctx.field_name   Update ctx._source.field_name   Search \u0026amp; Aggregation doc[\u0026ldquo;field_name\u0026rdquo;]    脚本缓存 #   编译的开销比较大，Elasticsearch 会将脚本编译后缓存在Cache中，Inline scripts 和 Stored Scripts 都会被缓存（默认缓存 100 个脚本）。\n    参数 说明     script.cache.max_size 设置最大缓存数   script.cache.expire 设置缓存超时   script.max_compilations_rate 默认5分钟最多75次编译（75/5m）    数据建模 #   数据建模（Data modeling），是创建数据模型的过程，数据模型是对真实世界进行抽象描述的一种工具和方法，实现对现实世界的映射。建模的三个过程：概念模型-》 逻辑模型-》 数据模型（第三范式）。\n  数据建模需要从两方面考虑，功能需求和性能需求：\n   功能需求-逻辑模型\n  实体属性 实体之间的关系 搜索相关的配置     性能需求- 物理模型\n  索引模板：分片数量 索引 Mapping：字段配置、关系处理     字段建模 #    字段类型\n   Text；\n用于全文本字段，文本会被 Analyzer分词；默认不支持聚合分析及排序。需要设置 fielddata 为 true。\n  Keyword；\n用于id，枚举及不需要分词的文本。例如电话号码，email地址，手机号码，邮政编码，性别等；适用于Filter（精确匹配），Sorting 和 Aggregations。\n  多字段类型；\n默认会为文本类型设置为text，并且设置一个keyword的子字段；在处理人类语言时，通过增加 英文 ，拼音 和 标准 分词器， 提高搜索结构。\n  数值类型；\n尽量选择贴近的类型。例如可以用byte，就不要用long。\n  枚举类型；\n设置为keyword。即便是数字，也应该设置成keyword，获取更加好的性能。\n  其他。\n日期/布尔/地理信息。\n     是否要搜索以及分词\n 如果不需要检索，排序和聚合分析，Enable 设置成false；\n如果不需要检索：Index 设置成false；\n如果需要检索的字段，可以通过如下配置，设定存储粒度：Index options/ Norms：不需要归一化数据时，可以关闭。\n   是否要聚合以及排序\n 如果不需要检索，排序和聚合分析，Enable 设置成false；\n如果不需要排序或者聚合分析功能，Doc_values / fielddata 设置成false。\n更新频繁，聚合查询频繁的keyword 类型的字段推荐将 eager_global_ordinals设置为 true（缓存）。\n   是否需要额外存储\n  是否需要专门存储当前字段数据\n Store 设置成 true，可以存储该字段的原始内容，一般结合_source 的enabled 为 false时候使用。\n   Disable _source：节约磁盘；适用于指标型数据\n 一般建议先考虑增加压缩比；无法看到_source字段，无法ReIndex，无法做Update。\n     Mapping设置 #    Enabled - 设置成fasle，仅做存储，不支持搜索和聚合分析（数据保存在_source中）； _Index - 是否构倒排索引。设置为 false，无法被搜索，但还支持aggregation，并且出现在_source中； Norms - 如果字段用来过滤和聚合分析，可以关闭，节约存储； Doc_values - 是否启动doc_values，用于排序和聚合分析； Field_data - 如果要对text类型启用排序和聚合分析，需要设置为true； Store - 默认不存储，数据默认存储在_source； Coerce - 默认开启，是否开启数据类型的自动转换（例如，字符串转数字）； Multifields 多字段特性；Dynamic - true/false/strict 控制Mapping的自动更新。   一些相关的API #    Index Template \u0026amp; Dynamic Template\n 根据索引名字匹配不同的Mappings 和 Settings；可以在一个Mapping 上动态的设定字段类型\n   Index Alias\n 无需停机，无需修改程序，即可进行修改。\n   Update By Query \u0026amp; Reindex\n  最佳实践 #  处理关联关系 #  避免过多字段 #   一个文档中，最好避免大量的字段，因为：\n  过多的字段数不容易维护；\n  Mapping 信息保存在Cluster State 中，数据量过大，对集群性能会有影响（Cluster State信息需要 和所有的节点同步）；\n  删除或者修改数据需要reindex。\n     默认最大字段是 1000， 参数：index.mapping.total_fields.limit；\n  Dynamic vs Strict\n Dynamic （生产环境，尽量不要打开Dynamic）  true - 未知字段会被自动加入； false - 新字段不会被索引。但是会保存在_source； strict - 新增字段不会被索引，文档写入失败。      使用Nested类型，解决字段膨胀问题。\n 通过Nested 对象保存Key/Value，解决Cluster State保存过多Meta信息，但是：\n 导致查询语句复杂度增加； 不利于在Kibana 中实现可视化分析。     避免正则查询 #   正则，通配符查询，前缀查询数据Term 查询，但是性能不够好，特别是将通配符放在开头，会导致性能的灾难。\n 解决：\n 将字符串转化为对象； 比如版本信息，7.1.2，用四个字段存储。  避免空值引起聚合不准 #   设置null_value属性。\n 为索引的mapping 加入meta信息 #  PUT softwares/ { \u0026#34;mappings\u0026#34;: { \u0026#34;_meta\u0026#34;: { \u0026#34;software_version_mapping\u0026#34;: \u0026#34;1.0\u0026#34; } } }  Mappings 设置非常重要，需要从两个维度进行考虑  功能：搜索，聚合，排序 性能：存储的开销；内存的开销；搜索的开销     Mappings 设置是一个迭代的过程\n加入新的字段很容易（必要时需要update_by_query）\n更新删除字段不允许（需要Reindex重建数据）\n最好能对Mappings 加入Meta信息，更好的进行版本管理可以考虑将 Mapping 文件上传git 进行管理\n "},{"id":6,"href":"/docs/elasticsearch/mds/6_scale_out/","title":"水平扩展集群","section":"Elasticsearch","content":"常见的集群部署方式 #  单一职责节点 #   在开发环境中，一个节点可承担多种角色。在生产环境，根据数据量，写入和查询的吞吐量，选择合适的部署方式，建议设置单一角色节点（dedicated node）。\n一个节点在默认情况下会同时扮演：master eligible、data node、coordinating node 和 ingest node，通过参数配置，让一个节点只承担一个角色。\n   参数配置\n   单一节点 配置     Master node.master: true、node.ingest: false、node.data: false   Data node.master: false、node.ingest: false、node.data: true   Coordinate node.master: false、node.ingest: true、node.data: false   Ingest node.master: false、node.ingest: false、node.data: false      职责分离的优势\n 对于不同角色的节点，可以使用不同的配置。\n   Dedicated master eligible nodes\n 负责集群状态的管理，使用低配置的CPU、RAM和磁盘。\n  从高可用 \u0026amp; 避免脑裂的角度出发，一般在生产环境中配置3台；一个集群只有一台活跃的主节点。如果与数据节点、Coordinate 节点混合部署，数据节点相对有比较大的内存占用，Coordinate 节点有时候可能会有开销很高的查询，导致OOM，这些都有可能影响Master 节点，导致集群不稳定。\n   Dedicated data nodes\n 负责数据的存储及处理客户端请求，使用高配置的CPU、RAM和磁盘。\n   Dedicated ingest nodes\n 负责数据处理，使用高配置的CPU、中等配置的RAM、低配置的磁盘。\n   Dedicated Coordinating Only Node\n  扮演 Load Balancers，降低 Master 和 Data Nodes 的负载； 负责搜索结果的Gather/Reduce。  生产环境中，建议为一些大的集群配置Coordinating Only Node，使用中高配置的CPU、中高配置的RAM、低配置的磁盘。\n     部署方式 #    增加节点，水平扩展\n 当磁盘容量无法满足需求时，可以增加数据节点；磁盘读写压力大时，增加数据节点。\n   Coordinate Only Node\n 当系统中有大量的复杂查询及聚合的时候，增加Coordinating节点，增加查询性能。LB指的是loadbalance。\n   读写分离\n  在集群中部署kibana\n 官方建议kibana 安装到Coordinating node。\n   异地多活的部署\n Global Traffic Manager，一种负载均衡。\n   Shard Filtering #   通过设置和标记，可以很好的空值分片的分配。\nnode.attr - 标记节点\nIndex.routing.allocation - 分配索引到节点\n    设置 分配索引节点，节点的属性规则     Index.routing.allocation.include.{attr} 至少包含一个值   Index.routing.allocation.exclude.{attr} 不能包含任何一个值   Index.routing.allocation.require.{attr} 所有值都需要包含    Hot \u0026amp; Warm Architecture #   数据通常不会有Update 操作：适用于Time Based 索引数据（生命周期管理），同时数据量比较大的场景。\n   Hot Nodes\n 用于数据的写入，Indexing 对 CPU 和 IO 都有很高的要求，所以需要使用高配置的机器，存储的性能要好，建议使用SSD。\n   Warm Nodes\n 用于保存只读的索引，比较旧的数据，通常使用大容量的磁盘（通常是Spinning Disks）。\n   配置\n   使用Shard Filtering，分为一下几步：\n   标记节点（Tagging）\n 通过“node.attr”来标记一个节点，节点的attribute 可以是任何的key/value，可以通过elasticsearch.yml 或者通过 -E 命令指定。\n # 标记一个 Hot 节点 bin/elasticsearch -E node.name=hotnode -E cluster.name=cluster1 -E path.data=hot_data -E node.attr.my_node_type=hot # 标记一个 warm 节点 bin/elasticsearch -E node.name=warmnode -E cluster.name=cluster1 -E path.data=warm_data -E node.attr.my_node_type=warm # 查看节点 GET /_cat/nodeattrs?v   配置索引到Hot Node\n 创建索引时，指定将其创建在 hot节点上。\n PUT logs-2019-06-27 { \u0026#34;settings\u0026#34;:{ \u0026#34;number_of_shards\u0026#34;:2, \u0026#34;number_of_replicas\u0026#34;:0, \u0026#34;index.routing.allocation.require.my_node_type\u0026#34;:\u0026#34;hot\u0026#34; } } // 查看分片信息 GET _cat/shards?v   配置索引到Warm Node\n 将某个索引移动到warm node。\nindex.routing.allocation 是一个索引级别的 dynamic setting，可以通过API 在后期进行设定。\n PUT PUT logs-2019-06-27/_settings { \u0026#34;index.routing.allocation.require.my_node_type\u0026#34;:\u0026#34;warm\u0026#34; }   Rack Awareness #   ES 节点可能分布在不同的机架，当一个机架断电，可能会同时丢失几个节点。如果一个索引相同的主分片和副本分片，同时在这个机架上，就可能导致数据丢失；通过Rack Awareness的机制，就可以尽可能避免将同一个索引的主副分片分配在一个机架的节点上。\n如下图，如果Rack 1断电，那么P0/R0对应的索引可能产生数据丢失。\n  配置   与Hot \u0026amp; Warm Architecture配置类似。\n   标记Rack 节点\n# 标记一个 rack 1 bin/elasticsearch -E node.name=node1 -E cluster.name=geektime -E path.data=node1_data -E node.attr.my_rack_id=rack1 # 标记一个 rack 2 bin/elasticsearch -E node.name=node2 -E cluster.name=geektime -E path.data=node2_data -E node.attr.my_rack_id=rack2   配置集群\n// 这样设置后，ES会自动把主分片和副本分片发送到不同的rack上 PUT _cluster/settings { \u0026#34;persistent\u0026#34;: { \u0026#34;cluster.routing.allocation.awareness.attributes\u0026#34;: \u0026#34;my_rack_id\u0026#34; } }   Force Awareness\nPUT _cluster/settings { \u0026#34;persistent\u0026#34;: { \u0026#34;cluster.routing.allocation.awareness.attributes\u0026#34;: \u0026#34;my_rack_id\u0026#34;, // 强制要求主副本分片分散到rack1和rack2上面，如果只有rack1节点，那么索引分片无法正常分配  \u0026#34;cluster.routing.allocation.awareness.force.my_rack_id.values\u0026#34;: \u0026#34;rack1,rack2\u0026#34; } } // 查看分片无法正常分配原因 GET _cluster/allocation/explain?pretty   分片设计及管理 #   之前会默认创建5个主分片，7.0开始，新创建一个索引时，默认只有一个主分片。\n单个分片，查询算分，聚合不准的问题都可以得以避免，但是单个索引，单个分片的时候，集群无法实现水平扩展。\n  集群新加一个节点后，Elasticsearch 会自动进行分片的移动，也叫Shard Rebalanceing。比如一个索引有2个分片，本来有一个节点A，这是节点A就有俩分片，后来加了一个节点B，那么此时A和B各有一个分片。\n   当分片数 \u0026gt; 节点数时\n 一旦集群中有新的数据节点加入，分片可以自动进行分配，分配在重新分配时，系统不会有downtime。\n   多分片的好处：一个索引如果分布在不同的节点，多个节点可以并行执行\n 查询可以并行执行；数据写入可以分散到多个机器。\n   分片过多所带来的的副作用\n 每个分片是一个Lucene的索引，会使用机器资源。过多的分片会导致额外的性能开销。\n 每次搜索的请求，需要从每个分片上获取数据； 分片的meta 信息由Master node维护，过多会增加管理负担； 经验值，控制分片总数在10w以内。     确定主分片数\n  从存储的物理角度看：\n 官方推荐：日志类应用，单个分片不要大于 50GB；搜索类应用，单个分片不要超过20GB。\n   为什么要控制分片存储大小：\n 提高Update 的性能；Merge 时，减少所需的资源；丢失节点后，具备更快的恢复速度 / 便于分片在集群内 Rebalancing。\n     确定副本分片数\n 副本会降低数据的索引速度：有几份副本就有几倍的CPU资源消耗在索引上；会减缓对主分片的查询压力，但是会消耗同样的内存资源。\n如果机器资源充分，提高副本数，可以提高整体查询的QPS。\n   调整分片总数设定，避免分配不均衡\n ES的分片策略会尽量保证节点上的分片数大致相同，但是，扩容的新节点没有数据，可能导致新索引集中在新的节点，热点数据过于集中，可能产生性能问题。\n  index.routing.allocation.total_shards_per_node：设置某个索引每个节点可以有几个分片。 cluster.routing.allocation.total_shards_per_node：全局配置。    集群容量规划 #   规划上需要保持一定的余量，当负载出现波动，节点出现丢失，还能正常运行。\n做容量规划时，一些需要考虑的因素：\n 机器的软硬件配置； 单条文档的尺寸/ 文档的总数据量 / 索引的总数据量 （time base 数据保留的时间）/ 副本分片数； 文档是如何写入的（Bulk的尺寸）； 文档的复杂度，文档是如何进行读取的。   评估业务的性能需求 #    数据吞吐及性能需求\n 数据写入的吞吐量，每秒要求写入多少数据；查询的吞吐量；单挑查询可接受的最大返回时间。\n   了解你的数据\n 数据的格式和数据的Mapping；实际的查询和聚合长的是什么样的。\n   应用分类\n   搜索：固定大小的数据集。搜索的数据集增长相对比较缓慢。\n  日志：基于时间序列的数据。使用 ES 存放日志与性能指标。数据每天不断写入，增长速度较快；结合 Warm Node 做数据的老化处理。\n     硬件配置\n 选择合理的硬件，数据节点尽可能使用 SSD； 搜索等性能要求高的场景，建议SSD；按照1 ： 10的比例配置内存和硬盘； 日志类和查询并发低的场景，可以考虑使用机械硬盘存储；按照1:50的比例配置内存和硬盘； 单节点数据建议控制在 2 TB以内，最大不建议超过5 TB； JVM 配置机器内存的一半， JVM 内存配置不建议超过32G。    部署方式\n 按需选择合理的部署方式：如果考虑可靠性高可用，建议部署3台 dedicated 的Master 节点；如果有复杂的查询和聚合，建议设置Coordinating 节点。\n   搜索类应用 #    一些案例：唱片信息库/ 产品信息\n  特性\n 被搜索的数据集很大，但是增长相对比较慢（不会有大量的写入），更关心搜索和聚合的读取性能。\n数据的重要性与时间范围无关。关注的是搜索的相关度。\n   估算索引的数据量，确定分片的大小\n 单个分片的数据不要超过20GB； 可以通过增加副本分片，提高查询的吞吐量。    拆分索引\n  如果业务上有大量的查询时基于一个字段进行Filter，该字段又是一个数量有限的枚举值（例如订单所在的地区），可以考虑以这个字段拆分为多个索引；\n  如果在单个索引有大量的数据，可以考虑将索引拆分成多个索引；\n 查询性能可以得到提高；如果要对多个索引进行查询，还是可以在查询中指定多个索引得以实现。\n   如果业务上有大量的查询是基于一个字段进行Filter，该字段数值并不固定。\n 可以启用Routing功能，按照filter 字段的值分布到集群中不同的shard，降低查询时相关的shard，提高CPU利用率。\n     日志类应用 #    相关的用案：日志/ 指标 / 安全性相关的Events；舆情分析\n  特性\n   每条数据都有时间戳；文档基本不会被更新（日志和指标数据）；\n  用户更多的会查询近期的数据；对旧的数据查询相对较少；\n  对数据的写入性能要求比较高。\n     创建 time-based 索引\n  在索引的名字中增加时间信息； 按照 每天/ 每周 / 每月 的方式进行划分。     优势\n 更加合理的组织索引，例如随着时间推移，便于对索引做的老化处理：\n 利用 Hot \u0026amp; Warm Architecture 备份和删除以及删除的效率高。（delete by query 执行速度慢，底层也不会立即释放空间，而Merge时又很消耗资源）。       写入时间序列的数据：基于 Data Math 的方式 #   容易使用，但如果时间规则变化，需要重新部署代码。\n假设现在是2019-08-01T00:00:00\n    公式 含义     \u0026lt;logs-{now/d}\u0026gt; logs-2022.01.01   \u0026lt;logs-{now{YYYY.MM}}\u0026gt; logs-2022.01   \u0026lt;logs-{now/w}\u0026gt; 这周的开始     另外可以通过别名的方式，更新每天的索引。\n 扩容 #    增加 Coordinating / Ingest Node\n 解决CPU 和 内存开销问题。\n   增加 Data Node\n 解决存储的容量问题。为避免分配不均的问题，需要提前监控磁盘空间，提前清理数据或增加节点（70%）。\n   "},{"id":7,"href":"/docs/elasticsearch/mds/7_cluster_setting/","title":"集群运维","section":"Elasticsearch","content":"常用配置 #  开发模式和生产模式 #   从ES 5开始，支持 Development和Production 两种运行模式。\n Bootstrap Checks #   一个集群在Production Mode时，启动时必须通过所有Bootstrap 检测，否则会启动失败。Bootstrap Checks 可以分为两类 JVM \u0026amp; Linux Checks。Linux Checks只针对Linux系统。\n JVM设定 #   从ES 6开始，只支持 64 位的JVM，JVM的设置可以在config/jvm.options中设置。尽量避免修改默认配置：\n 将内存 Xms 和 Xmx 设置成一样，避免heap resize 时引发停顿 Xmx设置不要超过物理内存的 50%（lucene索引会用内存）；单个节点，最大内存建议不超过32G（JVM内存小于32G时会使用指针压缩技术） 生产环境，JVM必须使用Server模式 关闭JVM Swapping   集群配置设定 #    静态设定\n 静态配置文件尽量简洁：按照文档设置所有相关系统参数。elasticsearch.yml 配置文件中尽量只写必备参数。\n   动态设定\n 其他的设置项可以通过 API 动态进行设定。动态设定分 transient 和 persistent 两种，都会覆盖 elasticsearch.yml 中的设置。transient 在集群重启后会丢失；persistent 在集群重启后不会丢失。\n    优先级 设置     1 Transient Settings   2 Persistent Settings   3 Command-line Settings   4 Config file Settings      系统设置 #   参照文档 Setup ELasticsearch \u0026gt; Important System Configuration。\n 最佳实践 #    网络\n 单个集群不要跨数据中心进行部署（不要使用WAN） 节点之间的hops 越少越好 如果有多块网卡，最好将transport 和http 绑定到不同的网卡，并设置不同的防火墙 Rules 按需为 Coordinating Node 或 Ingest Node 配置负载均衡    内存设定计算实例\n  内存大小要根据Node 需要存储的数据来进行估算：搜索类的比例建议 1:16；日志类：1:48 - 1:96 之间。\n 假设总数据量1T，设置一个副本 = 2T 总数据量。\n 搜索类项目，每个节点 31（JVM内存） * 16 = 496 G，加上预留空间。所以每个节点最多400G 数据，至少需要5 个数据节点； 日志类项目，每个节点 31 * 50 = 1550 GB， 两个数据节点即可。       存储\n 推荐使用SSD，使用本地存储（Local Disk），避免使用 SAN NFS/ AWS / Azure filesystem 可以在本地指定多个 \u0026ldquo;path.data\u0026rdquo;，以支持使用多块磁盘 ES 本来提供了很好的HA 机制，无需使用RAID 1/5/10 可以在Warm 节点上使用Spinning Disk，但是需要关闭Concurrent Merges Trim 你的SSD    服务器硬件\n 建议使用中等配置的机器，不建议使用过于强劲的硬件配置（建议使用中等配置的机器，不建议使用过于强劲的硬件配置） 不建议在一台服务器上运行多个节点    Throttles限流\n 为 Relocation 和Recovery 设置限流，避免过多任务对集群产生性能影响。\n   Recovery\nCluster.routing.allocation.node_concurrent_recoveries：2   Relocation\nCluster.routing.allocation.cluster_concurrent_rebalance：2     集群设置 #    关闭 Dynamic Indexes\nPUT _cluster/settings { \u0026#34;persistend\u0026#34; : { \u0026#34;actino.auto_create_index\u0026#34; : false } } // 也可以设置白名单 PUT _cluster/settings { \u0026#34;persistend\u0026#34; : { \u0026#34;actino.auto_create_index\u0026#34; : \u0026#34;logstash-*, .kibana*\u0026#34; } }   安全设定\n 打开Authentication \u0026amp; Authorization 实现索引和字段级的安全控制 节点间通信加密 Enable HTTPS Audit logs    监控集群 #  Stats相关API #    Node Stats\n// 节点级别统计信息 GET _nodes/stats   CLuster Stats\n// 集群级别统计信息，文档总数、索引总数等 GET _cluster/stats   Index Stats\n// 索引级别统计信息 GET 索引名/_stats   Task API #    Task\n// 查看所有的 tasks GET _tasks // Pending Cluster Tasks GET _cluster/pending_tasks   Thread Pools\nGET _nodes/thread_pool GET _nodes/stats/thread_pool GET _cat/thread_pool?v GET _nodes/hot_threads GET _nodes/stats/thread_pool   Query Slow Log #  PUT my_index/_settings { \u0026#34;index.indexing.slowlog\u0026#34;:{ \u0026#34;threshold.index\u0026#34;:{ \u0026#34;warn\u0026#34;:\u0026#34;10s\u0026#34;, \u0026#34;info\u0026#34;: \u0026#34;4s\u0026#34;, \u0026#34;debug\u0026#34;:\u0026#34;2s\u0026#34;, \u0026#34;trace\u0026#34;:\u0026#34;0s\u0026#34; }, \u0026#34;level\u0026#34;:\u0026#34;trace\u0026#34;, \u0026#34;source\u0026#34;:1000 } } PUT my_index/ { \u0026#34;settings\u0026#34;: { \u0026#34;index.search.slowlog.threshold\u0026#34;: { \u0026#34;query.warn\u0026#34;: \u0026#34;10s\u0026#34;, \u0026#34;query.info\u0026#34;: \u0026#34;3s\u0026#34;, \u0026#34;query.debug\u0026#34;: \u0026#34;2s\u0026#34;, \u0026#34;query.trace\u0026#34;: \u0026#34;0s\u0026#34;, \u0026#34;fetch.warn\u0026#34;: \u0026#34;1s\u0026#34;, \u0026#34;fetch.info\u0026#34;: \u0026#34;600ms\u0026#34;, \u0026#34;fetch.debug\u0026#34;: \u0026#34;400ms\u0026#34;, \u0026#34;fetch.trace\u0026#34;: \u0026#34;0s\u0026#34; } } }   支持将分片上，Search 和 Fetch 阶段的慢查询写入文件\n  支持为Query 和Fetch 分别定义阈值\n  索引级的动态设置，可以按需设置，或者通过 Index Template 统一设定\n  Slog log 文件通过log4j2.properties配置\n  创建监控dashboard #   开发 Elasticsearch plugin，通过读取相关的监控 API，将数据发送到 ES，或者TSDB 使用Metricbeats 搜索相关指标 使用Kibana 或者 Graffna 创建 Dashboard 可以开发Elasticsearch Exporter，通过 Promtheus 监控 Elasticsearch 集群  潜在问题 #    集群健康状态\n 是否有节点丢失\n   索引合理性\n 索引总数不能过大/ 副本分片尽量不要设置为0 / 主分片尺寸检测 / 索引的字段总数 / 索引是否分配不均衡 / 索引 segment 大小诊断分析\n   资源使用合理性\n CPU 内存 和磁盘使用情况分析 / 是否存在节点负载不平衡 / 是否需要增加节点\n   业务操作合理性\n 集群状态变更频率，是否在业务高峰期有频繁操作；慢查询监控与分析\n   集群 Yellow 与 Red 问题 #   分片健康：\n 红：至少有一个主分片没有分配 黄：至少有一个副本分片没有分配 绿：主副本分片全部正常分配。  Red \u0026amp; Yellow 是集群运维中常见的问题。除了集群故障，一些创建，增加副本等操作，都会导致集群短暂的Red 和Yellow，所以监控和报警时都需要设置一定的延时；通过检查节点数，使用ES 提供的相关API，找到真正的原因；可以指定Move 或者Reallocate分片。\n    GET _cluster/health 集群的状态（检查节点数量）     GET cluster/health?level=indices 所有索引的健康状态（查看有问题的索引）   GET cluster/health/my_index 耽搁索引的健康状态（查看具体的索引）   GET cluster/health?level=shards 分片级的索引   GET cluster/allocation/explain 返回第一个未分配Shard 的原因      案例\n  症状：集群变红； 分析，通过 Allocation Explain API 发现 创建索引失败，因为无法找到标记了相应 box type 的节点； 解决：删除索引，集群变绿。重新创建索引，并且指定正确的 routing box type，索引创建成功，集群保持绿色。     症状：集群变黄； 分析，通过 Allocation Explain API 发现 无法在相同的节点上创建副本； 解决：将索引的副本数设置为0，或者通过增加节点解决。     短暂的Yellow or Red\n INDEX_CREATE：创建索引导致。在索引的全部分片分配完成之前，会有短暂的 Red，不一定代表有问题 CLUSTER_RECOVER：集群重启阶段，也可能变黄 INDEX_REOPEN：Open 一个之前 CLose 的索引 DANGLING_INDEX_IMPORTED：一个节点离开集群期间，有索引被删除。这个节点重新返回时，会有Dangling问题，重新删除这个索引即可。    常见问题与解决方法\n  集群变红\n 需要检查是否有节点离线。如果有，通常通过重启离线的节点可以解决问题\n   由于配置导致的问题（例如错误的box_type，错误的副本数）\n 需要修复相关的配置；如果是测试的索引，可以直接删除\n   因为磁盘空间限制，分片规则（shard filtering）引发的\n 需要调整规则或者增加节点\n   对于节点返回集群，导致dangling变红\n 可以直接删除 dangling索引\n     提升写性能 #   ES 默认配置，已经综合考虑了数据可靠性，搜索的实时性质，写入速度，一般不要盲目修改 一切优化，都要基于高质量的数据建模  一般方法 #    客户端\n 多线程，批量写。可以通过性能测试，确定最佳文档数量；多线程时候需要观察是否有HTTP 429 返回，实现Retry 以及线程数量 的自动调节。\n单个bulk请求体的数据量不要太大，官方建议大约5-15mb；写入端的bulk请求超时超时需求足够长，建议60s以上；写入端尽量将数据轮训打到不同节点。\n   服务器端\n 单个性能问题，往往是多个因素造成的。需要先分解问题，在单个节点上进行调整并且结合测试，尽可能压榨硬件资源，以达到最高吞吐量。可以使用更好的硬件，观察CPU / IO Block；线程切换 / 堆栈情况。\n   服务端优化 #    降低IO操作\n 使用 ES 自动生成的文档ID，/一些相关的ES 配置，如提升Refresh Interval；\n   降低 CPU 和 存储开销\n 减少不必要分词 / 避免不需要的doc_values / 文档的字段尽量保证相同的顺序，可以提高文档的压缩率\n   尽可能做到写入和分片的均衡负载，实现水平扩展\n Shard Filtering / Write Load Balancer\n   调整 Bulk 线程池和队列\n 索引创建属于计算密集型任务，应该使用固定大小的线程池来配置，线程数应该配置成CPU 核心数 + 1，避免过多的上下文切换 来不及处理的放入队列，队列大小可以适当增加，不要过大，否则占用的内存会成为GC的负担    关闭无用的功能 #    Index设置为 false\n 适合只需要聚合不需要搜索\n   Norms 设置成 false\n 适合不需要算分\n   不要对字符串使用默认的 dynamic mapping\n 字段数量过多，会对性能产生表达的影响\n   Index_options控制在创建倒排索引时，哪些内容会被添加到 倒排索引中\n 优化这些配置，一定程度可以节约CPU\n   关闭_source，减少IO 操作\n 适合指标型数据\n   取舍 #   如果需要追求极致的写入速度，可以牺牲数据可靠性及搜索实时性以换取性能。\n 牺牲可靠性：将副本分片设置为0，写入完毕再调整回去 牺牲搜索实时性：增加Refresh Interval 的时间 牺牲可靠性：修改Translog 的配置   数据写入过程的可优化点 #    Refresh Interval\n 增加refresh_interval 的数值，降低Refresh 的频率。默认值为 1S，如果设置成-1，会禁止自动 refresh。此举避免过于频繁的refresh而生产过多的segment文件，但是会降低搜索的实时性。另外需要修改参数 indices.memory.index_buffer_size（默认是10%，会导致自动触发refresh）。\n   Translog\n 降低写磁盘的频率，但是会降低容灾能力。\n Index.translog.durability：默认是request，每个请求都落盘。设置成async，异步写入 index.translog.sync_interval 设置成60s，每分钟执行一次 index.translog.flush_threshod_size：默认521 mb，可以适当调大。当translog超过改值，会触发flush     分片设定\n  副本在写入时设为0，完成后再增加\n  合理设置主分片数，确保均匀分配在所有数据节点上\n index.routing.allocation.total_share_per_node：限定每个索引在每个节点可分配的主分片数；\n比如5个节点的集群，所有有5个主分片，一个副本，每个节点的分片数：（5 + 5） / 5 = 2，生产环境要适当调大这个数字，避免有节点下线时，分片无法正常迁移。\n     PUT myindex { \u0026#34;settings\u0026#34;: { \u0026#34;index\u0026#34;: { // 30s一次Refresh  \u0026#34;refresh_interval\u0026#34;: \u0026#34;30s\u0026#34;, \u0026#34;number_of_shards\u0026#34;: \u0026#34;2\u0026#34; }, \u0026#34;routing\u0026#34;: { \u0026#34;allocation\u0026#34;: { // 控制分片，避免数据热点  \u0026#34;total_shards_per_node\u0026#34;: \u0026#34;3\u0026#34; } }, \u0026#34;translog\u0026#34;: { // 降低translog落盘  \u0026#34;sync_interval\u0026#34;: \u0026#34;30s\u0026#34;, \u0026#34;durability\u0026#34;: \u0026#34;async\u0026#34; }, \u0026#34;number_of_replicas\u0026#34;: 0 }, \u0026#34;mappings\u0026#34;: { // 避免不必要的字段索引。必要时可以通过update by query 索引必要的字段  \u0026#34;dynamic\u0026#34;: false, \u0026#34;properties\u0026#34;: {} } } 提升读性能 #  数据建模 #   尽量Denormalize 数据 尽量将数据先行计算，然后保存到Elasticsearch 中，尽量避免查询时的Script 计算 尽量使用 Filter Context，利用缓存机制，减少不必要的算分 结合profile，explain API 分析慢查询的问题，持续优化数据模型 严禁 使用 * 开头通配符 Terms查询  优化分片 #   避免 Over Sharing一个查询需要访问每一个分片，分片过多，会导致不必要的查询开销 结合应用场景，控制单个分片的尺寸：  Search 20G Logging 40G Force-merge Read-only索引 使用基于时间序列的索引，将只读的索引进行force merge，减少segment数量。    段合并优化及注意事项 #  Merge优化 #   ES 和 Lucene 会自动进行Merge操作，Merge操作相对比较重，需要优化，降低对系统的影响。\n 降低分段产生的数量/频率；  可以将Refresh Interval 调整到分钟级别/ indices.memory.index_buffer_size（默认是10%） 尽量避免文档的更新操作   降低最大分段大小，避免较大的分段继续参加Merge，节省系统资源。（最终会有多个分段）  Index.merge.policy.segments_per_tier，默认为 10，越小需要越多的合并操作 Index.merge.policy.max_merged_segment，默认 5GB，操作此大小以后，就不再参与后续的合并操作     Force Merge #   当 Index 不再有写入操作的时候，建议对其进行force merge，可以提升查询速度 / 减少内存开销。\n POST my_index/_forcemerge?max_num_segments=1 GET _cat/segments/my_index?v  最终分成的segments越少越好，最好可以 force merge成1个。但是，Force Merge 会占用大量网络资源、IO和CPU。如果不能再业务高峰期之前做完，就需要考虑增大最终的分段数，加快force_merge完成的时间。\n 缓存及使用Breaker限制内存使用 #  缓存分类 #    Node Query Cache\n 每一个节点都有一个Node Query缓存，由该节点的所有Shard 共享，只缓存Filter Context 相关内容，采用LRU算法。\n   静态配置（需要设置在每个 Data Node 上）\n Node Level - indices.queries.cache.size : 10%\nIndex level - index.queries.cache.enabled:true\n   缓存失效\n 保存的是Segment 级缓存命中的结果。Segment 被合并后，缓存会失效。\n     Shard Request Cache\n 缓存每个分片上的查询结果，只会缓存设置了 size = 0 的查询对应的结果。不会缓存hits。但是会缓存Aggregation 和Suggestions。\n使用LRU算法，将整个JSON 查询串作为Key，与JSON对象的顺序有关。\n   静态配置\n 数据节点 ：indices.requests.cache.size：1%\n   缓存失效\n 分配Refresh 的时候，Shard Request Cache 会失效。如果Shard 对应的数据频繁发生变化，该缓存的效率会很差。\n     Fielddata Cache\n 除了Text 类型，默认都采用doc_values，节约了内存。Text 类型的字段需要打开Fileddata 才能对其进行聚合和排序，但是Text 经过分词，排序和聚合效果不佳，建议不要轻易使用。\nAggregation 的 Global ordinals 也保存在Fielddata cache中。\n   配置\n 可以控制 Indices.fielddata.cache.size ，避免产生GC（默认无限制）\n   缓存失效\n Segment 被合并后会失效。\n     内存管理与断路器 #   Elasticsearch 高效运维依赖于内存的合理分配，可用内存一半分配给JVM，一半留给操作系统，缓存索引文件。内存问题，可能引发的问题：\n 长时间GC，影响节点，导致集群相应缓慢； OOM，导致丢节点。     查看各个节点内存状况\nGET _cat/nodes?v GET _nodes/stats/indices?pretty GET _cat/nodes?v\u0026amp;h=name,queryCacheMemory,queryCacheEvictions,requestCacheMemory,requestCacheHitCount,request_cache.miss_count GET _cat/nodes?h=name,port,segments.memory,segments.index_writer_memory,fielddata.memory_size,query_cache.memory_size,request_cache.memory_size\u0026amp;v   常见的内存问题\n  Segments 个数过多，导致 full GC\n 现象：集群整体响应缓慢，没有特别多的数据读写。但是发现节点在持续进行 Full GC\n分析：查看Elasticsearch 的内存使用，发现 segments.memory占用很大空间\n解决：通过 force merge，把segments合并成一个\n建议：对于不再写入和更新的索引，可以将其设置为只读。同时，进行 force merge操作。如果问题依然存在，则需要考虑扩容。\n   Field data cache 过大，导致 full GC\n 现象：集群整体响应缓慢，也没有特别多的数据读写。但是发现节点在持续进行 Full GC\n分析：查看Elasticsearch 的内存使用，发现fielddata.memory.size 占用很大空间。同时。数据不存在写入和更新，也执行过segments merge。\n解决：将 indices.fielddata.cache.size 设小，重启节点，堆内存恢复正常\n建议：Field data cache 的构建比较重，Elasticsearch 不会主动释放，所以这个值设置的保守一些。如果业务上确实有所需要，可以通过增加节点，扩容解决。\n   复杂的嵌套聚合，导致集群full GC\n 现象：节点响应缓慢，持续进行 Full GC\n分析：导出 Dump 分析。发现内存中有大量 bucket对象，查看日志发现复杂的嵌套聚合\n解决：优化聚合\n建议：在大量数据集上进行嵌套聚合查询，需要很大的堆内存来完成。如果业务场景确实需要，则需要增加硬件进行扩展。同时，为了避免这类查询影响整个集群，需要设置 Circuit Breaker 和 search.max.buckets 的数值\n     Circuit Breaker\n 断路器，避免不合理操作引发的 OOM，每个断路器可以指定内存使用的限制。\n Parent circuit breaker：设置所有的熔断器可以使用的内存的总量 Fielddata circult breaker：加载fielddata 所需要的内存 Request circuit breaker：防止每个请求级数据结构超过一定的内存（例如聚合计算的内存） In fight circuit breaker：Request中的断路器 Accounting request circuit breaker：请求结束后不能释放对象所占用的内存   // Circuit Breaker统计信息 // Tripped 大于0，说明有过熔断 // Limit size 与 estimated size越接近，越可能引发熔断 GET /_nodes/stats/breaker?  不要触发了熔断，就盲目调大参数，有可能会导致集群出问题，也不要盲目调小，需要进行评估。将集群升到 7.x，更好的Circuit Breaker 实现机制：增加了 indices.breaker.total.use_real_memory 配置项，可以更加精准的分析内存情况，避免OOM。\n   "},{"id":8,"href":"/docs/elasticsearch/mds/8_index_lifecycle/","title":"索引生命周期管理","section":"Elasticsearch","content":"索引管理API #    Open / Close Index\n 索引关闭后无法进行读写，但是索引数据不会被删除。\n // 关闭索引 POST /索引名/_close // 索引存在 HEAD 索引名 // 打开索引 POST /索引名/_open   Shrink Index\n 可以将索引的主分片数收缩到较小的值。使用场景：\n 索引保存的数据量比较小，需要重新设定主分片； 索引从Hot 移动到 Warm后，需要降低主分片数。    会使用和索引源相同的配置创建一个新的索引，仅仅降低主分片数。源分片数必须是目标分片数的倍数。如果源分片数是素数，目标分片数只能为1；如果文件系统支持硬链接，会将Segments 硬连接到目标索引，所以性能好（相比较于Reindex）。完成后，可以删除源索引。\n  使用要求：\n 分片必须只读； 所有分片必须在同一个节点上； 集群健康状态为 Green。   POST my_source_index/_shrink/my_target_index { \u0026#34;settings\u0026#34;: { \u0026#34;index.number_of_replicas\u0026#34;: 0, \u0026#34;index.number_of_shards\u0026#34;: 2, \u0026#34;index.codec\u0026#34;: \u0026#34;best_compression\u0026#34; }, \u0026#34;aliases\u0026#34;: { \u0026#34;my_search_indices\u0026#34;: {} } }   Split Index\n 可以扩大主分片个数。使用要求：\n 目标索引必须不存在； 目标分片数是源分片数倍数； 源索引分片数小于目标索引； 分片必须只读； 相应分片会被复制到同样的节点。   POST my_source_index/_split/my_target_index { \u0026quot;settings\u0026quot;: { \u0026quot;index.number_of_shards\u0026quot;: 8, \u0026quot;index.number_of_replicas\u0026quot;:0 } }   Rollover Index\n 类似 Log4J 记录日志的方式，索引尺寸或者时间超过一定值后，创建新的索引。当满足一系列的条件（存活的时间 / 最大文档数 / 最大的文件尺寸），Rollver API 支持将一个 Alias 指向一个新的索引。\n  Rollover不会自动触发，一般需要和Index Lifecycle Management Policies 结合使用。\n // 不设定 is_write_true // 名字符合命名规范，以-数字结尾 PUT /nginx-logs-000001 { \u0026#34;aliases\u0026#34;: { \u0026#34;nginx_logs_write\u0026#34;: {} } } // 多于5条的文档会被移动到nginx-logs-000002索引，且nginx-logs-000001不再有别名 POST /nginx_logs_write/_rollover { \u0026#34;conditions\u0026#34;: { \u0026#34;max_age\u0026#34;: \u0026#34;1d\u0026#34;, \u0026#34;max_docs\u0026#34;: 5, \u0026#34;max_size\u0026#34;: \u0026#34;5gb\u0026#34; } } // 设置 is_write_index PUT apache-logs1 { \u0026#34;aliases\u0026#34;: { \u0026#34;apache_logs\u0026#34;: { \u0026#34;is_write_index\u0026#34;:true } } } // 需要指定 target 的名字 // 多于1条的文档会被移动到apache-logs2索引，但是前面设置了is_write_index，apache-logs1依然有别名apache_logs，但是新的数据只会写入apache-logs2 POST /apache_logs/_rollover/apache-logs2 { \u0026#34;conditions\u0026#34;: { \u0026#34;max_age\u0026#34;: \u0026#34;1d\u0026#34;, \u0026#34;max_docs\u0026#34;: 1, \u0026#34;max_size\u0026#34;: \u0026#34;5gb\u0026#34; } }   Rollup Index\n 对数据进行处理后，重新写入，减少数据量\n   时间序列索引 #   特点：索引中的数据随着时间持续不断增长 优势：按照时间序列划分索引，会使得管理更加简单。例如：完整删除一个索引，性能比 delete by query好 挑战：自动化管理，减少人工操作（从Hot 移动到 Warm；定期关闭或者删除索引） 生命周期常见的阶段  Hot：索引还存在着大量的读写操作； Warm：索引不存在写操作，还有被查询的需要； Cold：数据不存在写操作，读操作也不多； Delete：索引不再需要，可以被安全删除。    Index Lifecycle Management #   Elasticsearch 6.6 推出的新功能，基于 X-Pack Basic License，可免费使用。\n引入Policy、Phase、Action概念。\n "},{"id":9,"href":"/docs/mysql/mds/0_index/","title":"索引","section":"MySQL","content":"索引的类型 #   索引的出现是为了提高数据查询的效率，就像书的目录一样。实现索引的方式也有很多种，MySQL有如下几种类型的索引。\n 哈希索引 #   哈希索引是基于哈希表这种数据结构的索引。\n   优点\n 新增、精确查询都很快，O(1)的时间复杂度。\n   缺点\n  无法用于排序和分组； 区间查询很慢。     适用场景：等值查询\n  全文索引 #   MyISAM存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。 查找条件使用MATCH AGAINST，而不是普通的WHERE。\n全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。\nInnoDB存储引擎在MySQL 5.6.4 版本中也开始支持全文索引。\n B+树索引 #  不同数据结构的出现，主要是为了解决不同场景，不同操作的效率问题。B+树是适合存在磁盘的数据结构，它有以下特点：\n  B+树的每个节点都是一页；\n 从磁盘读取数据的时候，并不是一条一条读的，而是读“一块”（好几条）数据到内存。在MySQL中，这“一块”的单位就是页，默认大小为16k。\n   B+树是N叉树，N取决于字段的大小和页的大小；\n 假设一棵二叉树高度为5，目标值在树的底部，那么在进行深度优先搜索过程中，就需要经过5个节点。对于存储在磁盘的B+树来说，经过5个节点就意味着要查询5次磁盘，是比较耗时的操作。如果这棵树的高度低一些，就意味着可以少进行几次查询磁盘的操作。\n  同样一棵树，每个节点的子节点（扇出）越多，那么它的树高也越低。所以B+树是N叉树的结构，是更适合磁盘的数据结构。\n  以整数（bigint）字段索引为例，一个key为8B，一个引用约为6B，所以一条数据的索引占据空间约为14B，一页可以存：16K/14B ≈ 1170 条数据的索引，也就是说，此时N = 1170，是1170叉树。\n   B+树的非叶子节点存key（索引字段的值）和其它页的引用，叶子节点存全部数据；\n 假想如果在非叶子节点也存全部数据（一般来说大小远超6B）的话，那么每页可以存的索引条数就会变少，也就是说每个节点的子节点会变少，进而导致树的高度变大。\n   B+树的每个节点中的key都是按照顺序排列的。\n 在每个页查找的时候，可以使用二分法查找。\n ​\n  在InnoDB中，表都是根据主键顺序，以索引（B+树）的形式存放的，这种存储方式称为索引组织表。 根据索引类型，分为两种：\n 主键索引：叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）； 非主键索引：叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。  二者区别：\n 主键查询方式，则只需要搜索 ID 这棵 B+ 树； 普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。 基于非主键索引的查询需要多扫描一棵索引树。因此，在应用中应该尽量使用主键查询。  维护 #   B+树为了维护索引的有序性，在插入新值的时候需要做必要的维护。\n 根据插入的类型，可以分为几种：\n 直接在后面插入； 插在中间，挪动后面的数据； 插入时数据满了，会造成页分裂，性能受影响，空间利用率降低； 合并：当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并，合并的过程，可以认为是分裂的逆过程。  使用优化 #  使用问题 #  "},{"id":10,"href":"/docs/elasticsearch/","title":"Elasticsearch","section":"Docs","content":" 大部分内容总结自极客时间视频课  "}]