[{"id":0,"href":"/docs/elasticsearch/mds/4_aggs/","title":"聚合","section":"Elasticsearch","content":"聚合语法 #  { \u0026#34;size\u0026#34;: 0, \u0026#34;aggs\u0026#34;: { // 与query同级的关键词  \u0026#34;\u0026lt;aggs_name\u0026gt;\u0026#34;: { // 自定义的聚合名字  \u0026#34;\u0026lt;aggs_type\u0026gt;\u0026#34;: { // 聚合的定义：不同的Type + Body  \u0026lt;aggs_body\u0026gt; }, \u0026#34;aggs\u0026#34;: {} // 子聚合查询  }, \u0026#34;\u0026lt;aggs_name_2\u0026gt;\u0026#34; : {} // 可以包含多个同级的聚合查询  } } Metric #   一些系列的统计方法，会基于数据集计算结果，除了支持在字段上进行计算，同样也支持在脚本（painless script）产生的结果之上进行计算，类比SQL中的max、min等函数。\n   单值分析：只输出一个分析结果\n   aggs_type 含义     min 最小值   max 最大值   avg 平均值   sum 求和   cardinality 去重求数量，相当于distinct count      多值分析\n   aggs_type 含义     stats 输出最低、最高、平均、求和、count的值   extended stats 多了平方和、标准差等统计值   percentile 百分位数   percentile rank 百分位排比   top hits 前几条数据      Bucket #   一组满足条件的文档，类比SQL中的Group By。\n   Terms\n 支持嵌套，嵌套后可输出 sum() group by类型聚合结果。\n 注意：keyword 类型字段默认支持doc_values；text 类型字段需要在Mappings 中开启如下配置\n\u0026#34;fielddata\u0026#34;: true 才能进行Terms Aggregation，会按照分词后的结果进行分桶。\n  优化Terms 性能\n在keyword字段上，打开eager_global_ordinals参数打开，每当有新的数据写入，term会加载到cache中。\n适用场景：1. 聚合分析经常发生；2.索引不断有文档写入。\n  排序\n指定 order，按照count 和 key进行排序。默认情况，按照count降序排列；指定size，就能返回相应的桶。\n    数字类型\n   aggs_type 含义     range 自定义数据范围作为桶，可以自定义key   Date range 日期范围   histogram 直方图   Date histogram 日期直方图      Pipeline #   对其他的聚合结果进行二次聚合，通过bucket_path 关键字指定路径。Pipeline 的分析结果会输出到原结果中，根据位置的不同，分为Sibling和Parent两类。\n   Sibling - 结果和现有分析结果同级\n   type 含义     min_bucket 最小的桶的值   max_bucket 最大的桶的值   avg_bucket 桶的值的平均数   stats_bucket 桶的值的统计值   percentiles_bucket 桶的值的百分位数      Parent - 结果内嵌到现有的聚合分析结果中\n   type 含义     dervative 求导   cumultive sum 累计求和   moving window 滑动窗口      作用范围 #   默认作用范围是 query 的查询结果集，同时支持以下方式改变作用范围：\n   Filter\n 只过滤聚合的结果集，不过滤query 的结果集。\n   Post Filter\n 只过滤 query 的结果集，不过滤聚合的结果集。\n  性能考量：post_filter会在查询之后才会被执行，因此会失去过滤在性能上帮助(比如缓存)。因此post_filter应该只和聚合一起使用，并且仅当你使用了不同的过滤条件时。    Global\n 全局聚合，不受 query 作用域的影响。\n   聚合原理 #    Min聚合分析执行流程\n  Terms聚合分析的执行流程\n  Terms Aggregation的特殊返回值\n doc_count_error_upper_bound：被遗漏的term分桶，包含的文档，可能有最大值；\n  sum_other_doc_count：除了返回结果 bucket 的terms 以外，其他terms 的文档总数（总数 - 返回的总数）。\n   当 Terms的 size为3\n  Terms 不正确demo\n Top3应该是A(12)、B(6)、D(6)。\n     解决Terms 不准的问题\n  不准的原因\n数据分散在多个分片上，Coordinating Node 无法获取数据全貌。\n  解决方案\n  当数据量不大时，设置Primary Shard 为1，实现准确性；\n  在分布式数据上，设置shard_size参数，提高精确度。\n 原理：每次从Shard上额外多获取数据，提升准确率。\n     shard_size 设定\n 调整shard_size 大小，降低doc_count_error_upper_bound来提升准确度（增加整体计算量，提高了准确度，但会降低相应时间）； shard Size 默认大小：shard size = size * 1.5 + 10      "},{"id":1,"href":"/docs/elasticsearch/mds/2_distribute/","title":"分布式原理","section":"Elasticsearch","content":"分布式特性 #   Elasticsearch 天生就是分布式架构。\n  带来的好处  存储支持水平扩容，支持PB级数据； 提高系统的可用性，部分节点停止服务，整个集群的服务不受影响。   不同集群的设置  不同的集群通过不同的名字来区分，默认名字 elasticsearch ； 通过配置文件修改，或者在命令行中 -E cluster.name = clustername 进行设定。    分布式模式 #  节点 #   节点是一个Elasticsearch 的实例，其本质就是一个JAVA进程。一台机器上可以运行多个Elasticsearch进程，但是生产环境一般建议一台机器上就运行一个Elasticsearch实例。\n每一个节点都有名字，通过配置文件配置，或者启动的时候 -E node.name = nodename指定；每一个节点在启动之后，会分配一个UID，保存在data目录下。\n   Coordinating Node\n 处理请求的节点，叫Coordinating Node。路由请求道正确的节点，例如创建索引的请求，需要路由到Master节点。\n  所有节点默认都是Coordinating Node； 通过将其他类型设置为False，使其成为Dedicated Coordinating Node。    Data Node\n 可以保存数据的节点，叫做Data Node，在数据扩展上起到了至关重要的作用（由Master Node决定如何把分片分发到数据节点上）。通过增加 Data Node，可以解决数据水平扩展和解决数据单点问题。\n  同一索引，主分片和副本分片不能分配在同一节点，防止某一节点宕机时数据丢失。如果某一个集群只有一个节点，此时某一个索引又存在副本分片，此时集群状态是黄色的，因为无法分配副本分片；如果该集群后续有节点加入，会在新加入的节点创建副本分片。\n  节点启动后，默认就是数据节点； 可以设置node.data:false禁止。    Master Node\n Master Node的职责：处理创建，删除索引等请求/决定分片被分配到哪个节点/负责索引的创建于删除；维护并且更新Cluster State。\n  最佳实践  Master非常重要，在部署上需要考虑解决单点的问题； 为一个集群设置多个Mastger节点/每个节点只承担Master的单一角色。      Master Eligible Node\n 一个集群，支持配置多个Master Eligible节点。这些节点可以在必要时（如Master节点出现故障，网络故障时）参与选主流程，成为Master节点；当集群内第一个Master eligible节点启动的时候，它会将自己选举成Master节点。\n  每个节点启动后，默认就是一个Master eligible节点； 可以设置node.master:false禁止。    默认节点类型\n   节点类型 配置参数 默认值     Master Eligible node.master true   data ode.data true   ingest node.ingest true   coordinating only 无 设置上面三个参数全为false   machine learning node.ml true（需要 enable x-pack）      集群状态 #   集群状态（Cluster State），维护了一个集群中，必要的信息：\n 所有节点信息； 所有索引和其相关的Mapping和Setting信息； 分片的路由信息。    在每个节点上都保存了集群的状态信息； 只有Master节点才能修改集群的状态信息，并负责同步给其他节点。  选主过程 #   Master Eligible Node互相Ping对方，Node Id 低的成为被选举的节点； 其他节点会加入集群，但是不承担Master节点的角色； 一旦发现被选中的主节点丢失，就会被选举出新的Master节点。  脑裂 #   Split-Brain，分布式系统的经典网络问题，当出现网络问题，假设有3个节点，一个节点和其他节点无法连接，Node 2 和 Node 3会重新选举Master，Node 1 自己还是作为 Master组成一个集群，同时更新Cluster State；导致两个Master 维护不同的 cluster state。网络恢复时，无法正确恢复。\n Es中如何解决\n  设定仲裁数\n 限定一个选举条件，设置quorum（仲裁），只有在Master eligible节点数大于quorum时，才能进行选举；Quorum = (master 节点总数/ 2) + 1。\n例如：当3个master eligible时，设置discovery.zen.minimum_master_nodes为2，避免脑裂。\n   从7.0开始，无需这个配置\n  集群的故障转移 #  分片 #    Primary Shard - 提升系统存储容量\n 通过主分片，将数据分布在所有节点上，实现存储的水平扩展。\n主分片（Primary Shard）数在索引创建的时候指定，后续默认不能修改，如果修改，需重建索引。\n   Replica Shard - 提高数据可用性\n 通过引入副本分配（Replica Shard）\n  提高数据的可用性。一旦主分片丢失，副本分配可以Promote成主分片。副本分片数可以动态调整。每个节点上都有完备的数据。如果不设置副本分片，一旦节点硬件故障，就有可能造成数据丢失。\n  副本分片由主分片（Primary Shard）同步。通过支持增加Replica个数，一定程度可以提高读取吞吐量。\n     分片数的设定\n  主分片数过小\n 如果该索引增长的很快，集群无法通过增加节点实现对这个索引的数据扩展。\n   主分片数过大\n 导致单个Shard容量很小，引发一个节点上有过多的分片，影响性能。\n   副本分片数设置过多\n 副本分片数设置过多，会降低集群整体的写入性能。\n     故障转移 #   下图3个节点共同组成集群。包含了1个索引，索引设置了3个Primary Shard 和 1个 Replica。\n 故障转移过程：\n Node 1 是Master 节点，节点意外出现故障。集群重新选举Master 节点； Node 3上的R0提升为 P0，集群变黄； R0 和R1 分配，集群变绿。   集群健康状态  Green：健康，所有主分片和副本分片都可用； Yellow：亚健康，所有的主分片可用，部分副本分片不可用； Red：不健康状态，部分主分片不可用。    文档分布式存储 #   文档会存储在具体的某个主分片和副本分片上：例如 文档1，会存储在P0和 R0分片上。\n   文档到分片的映射算法\n 确保文档能够均匀分布在所用分片上，充分利用硬件资源，避免部分机器空闲，部分机器繁忙。\n   随机/Round Robin；\n缺点：当查询文档1，分片数很多，需要多次查询才可能查到 文档1。\n  维护文档到分片的映射关系；\n缺点：当文档数据量大的时候，维护成本高。\n  实时计算，通过文档1，自动算出，需要去哪个分片获取文档。\nshard = hash(_routing) % number_of_primary_shards\n Hash算法确保文档均匀分散到分片中；默认的_routing值是文档id；可以自行制定routing数值，例如用相同国家的商品，都分配到制定的shard（如下）。\n PUT posts/_doc/100?routing=bigdata { \u0026#34;title\u0026#34; : \u0026#34;xxxx\u0026#34; }   ES一般使用算法3，这也是设置Index Settings 后，Primary 数，不能随意更改的根本原因。\n  更新一个文档的流程\n  删除一个文档的流程\n  分片及其生命周期 #   分片ES中最小的工作单元，是一个Lucene的Index。\n 倒排索引的不可变性 #   倒排索引采用Immutable Design 一旦生成，不可更改。\n   不可变性优势\n 无需考虑并发写文件的问题，避免了锁机制带来的性能问题； 一旦读入内核的文件系统缓存，便留在那里。只要文件系统存有足够的空间，大部分请求会直接请求内存，不会命中磁盘，提升了很大的性能； 缓存容易生成和维护/数据可以被压缩。    不可变性带来的挑战\n如果需要让一个新的文档可以被搜索，需要重建整个索引。\n  Lucene Index #   在Lucene中，单个倒排索引文件被称为Segment。Segment是自包含的，不可变更的。\n  多个Segments汇总在一起，称为Lucene的Index，其对应的就是Es中的Shard。\n   新文档写入时\n会生成新的Segment，查询时会同时查询所有的Segments，并且对结果汇总。Lucene中有一个文件，用来记录所有Segments信息，叫做Commit Point。\n  删除文档信息时\n保存在.del文件中，查询时会过滤掉。\n  Refresh #   将Index Buffer写入Segment的过程叫Refresh。Refresh 不执行 fsync操作。如果系统有大量的数据写入，那就会产生很多的Segment。\nRefresh后，数据就可以被搜索到了。这也是为什么Elasticsearch被称为近实时搜索。\n  Refresh 频率：默认1s发生一次，可通过index.refresh_interval 配置。 其他 Refresh时机：Index Buffer 被占满时，会触发Refresh，默认值是JVM的 10%。  Transaction Log #   Segment写入磁盘的过程相对耗时，借助文件系统缓存，Refresh时，先将Segment写入缓存以开放查询；为了保证数据不会丢失，所以在Index文档时，同时写Transaction Log，高版本开始，Transaction Log默认落盘，每个分片有一个Transaction Log。\n在ES Refresh时，Index Buffer 被清空，Transaction Log 不会清空。\n Flush \u0026amp; Lucene Commit #   调用Refresh，Index Buffer 清空并且 Refresh；调用fsync，将缓存中的Segments写入磁盘；清空（删除）Transaction Log.\n  频率：默认30分钟调用一次； 其他Flush 时机：Transaction Log满了会调用（默认512M）。  Merge #   Segment很多，需要被定期合并。Merge可以减少Segments，真正删除已经删除的文档（.del文件）。\n ES 和 Lucene 会自动进行Merge 操作，也可以手动调用：\nPOST my_index/_forcemerge 分布式搜索机制 #   Elasticsearch 的搜索，会分两阶段进行：\n 第一阶段-Query； 第二阶段-Fetch。     Query 阶段\n 假设集群有3个节点\n 用户发出搜索请求到ES 节点。节点收到请求后，会以 Coordinating 节点的身份，在6个主副分片中随机选择3个分片，发送查询请求； 被选中的分片执行查询，进行排序。然后，每个分片都会返回From + Size 个排序后的文档Id和排序值给Coordinating节点。     Fetch 阶段\n  Coordinating Node 会将 Query 阶段，从每个分片获取的排序后的文档Id列表重新进行排序。选取From 到 From + size 个文档的Id； 以Multi get请求的方式，到相应的分片获取详细的文档数据。     Query Then Fetch 潜在的问题 #    性能问题\n 每个分片上需要查的文档个数 = from +size 最终协调节点需要处理：number_of_shard * ( from + size) 深度分页    相关性算分\n 每个分片基于自己的分片上的数据进行相关度计算。这会导致打分偏离的情况，特别是数据量很少时。相关性算分在分片之间是相互独立。当文档总数很少的情况下，如果主分片大于1，主分片数越多，相关性算分会越不准。\n 解决方法：\n  数据量不大的时候，可以将主分片数设置为1;\n  当数据量足够大的时候，只要保证文档均匀分散在各个分片上，结果一般不会出现偏差；\n  使用DFS Query Then Fetch，搜索URL中指定参数 \u0026ldquo;_search?search_type=dfs_query_then_fetch\u0026rdquo;\n 到每个分片把各分片的词频和文档频率进行搜集，然后完整的进行一次相关性算分，耗费更加多的CPU和内存，执行性能低下，一般不建议使用。\n     排序 #   排序是针对字段原始内容进行的，倒排索引无法发挥作用，需要用到正排索引。通过文档ID 和字段快速得到字段原始内容。默认情况根据算分进行排序。\nElasticsearch 有两种实现方法：\n Fielddata Doc Values （列式存储，对Text 类型无效）       Doc Values Fielddata     何时创建 索引时，和倒排索引一起创建 搜索时候动态创建   创建位置 磁盘文件 JVM Heap   优点 避免大量内存占用 索引速度块，不用占用额外磁盘空间   缺点 降低索引速度，占用额外磁盘空间 文档过多时，动态创建开销大，占用过多JVM Heap   缺省值 ES 2.x 之后 ES 1.x 及之前      关闭 Doc Values\n Doc Values 默认启用，可以通过Mapping设置关闭，可以增加索引的速度/减少磁盘空间。如果重新打开，需要重建索引。\n明确不需要做排序以及聚合分析，可以关闭。\n   分页 #   默认情况下，查询按照相关度算分排序，返回前10条记录；\nfrom ：开始位置；\nSize ：期望获取文档的总数。\n 深度分页问题 #   ES 天生就是分布式的。查询信息，但是数据分别保存在多个分片，多台机器，ES天生就需要满足排序的需要（按照相关性算分）。\n当一个查询：From = 990， Size = 10：\n 会在每个分片上先获取1000 个文档； 然后通过Coordinating Node聚合所有结果； 最后再通过排序选取前 1000个文档。    页数越深，占用内存越多。为了避免深度分页带来的内存开销。ES有一个设定，默认限定10000 个文档\n   Search After\n 避免深度分页的性能问题，可以实时获取下一页文档信息。但是有限制：\n 不支持指定页数； 只能下翻。  使用：\n 第一步搜索需要指定sort，并且保证值是唯一的（可以通过加入_id保证唯一性）; 然后使用上一次，最后一个文档的sort值进行查询。   { \u0026#34;size\u0026#34;: 1, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} }, \u0026#34;search_after\u0026#34;: [10,\u0026#34;ZQ0vYGsBrR8X3IP75QqX\u0026#34;], \u0026#34;sort\u0026#34;: [ {\u0026#34;age\u0026#34;: \u0026#34;desc\u0026#34;} ,{\u0026#34;_id\u0026#34;: \u0026#34;asc\u0026#34;} ] }  通过唯一排序值定位，将每次要处理的文档数都控制在 10。\n   Scroll API\n 创建一个快照，有新的数据写入以后，无法被查到；每次查询后，输入上一次的scroll id。\n POST /users/_search?scroll=5m { \u0026#34;size\u0026#34;: 1, \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34; : { } } } POST /_search/scroll { \u0026#34;scroll\u0026#34; : \u0026#34;1m\u0026#34;, \u0026#34;scroll_id\u0026#34; : \u0026#34;DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAWAWbWdoQXR2d3ZUd2kzSThwVTh4bVE0QQ==\u0026#34; }   不同的搜索类型和使用场景\n  Regular\n 需要实时获取顶部的部分文档。例如查询最新的订单。\n   Scroll\n 需要全部文档，例如导出全部数据。\n   Pagination\n From 和 Size；\n如果需要深度分页，使用 Search After。\n     处理并发读写操作 #  并发空值的必要性 #   两个Web程序同时更新某个文档，如果缺乏有效的并发，会导致更改的数据丢失。\n   悲观并发控制\n 假定有变更冲突的可能。会对资源加锁，防止冲突。例如数据库行锁。\n   乐观并发控制\n 假定冲突是不会发生的，不会阻塞正在尝试的操作。如果数据在读写中被修改，更新将会失败。应用程序决定如何解决冲突，例如重试更新，使用新的数据，或者将错误报告给用户。\n  ES采用的是乐观并发控制。\n   ES的乐观并发空值 #   ES 中的文档是不可变更的。如果你更新一个文档，会将文档标记为删除，同时增加一个全新的文档。同时文档的version字段加1。\n   内部版本控制\n if_seq_no + if_primary_term\n PUT products/_doc/1?if_seq_no=1\u0026amp;if_primary_term=1 { \u0026#34;title\u0026#34;:\u0026#34;iphone\u0026#34;, \u0026#34;count\u0026#34;:100 }   使用外部版本（使用其他数据库作为主要数据存储）\n version + version_type = external\n PUT products/_doc/1?version=30000\u0026amp;version_type=external { \u0026#34;title\u0026#34;:\u0026#34;iphone\u0026#34;, \u0026#34;count\u0026#34;:100 }   "}]